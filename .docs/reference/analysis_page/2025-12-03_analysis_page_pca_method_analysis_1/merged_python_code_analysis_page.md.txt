## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page.py ##

"""
Analysis Page (Version 2.0) - Card-Based Architecture

This module implements a modern card-based analysis interface for Raman spectroscopy data
with categorized method selection, dynamic parameter generation, and comprehensive results.

Architecture:
- Startup view: Card gallery organized by category (Exploratory, Statistical, Visualization)
- Method view: Split layout with input form (left) and results display (right)
- History sidebar: Session-based analysis tracking with clickable items
- Top bar: Navigation with "New Analysis" button

Key Features:
- 15+ analysis methods across 3 categories
- Dynamic parameter widgets generated from registry
- Threaded analysis execution with progress feedback
- Multi-tab results (plots, data tables, summaries, diagnostics)
- Comprehensive export (PNG, SVG, CSV, full reports)
- Full localization support (English + Japanese)
- Responsive design with proper error handling

UI Components (Modularized):
- views.py: Startup view, category sections, method cards, history sidebar, top bar
- method_view.py: Method-specific input forms and results panels
- export_utils.py: Export manager for all output formats
- thread.py: Background analysis execution
- result.py: Result data structures
- registry.py: Method definitions and parameters

Author: Enhanced by AI Assistant
Date: 2024-12-18
Version: 2.0
"""

import sys
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime

from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QStackedWidget,
    QListWidgetItem, QMessageBox, QProgressBar, QFrame, QSplitter
)
from PySide6.QtCore import Qt, Signal, QSize
from PySide6.QtGui import QFont

from components.widgets import load_icon
from components.widgets.matplotlib_widget import MatplotlibWidget
from configs.configs import load_config
from utils import RAMAN_DATA, PROJECT_MANAGER

# Import analysis utilities
from .analysis_page_utils import (
    ANALYSIS_METHODS,
    AnalysisResult,
    AnalysisThread
)
from .analysis_page_utils.views import (
    create_startup_view,
    create_history_sidebar,
    create_top_bar
)
from .analysis_page_utils.method_view import (
    MethodView,
    populate_results_tabs
)
from .analysis_page_utils.export_utils import ExportManager


@dataclass
class AnalysisHistoryItem:
    """Represents a single analysis in the session history."""
    timestamp: datetime
    category: str
    method_key: str
    method_name: str
    dataset_name: str
    parameters: Dict[str, Any]
    result: Optional[AnalysisResult] = None


class AnalysisPage(QWidget):
    """
    Main analysis page with card-based interface.
    
    View States:
    - startup: Card gallery showing all available methods
    - method: Input form and results for selected method
    
    Signals:
    - analysis_started: Emitted when analysis begins
    - analysis_finished: Emitted when analysis completes
    - error_occurred: Emitted on analysis errors
    """
    
    analysis_started = Signal(str, str)  # category, method_key
    analysis_finished = Signal(str, str, object)  # category, method_key, result
    error_occurred = Signal(str)  # error message
    showNotification = Signal(str, str)  # title, message - for toast notifications
    
    def __init__(self, parent=None):
        """Initialize Analysis Page with card-based architecture."""
        super().__init__(parent)
        
        # Core references
        self.raman_data = RAMAN_DATA
        self.project_manager = PROJECT_MANAGER
        # Use global localization manager instead of creating a new one
        from utils import LOCALIZE
        self.localize = LOCALIZE  # Use global LOCALIZE function
        
        # State management
        self.current_view = "startup"  # 'startup' or 'method'
        self.current_category = None
        self.current_method_key = None
        self.current_result = None
        self.analysis_history: List[AnalysisHistoryItem] = []
        
        # Analysis thread
        self.analysis_thread: Optional[AnalysisThread] = None
        
        # Export manager
        self.export_manager = ExportManager(self, self.localize, self.project_manager)
        
        # Build UI
        self._setup_ui()
    
    def _setup_ui(self):
        """Setup main UI layout with stacked views."""
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        # Top bar with reduced height
        # self.top_bar = create_top_bar(self.localize, self._show_startup_view)
        # main_layout.addWidget(self.top_bar)
        
        # Main content: Sidebar + Stacked Views
        content_splitter = QSplitter(Qt.Horizontal)
        content_splitter.setChildrenCollapsible(False)
        
        # History sidebar
        self.history_sidebar = create_history_sidebar(self.localize)
        self.history_sidebar.history_list.itemClicked.connect(self._on_history_item_clicked)
        self.history_sidebar.clear_btn.clicked.connect(self._clear_history)
        content_splitter.addWidget(self.history_sidebar)
        
        # Stacked widget for views
        self.view_stack = QStackedWidget()
        
        # Startup view
        self.startup_view = create_startup_view(self.localize, self._show_method_view)
        self.view_stack.addWidget(self.startup_view)
        
        # Method view placeholder (created dynamically)
        self.method_view = None
        
        content_splitter.addWidget(self.view_stack)
        content_splitter.setSizes([280, 1000])  # Sidebar smaller than main content
        
        main_layout.addWidget(content_splitter)
        
        # Show startup view initially
        self._show_startup_view()
    
    def _show_startup_view(self):
        """Switch to startup view showing method cards."""
        self.current_view = "startup"
        self.view_stack.setCurrentWidget(self.startup_view)
        
        # Update top bar (if enabled)
        if hasattr(self, 'top_bar'):
            self.top_bar.new_analysis_btn.setVisible(False)
            self.top_bar.back_btn.setVisible(False)
            self.top_bar.title_label.setText("ðŸ“Š " + self.localize("ANALYSIS_PAGE.title"))
    
    def _show_method_view(self, category: str, method_key: str):
        """
        Switch to method view for specific analysis method.
        
        Args:
            category: Method category (exploratory, statistical, visualization)
            method_key: Method identifier from registry
        """
        self.current_view = "method"
        self.current_category = category
        self.current_method_key = method_key
        
        # Get method info
        method_info = ANALYSIS_METHODS[category][method_key]
        
        # Get available datasets - RAMAN_DATA is a dict, get names from keys
        dataset_names = list(self.raman_data.keys()) if self.raman_data else []
        if not dataset_names:
            QMessageBox.warning(
                self,
                self.localize("ANALYSIS_PAGE.no_datasets_title"),
                self.localize("ANALYSIS_PAGE.no_datasets_message")
            )
            return
        
        # Remove old method view if exists
        if self.method_view:
            self.view_stack.removeWidget(self.method_view)
            self.method_view.deleteLater()
        
        # Create new method view
        self.method_view = MethodView(
            category, method_key, dataset_names,
            self.localize,
            self._run_analysis,
            self._show_startup_view
        )
        
        # Connect export buttons (plot export via matplotlib toolbar)
        results_panel = self.method_view.results_panel
        results_panel.export_data_btn.clicked.connect(self.method_view._handle_export_csv)
        
        self.view_stack.addWidget(self.method_view)
        self.view_stack.setCurrentWidget(self.method_view)
        
        # Update top bar (if enabled)
        if hasattr(self, 'top_bar'):
            self.top_bar.new_analysis_btn.setVisible(True)
            self.top_bar.back_btn.setVisible(True)
            self.top_bar.title_label.setText(f"ðŸ“Š {method_info['name']}")
    
    def _run_analysis(self, category: str, method_key: str, dataset_selection, param_widget):
        """
        Execute analysis with selected parameters.
        
        Args:
            category: Method category
            method_key: Method identifier
            dataset_selection: Can be:
                - string: Single dataset name
                - list: Multiple dataset names
                - dict: Group assignments {group_label: [dataset_names]}
            param_widget: DynamicParameterWidget instance
        """
        # Get method info for validation
        method_info = ANALYSIS_METHODS[category][method_key]
        min_datasets = method_info.get("min_datasets", 1)
        max_datasets = method_info.get("max_datasets", None)
        
        # Handle group-based selection
        group_labels = None
        if isinstance(dataset_selection, dict):
            # Group mode: {group_label: [dataset_names]}
            if not dataset_selection:
                QMessageBox.warning(
                    self,
                    self.localize("ANALYSIS_PAGE.validation_error_title"),
                    self.localize("ANALYSIS_PAGE.no_groups_defined")
                )
                return
            
            # Flatten groups to get all dataset names
            selected_datasets = []
            group_labels = {}  # {dataset_name: group_label}
            for group_name, datasets in dataset_selection.items():
                for ds in datasets:
                    selected_datasets.append(ds)
                    group_labels[ds] = group_name
        
        # Normalize dataset_selection to list for consistent processing
        elif isinstance(dataset_selection, str):
            selected_datasets = [dataset_selection]
        elif isinstance(dataset_selection, list):
            selected_datasets = dataset_selection
        else:
            QMessageBox.critical(
                self,
                self.localize("ANALYSIS_PAGE.error_title"),
                "Invalid dataset selection format"
            )
            return
        
        # Validate number of datasets selected
        num_selected = len(selected_datasets)
        if num_selected < min_datasets:
            QMessageBox.warning(
                self,
                self.localize("ANALYSIS_PAGE.validation_error_title"),
                self.localize("ANALYSIS_PAGE.insufficient_datasets_message", 
                            required=min_datasets, selected=num_selected)
            )
            return
        
        if max_datasets is not None and num_selected > max_datasets:
            QMessageBox.warning(
                self,
                self.localize("ANALYSIS_PAGE.validation_error_title"),
                self.localize("ANALYSIS_PAGE.too_many_datasets_message",
                            max=max_datasets, selected=num_selected)
            )
            return
        
        # Get datasets from RAMAN_DATA dict
        dataset_data = {}
        missing_datasets = []
        for name in selected_datasets:
            dataset = self.raman_data.get(name)
            if dataset is None:
                missing_datasets.append(name)
            else:
                dataset_data[name] = dataset
        
        if missing_datasets:
            QMessageBox.critical(
                self,
                self.localize("ANALYSIS_PAGE.error_title"),
                self.localize("ANALYSIS_PAGE.datasets_not_found", 
                            datasets=", ".join(missing_datasets))
            )
            return
        
        # Extract parameters from widget using get_parameters() method
        parameters = param_widget.get_parameters() if param_widget else {}
        
        # Add group labels to parameters if present
        if group_labels:
            parameters['_group_labels'] = group_labels
        
        # Disable run button during execution
        self.method_view.run_btn.setEnabled(False)
        self.method_view.run_btn.setText(self.localize("ANALYSIS_PAGE.running"))
        
        # Create and start analysis thread
        # AnalysisThread expects dataset_data as Dict[str, pd.DataFrame]
        self.analysis_thread = AnalysisThread(
            category, method_key, parameters, dataset_data
        )
        self.analysis_thread.finished.connect(
            lambda result: self._on_analysis_finished(result, category, method_key, selected_datasets, parameters)
        )
        self.analysis_thread.error.connect(self._on_analysis_error)
        self.analysis_thread.progress.connect(self._on_analysis_progress)
        
        # Emit signal
        self.analysis_started.emit(category, method_key)
        
        # Start thread
        self.analysis_thread.start()
    
    def _on_analysis_finished(
        self,
        result: AnalysisResult,
        category: str,
        method_key: str,
        dataset_names: list,
        parameters: Dict
    ):
        """
        Handle completed analysis.
        
        Args:
            result: Analysis result object
            category: Method category
            method_key: Method identifier
            dataset_names: List of dataset names used
            parameters: Analysis parameters
        """
        # Re-enable run button
        self.method_view.run_btn.setEnabled(True)
        self.method_view.run_btn.setText(self.localize("ANALYSIS_PAGE.start_analysis_button"))
        
        # Store result
        self.current_result = result
        
        # Populate results tabs
        populate_results_tabs(
            self.method_view.results_panel,
            result,
            self.localize,
            MatplotlibWidget
        )
        
        # Add to history (use first dataset name for display, full list in result)
        method_info = ANALYSIS_METHODS[category][method_key]
        display_name = dataset_names[0] if len(dataset_names) == 1 else f"{len(dataset_names)} datasets"
        history_item = AnalysisHistoryItem(
            timestamp=datetime.now(),
            category=category,
            method_key=method_key,
            method_name=method_info["name"],
            dataset_name=display_name,
            parameters=parameters,
            result=result
        )
        self.analysis_history.append(history_item)
        self._update_history_list()
        
        # Emit signal
        self.analysis_finished.emit(category, method_key, result)
    
    def _on_analysis_error(self, error_msg: str):
        """
        Handle analysis errors.
        
        Args:
            error_msg: Error message
        """
        # Re-enable run button
        if self.method_view:
            self.method_view.run_btn.setEnabled(True)
            self.method_view.run_btn.setText(self.localize("ANALYSIS_PAGE.start_analysis_button"))
        
        # Show error dialog
        QMessageBox.critical(
            self,
            self.localize("ANALYSIS_PAGE.error_title"),
            self.localize("ANALYSIS_PAGE.analysis_error").format(error_msg)
        )
        
        # Emit signal
        self.error_occurred.emit(error_msg)
    
    def _on_analysis_progress(self, progress: int):
        """
        Update progress during analysis.
        
        Args:
            progress: Progress percentage (0-100)
        """
        # Update button text with progress
        if self.method_view:
            self.method_view.run_btn.setText(f"{self.localize('ANALYSIS_PAGE.running')}... ({progress}%)")
    
    def _update_history_list(self):
        """Update history sidebar with recent analyses."""
        history_list = self.history_sidebar.history_list
        history_list.clear()
        
        # Add items in reverse chronological order
        for idx, item in enumerate(reversed(self.analysis_history)):
            list_item = QListWidgetItem()
            
            # Format: "ðŸ• 14:35 | PCA | Dataset 1"
            time_str = item.timestamp.strftime("%H:%M")
            text = f"ðŸ• {time_str}\n{item.method_name}\nðŸ“ {item.dataset_name}"
            
            list_item.setText(text)
            list_item.setData(Qt.UserRole, len(self.analysis_history) - 1 - idx)  # Store index
            list_item.setFont(QFont("Segoe UI", 10))
            
            history_list.addItem(list_item)
    
    def _on_history_item_clicked(self, item: QListWidgetItem):
        """
        Restore analysis from history.
        
        Args:
            item: Clicked history list item
        """
        idx = item.data(Qt.UserRole)
        history_item = self.analysis_history[idx]
        
        # Show method view for this analysis
        self._show_method_view(history_item.category, history_item.method_key)
        
        # Restore parameters (if possible)
        if self.method_view and hasattr(self.method_view, 'param_widget'):
            # Set dataset - handle both simple and group modes
            dataset_widget = self.method_view.dataset_widget
            if dataset_widget and isinstance(history_item.dataset_name, str):
                # Handle both QComboBox (single mode) and QListWidget (multi mode)
                if hasattr(dataset_widget, 'findText'):  # QComboBox
                    dataset_idx = dataset_widget.findText(history_item.dataset_name)
                    if dataset_idx >= 0:
                        dataset_widget.setCurrentIndex(dataset_idx)
                elif hasattr(dataset_widget, 'findItems'):  # QListWidget
                    items = dataset_widget.findItems(history_item.dataset_name, Qt.MatchExactly)
                    if items:
                        items[0].setSelected(True)
            
            # Restore parameters by recreating the widget with saved params
            # The DynamicParameterWidget constructor accepts saved_params
            # This will be handled by _show_method_view when it creates the widget
            
            # Display cached result if available
            if history_item.result:
                populate_results_tabs(
                    self.method_view.results_panel,
                    history_item.result,
                    self.localize,
                    MatplotlibWidget
                )
                self.current_result = history_item.result
    
    def _clear_history(self):
        """Clear analysis history."""
        reply = QMessageBox.question(
            self,
            self.localize("ANALYSIS_PAGE.clear_history_title"),
            self.localize("ANALYSIS_PAGE.clear_history_confirm"),
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self.analysis_history.clear()
            self._update_history_list()
    
    def _on_dataset_changed(self):
        """Handle dataset changes (load/remove)."""
        # If in method view, update dataset widget
        if self.method_view and hasattr(self.method_view, 'dataset_widget'):
            widget = self.method_view.dataset_widget
            
            # Handle QComboBox (single-dataset mode)
            if hasattr(widget, 'currentText'):
                current = widget.currentText()
                widget.clear()
                
                if self.raman_data:
                    # RAMAN_DATA is a dict, get dataset names from keys
                    widget.addItems(list(self.raman_data.keys()))
                    
                    # Restore selection if still available
                    idx = widget.findText(current)
                    if idx >= 0:
                        widget.setCurrentIndex(idx)
            
            # Handle QListWidget (multi-dataset mode)
            elif hasattr(widget, 'selectedItems'):
                selected_names = [item.text() for item in widget.selectedItems()]
                widget.clear()
                
                if self.raman_data:
                    widget.addItems(list(self.raman_data.keys()))
                    
                    # Restore selections if still available
                    for i in range(widget.count()):
                        if widget.item(i).text() in selected_names:
                            widget.item(i).setSelected(True)
    
    # === Export Methods ===
    
    def _export_png(self):
        """Export current plot as PNG."""
        if not self.current_result or not self.current_result.primary_figure:
            return
        
        method_name = ANALYSIS_METHODS[self.current_category][self.current_method_key]["name"]
        filename = f"{method_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        
        self.export_manager.export_plot_png(self.current_result.primary_figure, filename)
    
    def _export_svg(self):
        """Export current plot as SVG."""
        if not self.current_result or not self.current_result.primary_figure:
            return
        
        method_name = ANALYSIS_METHODS[self.current_category][self.current_method_key]["name"]
        filename = f"{method_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.svg"
        
        self.export_manager.export_plot_svg(self.current_result.primary_figure, filename)
    
    def _export_csv(self):
        """Export current data table as CSV."""
        if not self.current_result or self.current_result.data_table is None:
            return
        
        method_name = ANALYSIS_METHODS[self.current_category][self.current_method_key]["name"]
        filename = f"{method_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        self.export_manager.export_data_csv(self.current_result.data_table, filename)
    
    def export_full_report(self):
        """Export complete analysis report (public method for external calls)."""
        if not self.current_result:
            QMessageBox.warning(
                self,
                self.localize("ANALYSIS_PAGE.warning_title"),
                self.localize("ANALYSIS_PAGE.no_results_to_export")
            )
            return
        
        method_name = ANALYSIS_METHODS[self.current_category][self.current_method_key]["name"]
        
        # Get dataset name from widget
        dataset_name = "Unknown"
        if self.method_view and hasattr(self.method_view, 'dataset_widget'):
            widget = self.method_view.dataset_widget
            if hasattr(widget, 'currentText'):
                dataset_name = widget.currentText()
            elif hasattr(widget, 'selectedItems'):
                selected = widget.selectedItems()
                dataset_name = selected[0].text() if selected else "Multiple"
        
        # Get current parameters
        parameters = {}
        if self.method_view and hasattr(self.method_view, 'param_widget'):
            try:
                parameters = self.method_view.param_widget.get_parameters()
            except:
                pass
        
        self.export_manager.export_full_report(
            self.current_result,
            method_name,
            parameters,
            dataset_name
        )
    
    def save_to_project(self):
        """Save current analysis to project folder (public method)."""
        if not self.current_result:
            QMessageBox.warning(
                self,
                self.localize("ANALYSIS_PAGE.warning_title"),
                self.localize("ANALYSIS_PAGE.no_results_to_save")
            )
            return
        
        method_name = ANALYSIS_METHODS[self.current_category][self.current_method_key]["name"]
        
        # Get dataset name from widget
        dataset_name = "Unknown"
        if self.method_view and hasattr(self.method_view, 'dataset_widget'):
            widget = self.method_view.dataset_widget
            if hasattr(widget, 'currentText'):
                dataset_name = widget.currentText()
            elif hasattr(widget, 'selectedItems'):
                selected = widget.selectedItems()
                dataset_name = selected[0].text() if selected else "Multiple"
        
        # Get current parameters
        parameters = {}
        if self.method_view and hasattr(self.method_view, 'param_widget'):
            try:
                parameters = self.method_view.param_widget.get_parameters()
            except:
                pass
        
        self.export_manager.save_to_project(
            self.current_result,
            method_name,
            parameters,
            dataset_name
        )


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\__init__.py ##

"""
Analysis Page Utilities

This module provides utility classes and functions for the Analysis Page,
including analysis method registry, threading, and result management.
"""

from .registry import ANALYSIS_METHODS
from .result import AnalysisResult
from .thread import AnalysisThread
from .widgets import create_parameter_widgets

__all__ = [
    'ANALYSIS_METHODS',
    'AnalysisResult',
    'AnalysisThread',
    'create_parameter_widgets'
]


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\backups\method_view_bkp.py ##

"""
Method View Components

This module handles the method-specific view with input forms and results display.
Includes dynamic parameter widget generation and results visualization.
"""

from typing import Dict, Any, Callable, Optional
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QFrame, QScrollArea, QTabWidget, QGroupBox, QComboBox,
    QSplitter, QTextEdit, QTableWidget, QTableWidgetItem, QListWidget,
    QAbstractItemView, QStackedWidget, QButtonGroup, QRadioButton, QCheckBox, QMessageBox
)
from PySide6.QtCore import Qt, QSize
from PySide6.QtGui import QFont

from components.widgets import load_icon, GroupTreeManager, DynamicParameterWidget

from .registry import ANALYSIS_METHODS
from .group_assignment_table import GroupAssignmentTable


def create_method_view(
    category: str,
    method_key: str,
    dataset_names: list,
    localize_func: Callable,
    on_run_analysis: Callable,
    on_back: Callable
) -> QWidget:
    """
    Create method-specific view with input form and results display (Image 2 reference).
    
    Args:
        category: Method category
        method_key: Method identifier
        dataset_names: Available dataset names list (strings)
        localize_func: Localization function
        on_run_analysis: Callback when Run Analysis is clicked
        on_back: Callback for back button
    
    Returns:
        Method view widget with accessible components
    """
    method_info = ANALYSIS_METHODS[category][method_key]
    
    method_widget = QWidget()
    method_widget.setObjectName("methodView")
    
    main_layout = QVBoxLayout(method_widget)
    main_layout.setContentsMargins(0, 0, 0, 0)
    main_layout.setSpacing(0)
    
    # Splitter: Left (Input Form) | Right (Results)
    splitter = QSplitter(Qt.Horizontal)
    splitter.setChildrenCollapsible(False)
    
    # === LEFT PANEL: Input Form ===
    left_panel = QWidget()
    left_layout = QVBoxLayout(left_panel)
    left_layout.setContentsMargins(24, 24, 24, 24)
    left_layout.setSpacing(16)
    
    # Method header
    method_name_label = QLabel(method_info["name"])
    method_name_label.setStyleSheet("""
        font-size: 20px;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 8px;
    """)
    left_layout.addWidget(method_name_label)
    
    # Use localized description from locales, not hardcoded from registry
    method_desc_text = localize_func(f"ANALYSIS_PAGE.METHOD_DESC.{method_key}")
    method_desc_label = QLabel(method_desc_text)
    method_desc_label.setWordWrap(True)
    method_desc_label.setStyleSheet("""
        font-size: 13px;
        color: #6c757d;
        line-height: 1.5;
        margin-bottom: 16px;
    """)
    left_layout.addWidget(method_desc_label)
    
    # Dataset selection - conditional widget based on method requirements
    dataset_selection_mode = method_info.get("dataset_selection_mode", "single")
    min_datasets = method_info.get("min_datasets", 1)
    
    dataset_card = QFrame()
    dataset_card.setObjectName("datasetCard")
    dataset_card.setStyleSheet("""
        QFrame#datasetCard {
            background-color: #ffffff;
            border: 1px solid #dfe3ea;
            border-radius: 16px;
            padding: 0px;
        }
    """)
    dataset_card_layout = QVBoxLayout(dataset_card)
    dataset_card_layout.setContentsMargins(24, 24, 24, 24)
    dataset_card_layout.setSpacing(18)

    # Card header with icon + badges
    dataset_header = QHBoxLayout()
    dataset_header.setSpacing(12)

    dataset_title = QLabel("ðŸ“‚ " + localize_func("ANALYSIS_PAGE.dataset_selection"))
    dataset_title.setStyleSheet("""
        font-size: 18px;
        font-weight: 600;
        color: #1f2a37;
    """)
    dataset_header.addWidget(dataset_title)

    dataset_header.addStretch()

    selection_badge = QLabel(
        localize_func("ANALYSIS_PAGE.dataset_mode_multi")
        if dataset_selection_mode == "multi"
        else localize_func("ANALYSIS_PAGE.dataset_mode_single")
    )
    selection_badge.setStyleSheet("""
        background-color: #eef2ff;
        color: #4338ca;
        border-radius: 999px;
        padding: 4px 14px;
        font-size: 12px;
        font-weight: 600;
    """)
    dataset_header.addWidget(selection_badge)

    min_badge_text = localize_func("ANALYSIS_PAGE.min_datasets").format(count=min_datasets)
    min_badge = QLabel(min_badge_text)
    min_badge.setStyleSheet("""
        background-color: #ecfdf5;
        color: #047857;
        border-radius: 999px;
        padding: 4px 14px;
        font-size: 12px;
        font-weight: 600;
    """)
    dataset_header.addWidget(min_badge)

    dataset_card_layout.addLayout(dataset_header)

    dataset_subtitle = QLabel(localize_func("ANALYSIS_PAGE.dataset_selection_subtitle"))
    dataset_subtitle.setWordWrap(True)
    dataset_subtitle.setStyleSheet("""
        font-size: 13px;
        color: #4b5563;
        line-height: 1.5;
    """)
    dataset_card_layout.addWidget(dataset_subtitle)

    dataset_layout = QVBoxLayout()
    dataset_layout.setSpacing(16)
    dataset_layout.setContentsMargins(0, 0, 0, 0)
    dataset_card_layout.addLayout(dataset_layout)
    
    # For multi-dataset methods, add professional pill-shaped segmented control
    mode_toggle = None
    comparison_radio = None
    classification_radio = None
    
    if dataset_selection_mode == "multi":
        # Modern pill-shaped segmented control container
        toggle_frame = QFrame()
        toggle_frame.setStyleSheet("""
            QFrame {
                background-color: #e9ecef;
                border: 1px solid #dee2e6;
                border-radius: 25px;
                padding: 3px;
                max-width: 500px;
            }
        """)
        toggle_layout = QHBoxLayout(toggle_frame)
        toggle_layout.setContentsMargins(3, 3, 3, 3)
        toggle_layout.setSpacing(3)
        
        # Comparison mode button - pill shaped
        comparison_radio = QRadioButton("ðŸ“Š Unsupervised")
        comparison_radio.setObjectName("comparison_radio")
        comparison_radio.setChecked(True)
        comparison_radio.setCursor(Qt.PointingHandCursor)
        comparison_radio.setStyleSheet("""
            QRadioButton {
                background-color: transparent;
                border-radius: 22px;
                padding: 12px 32px;
                font-weight: 600;
                font-size: 14px;
                color: #495057;
            }
            QRadioButton:hover {
                background-color: rgba(0, 120, 212, 0.1);
            }
            QRadioButton:checked {
                background-color: #0078d4;
                color: white;
            }
            QRadioButton::indicator {
                width: 0px;
                height: 0px;
            }
        """)
        toggle_layout.addWidget(comparison_radio)
        
        # Classification mode button - pill shaped
        classification_radio = QRadioButton("ðŸ”¬ Grouped Classification")
        classification_radio.setObjectName("classification_radio")
        classification_radio.setCursor(Qt.PointingHandCursor)
        classification_radio.setStyleSheet("""
            QRadioButton {
                background-color: transparent;
                border-radius: 22px;
                padding: 12px 32px;
                font-weight: 600;
                font-size: 14px;
                color: #495057;
            }
            QRadioButton:hover {
                background-color: rgba(40, 167, 69, 0.1);
            }
            QRadioButton:checked {
                background-color: #28a745;
                color: white;
            }
            QRadioButton::indicator {
                width: 0px;
                height: 0px;
            }
        """)
        toggle_layout.addWidget(classification_radio)
        
        # Button group for mutual exclusion
        mode_toggle = QButtonGroup()
        mode_toggle.addButton(comparison_radio, 0)
        mode_toggle.addButton(classification_radio, 1)
        
        dataset_layout.addWidget(toggle_frame)
    
    # Create stacked widget for simple vs group mode
    dataset_stack = QStackedWidget()
    
    # === PAGE 0: Simple Selection (Comparison Mode) ===
    simple_widget = QWidget()
    simple_layout = QVBoxLayout(simple_widget)
    simple_layout.setContentsMargins(0, 0, 0, 0)
    
    # Add professional hint label
    if dataset_selection_mode == "multi":
        hint_label = QLabel("ðŸ’¡ <b>Unsupervised Mode:</b> Select multiple datasets for combined analysis. Click checkboxes or use 'Select All' below.")
        hint_label.setWordWrap(True)
        hint_label.setStyleSheet("""
            font-size: 12px;
            color: #495057;
            padding: 12px;
            background-color: #e7f3ff;
            border-left: 4px solid #0078d4;
            border-radius: 4px;
            margin-top: 8px;
        """)
        simple_layout.addWidget(hint_label)
    
    # Create appropriate widget based on selection mode
    dataset_widget = None
    select_all_checkbox = None
    
    if dataset_selection_mode == "single":
        # Single dropdown for single-dataset methods
        dataset_combo = QComboBox()
        dataset_combo.setObjectName("datasetComboBox")
        dataset_combo.setMinimumHeight(36)
        dataset_combo.addItems(dataset_names)
        dataset_combo.setStyleSheet("""
            QComboBox {
                border: 1px solid #d0d0d0;
                border-radius: 4px;
                padding: 6px 12px;
                background-color: white;
                font-size: 13px;
            }
            QComboBox:hover {
                border-color: #0078d4;
            }
            QComboBox::drop-down {
                border: none;
                width: 24px;
            }
            QComboBox::down-arrow {
                image: url(none);
                border-left: 5px solid transparent;
                border-right: 5px solid transparent;
                border-top: 5px solid #6c757d;
                width: 0;
                height: 0;
            }
        """)
        dataset_widget = dataset_combo
        simple_layout.addWidget(dataset_combo)
    else:
        # Create toolbar with Select All checkbox
        from PySide6.QtWidgets import QCheckBox
        toolbar_layout = QHBoxLayout()
        toolbar_layout.setContentsMargins(8, 8, 8, 4)
        
        select_all_checkbox = QCheckBox("Select All")
        select_all_checkbox.setObjectName("selectAllCheckbox")
        select_all_checkbox.setStyleSheet("""
            QCheckBox {
                font-weight: 600;
                font-size: 13px;
                color: #495057;
                spacing: 8px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #adb5bd;
                border-radius: 3px;
                background-color: white;
            }
            QCheckBox::indicator:hover {
                border-color: #0078d4;
            }
            QCheckBox::indicator:checked {
                background-color: #0078d4;
                border-color: #0078d4;
                image: url(none);
            }
            QCheckBox::indicator:checked:after {
                content: "âœ“";
                color: white;
            }
        """)
        toolbar_layout.addWidget(select_all_checkbox)
        toolbar_layout.addStretch()
        simple_layout.addLayout(toolbar_layout)
        
        # Enhanced list with larger rows and hover effects
        dataset_list = QListWidget()
        dataset_list.setObjectName("datasetListWidget")
        dataset_list.setSelectionMode(QAbstractItemView.MultiSelection)
        dataset_list.setMinimumHeight(180)
        dataset_list.setMaximumHeight(300)
        dataset_list.addItems(dataset_names)
        dataset_list.setSpacing(2)
        dataset_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #dee2e6;
                border-radius: 4px;
                padding: 6px;
                background-color: white;
            }
            QListWidget::item {
                padding: 12px 16px;
                border-radius: 4px;
                margin: 1px 0;
                border: 1px solid transparent;
                font-size: 13px;
            }
            QListWidget::item:hover {
                background-color: #f8f9fa;
                border-color: #e9ecef;
            }
            QListWidget::item:selected {
                background-color: #e7f3ff;
                color: #0078d4;
                border-left: 3px solid #0078d4;
                font-weight: 600;
            }
        """)
        
        # Connect Select All functionality
        def toggle_select_all(checked):
            if checked:
                dataset_list.selectAll()
            else:
                dataset_list.clearSelection()
        
        select_all_checkbox.toggled.connect(toggle_select_all)
        
        # Update Select All state when list selection changes
        def update_select_all_state():
            total = dataset_list.count()
            selected = len(dataset_list.selectedItems())
            select_all_checkbox.blockSignals(True)
            select_all_checkbox.setChecked(selected == total and total > 0)
            select_all_checkbox.blockSignals(False)
        
        dataset_list.itemSelectionChanged.connect(update_select_all_state)
        
        dataset_widget = dataset_list
        simple_layout.addWidget(dataset_list)
    
    dataset_stack.addWidget(simple_widget)
    
    # === PAGE 1: Group Assignment (Classification Mode) ===
    group_widget = None
    if dataset_selection_mode == "multi":
        group_widget = GroupAssignmentTable(dataset_names, localize_func)
        group_widget.setMinimumHeight(400)
        dataset_stack.addWidget(group_widget)
        
        # Connect mode toggle to switch between modes
        def toggle_mode(button):
            print("[DEBUG] toggle_mode called")
            print(f"[DEBUG] Button clicked: {button}")
            print(f"[DEBUG] Button objectName: {button.objectName()}")
            print(f"[DEBUG] comparison_radio: {comparison_radio}")
            print(f"[DEBUG] classification_radio: {classification_radio}")
            print(f"[DEBUG] Current stack index BEFORE: {dataset_stack.currentIndex()}")
            
            # Check which button was clicked and switch pages
            if button == comparison_radio:
                print("[DEBUG] Switching to Comparison Mode (page 0)")
                dataset_stack.setCurrentIndex(0)  # Show simple selection
                print(f"[DEBUG] Stack index AFTER: {dataset_stack.currentIndex()}")
            elif button == classification_radio:
                print("[DEBUG] Switching to Classification Mode (page 1)")
                dataset_stack.setCurrentIndex(1)  # Show group assignment table
                print(f"[DEBUG] Stack index AFTER: {dataset_stack.currentIndex()}")
            else:
                print("[DEBUG] WARNING: Button not recognized!")
            
            print(f"[DEBUG] Current visible widget: {dataset_stack.currentWidget()}")
        
        # CRITICAL FIX: Connect individual button toggled signals instead of buttonClicked
        # buttonClicked sometimes fails silently, toggled is more reliable
        comparison_radio.toggled.connect(lambda checked: toggle_mode(comparison_radio) if checked else None)
        classification_radio.toggled.connect(lambda checked: toggle_mode(classification_radio) if checked else None)
        
        # Also try buttonClicked as backup
        mode_toggle.buttonClicked.connect(toggle_mode)
        
        print("[DEBUG] Mode toggle signals connected (toggled + buttonClicked)")
        print(f"[DEBUG] comparison_radio.toggled: {comparison_radio.toggled}")
        print(f"[DEBUG] classification_radio.toggled: {classification_radio.toggled}")
        print(f"[DEBUG] mode_toggle.buttonClicked: {mode_toggle.buttonClicked}")
        print(f"[DEBUG] Toggle function object: {toggle_mode}")
        print(f"[DEBUG] Initial stack index: {dataset_stack.currentIndex()}")
        print(f"[DEBUG] Initial visible widget: {dataset_stack.currentWidget()}")
        print(f"[DEBUG] comparison_radio checked: {comparison_radio.isChecked()}")
        print(f"[DEBUG] classification_radio checked: {classification_radio.isChecked()}")
        
        # Set initial page to Comparison Mode
        dataset_stack.setCurrentIndex(0)
        comparison_radio.setChecked(True)
        print("[DEBUG] Set initial mode to Comparison (index 0)")
        print(f"[DEBUG] After init - comparison_radio checked: {comparison_radio.isChecked()}")
    
    dataset_layout.addWidget(dataset_stack)
    
    left_layout.addWidget(dataset_card)
    
    # Parameters section
    params_group = QGroupBox(localize_func("ANALYSIS_PAGE.parameters"))
    params_group.setStyleSheet("""
        QGroupBox {
            font-weight: 600;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            margin-top: 8px;
            padding-top: 16px;
        }
        QGroupBox::title {
            subcontrol-origin: margin;
            left: 12px;
            padding: 0 4px;
        }
    """)
    params_layout = QVBoxLayout(params_group)
    
    # Create dynamic parameter widget
    # Convert registry format to DynamicParameterWidget format
    # Registry uses: "spinbox"/"double_spinbox"/"combo"/"checkbox"
    # DynamicParameterWidget expects: "int"/"float"/"choice"/"bool"
    
    type_mapping = {
        "spinbox": "int",
        "double_spinbox": "float",
        "combo": "choice",
        "checkbox": "bool"
    }
    
    # Convert params from registry format to param_info format
    params_dict = method_info.get("params", {})
    param_info = {}
    default_params = {}
    
    for param_name, param_config in params_dict.items():
        # Map the type
        registry_type = param_config.get("type", "float")
        widget_type = type_mapping.get(registry_type, registry_type)
        
        # Build param_info entry
        param_info[param_name] = {
            "type": widget_type,
            "description": param_config.get("label", param_name)
        }
        
        # Add range if exists
        if "range" in param_config:
            param_info[param_name]["range"] = param_config["range"]
        
        # Add step if exists
        if "step" in param_config:
            param_info[param_name]["step"] = param_config["step"]
        
        # Add choices if exists (for combo/choice type)
        if "options" in param_config:
            param_info[param_name]["choices"] = param_config["options"]
        
        # Store default value
        if "default" in param_config:
            default_params[param_name] = param_config["default"]
    
    # Create widget with converted format
    param_widget = DynamicParameterWidget(
        method_info={
            "param_info": param_info,
            "default_params": default_params
        },
        saved_params={},
        data_range=None,
        parent=params_group
    )
    params_layout.addWidget(param_widget)
    
    left_layout.addWidget(params_group)
    left_layout.addStretch()
    
    # Action buttons
    button_layout = QHBoxLayout()
    button_layout.setSpacing(12)
    
    back_btn = QPushButton("â† " + localize_func("ANALYSIS_PAGE.back_button"))
    back_btn.setObjectName("secondaryButton")
    back_btn.setMinimumHeight(40)
    back_btn.clicked.connect(on_back)
    button_layout.addWidget(back_btn)
    
    run_btn = QPushButton(localize_func("ANALYSIS_PAGE.run_analysis"))
    run_btn.setObjectName("primaryButton")
    run_btn.setMinimumHeight(40)
    run_btn.setStyleSheet("""
        QPushButton#primaryButton {
            background-color: #0078d4;
            color: white;
            border: none;
            border-radius: 4px;
            font-weight: 600;
            font-size: 14px;
        }
        QPushButton#primaryButton:hover {
            background-color: #006abc;
        }
        QPushButton#primaryButton:pressed {
            background-color: #005a9e;
        }
        QPushButton#primaryButton:disabled {
            background-color: #c0c0c0;
        }
    """)
    
    # Connect run button - extract selected dataset(s) correctly
    def _get_selected_datasets():
        """
        Extract selected dataset names based on widget type and mode.
        
        Returns:
            For Comparison Mode:
                - Single string (single-dataset methods)
                - List of strings (multi-dataset methods)
            For Classification Mode:
                - Dict[str, List[str]] mapping group names to dataset lists
        """
        # Check if Classification Mode is active (for multi-dataset methods)
        if classification_radio and classification_radio.isChecked() and group_widget:
            # Return group assignments
            groups = group_widget.get_groups()
            if not groups:
                # No groups assigned - show warning
                return None
            return groups
        
        # Comparison Mode (simple selection)
        if dataset_selection_mode == "single":
            return dataset_widget.currentText()  # Single string
        else:
            # Multi-select list widget
            selected_items = dataset_widget.selectedItems()
            return [item.text() for item in selected_items]  # List of strings
    
    run_btn.clicked.connect(lambda: on_run_analysis(
        category, method_key, _get_selected_datasets(), param_widget
    ))
    button_layout.addWidget(run_btn)
    
    left_layout.addLayout(button_layout)
    
    # === RIGHT PANEL: Results Display ===
    right_panel = create_results_panel(localize_func)
    
    # Add panels to splitter
    splitter.addWidget(left_panel)
    splitter.addWidget(right_panel)
    splitter.setSizes([400, 600])  # Initial sizes
    
    main_layout.addWidget(splitter)
    
    # Store references for external access
    method_widget.dataset_widget = dataset_widget  # Store the actual widget (QComboBox or QListWidget)
    method_widget.group_widget = group_widget  # Store group widget (GroupAssignmentTable)
    method_widget.comparison_radio = comparison_radio  # Store comparison mode button
    method_widget.classification_radio = classification_radio  # Store classification mode button
    method_widget.dataset_selection_mode = dataset_selection_mode
    method_widget.param_widget = param_widget
    method_widget.run_btn = run_btn
    method_widget.back_btn = back_btn
    method_widget.results_panel = right_panel
    method_widget.category = category
    method_widget.method_key = method_key
    
    return method_widget


def create_results_panel(localize_func: Callable) -> QWidget:
    """
    Create results display panel with tabs for different result types.
    
    Args:
        localize_func: Localization function
    
    Returns:
        Results panel widget with tab_widget attribute
    """
    results_panel = QWidget()
    results_panel.setObjectName("resultsPanel")
    results_panel.setStyleSheet("""
        QWidget#resultsPanel {
            background-color: #ffffff;
            border-left: 1px solid #e0e0e0;
        }
    """)
    
    layout = QVBoxLayout(results_panel)
    layout.setContentsMargins(24, 24, 24, 24)
    layout.setSpacing(16)
    
    # Header with export buttons
    header_layout = QHBoxLayout()
    
    results_title = QLabel("ðŸ“Š " + localize_func("ANALYSIS_PAGE.results_title"))
    results_title.setStyleSheet("""
        font-size: 18px;
        font-weight: 600;
        color: #2c3e50;
    """)
    header_layout.addWidget(results_title)
    header_layout.addStretch()
    
    # Export CSV button (hidden until results available)
    # Note: Plot export (PNG/SVG) available via matplotlib toolbar right-click
    export_data_btn = QPushButton(localize_func("ANALYSIS_PAGE.export_csv"))
    export_data_btn.setObjectName("exportButton")
    export_data_btn.setMinimumHeight(32)
    export_data_btn.setVisible(False)
    header_layout.addWidget(export_data_btn)
    
    layout.addLayout(header_layout)
    
    # Tab widget for different result views
    tab_widget = QTabWidget()
    tab_widget.setObjectName("resultsTabWidget")
    tab_widget.setStyleSheet("""
        QTabWidget::pane {
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            background-color: white;
        }
        QTabBar::tab {
            background-color: #f8f9fa;
            border: 1px solid #e0e0e0;
            padding: 8px 16px;
            margin-right: 2px;
        }
        QTabBar::tab:selected {
            background-color: white;
            border-bottom-color: white;
            font-weight: 600;
        }
        QTabBar::tab:hover {
            background-color: #e7f3ff;
        }
    """)
    
    # Placeholder tabs (will be populated with actual results)
    placeholder_label = QLabel(localize_func("ANALYSIS_PAGE.no_results_yet"))
    placeholder_label.setAlignment(Qt.AlignCenter)
    placeholder_label.setStyleSheet("""
        font-size: 14px;
        color: #6c757d;
        padding: 40px;
    """)
    tab_widget.addTab(placeholder_label, localize_func("ANALYSIS_PAGE.results_tab"))
    
    layout.addWidget(tab_widget)
    
    # Store references for external access
    results_panel.tab_widget = tab_widget
    results_panel.export_data_btn = export_data_btn
    results_panel.results_title = results_title
    
    return results_panel


def populate_results_tabs(
    results_panel: QWidget,
    result: Any,
    localize_func: Callable,
    matplotlib_widget_class: type
) -> None:
    """
    Populate results tabs with analysis output.
    
    Args:
        results_panel: Results panel widget from create_results_panel
        result: AnalysisResult object
        localize_func: Localization function
        matplotlib_widget_class: MatplotlibWidget class for plot rendering
    """
    tab_widget = results_panel.tab_widget
    
    # Clear existing tabs
    while tab_widget.count() > 0:
        tab_widget.removeTab(0)
    
    # Show CSV export button (plot export via matplotlib toolbar)
    results_panel.export_data_btn.setVisible(True)
    
    # === Special handling for PCA Analysis: Create 5-tab visualization ===
    is_pca = hasattr(result, "raw_results") and "pca_model" in result.raw_results
    
    if is_pca:
        print("[DEBUG] PCA Analysis detected - creating 5-tab visualization")
        
        # Extract figures from raw_results
        scree_figure = result.raw_results.get("scree_figure")
        loadings_figure = result.raw_results.get("loadings_figure")
        biplot_figure = result.raw_results.get("biplot_figure")
        cumulative_variance_figure = result.raw_results.get("cumulative_variance_figure")
        distributions_figure = result.raw_results.get("distributions_figure")
        
        print(f"[DEBUG] PCA figures found:")
        print(f"[DEBUG]   scree_figure: {scree_figure is not None}")
        print(f"[DEBUG]   loadings_figure: {loadings_figure is not None}")
        print(f"[DEBUG]   biplot_figure: {biplot_figure is not None}")
        print(f"[DEBUG]   cumulative_variance_figure: {cumulative_variance_figure is not None}")
        print(f"[DEBUG]   distributions_figure: {distributions_figure is not None}")
        
        # Tab 1: Score Plot (PC1 vs PC2)
        if result.primary_figure:
            score_tab = matplotlib_widget_class()
            score_tab.update_plot(result.primary_figure)
            score_tab.setMinimumHeight(400)
            tab_widget.addTab(score_tab, "ðŸ“ˆ Score Plot")
        
        # Tab 2: Scree Plot
        if scree_figure:
            scree_tab = matplotlib_widget_class()
            scree_tab.update_plot(scree_figure)
            scree_tab.setMinimumHeight(400)
            tab_widget.addTab(scree_tab, "ðŸ“Š Scree Plot")
        
        # Tab 3: Loading Plot
        if loadings_figure:
            loading_tab = matplotlib_widget_class()
            loading_tab.update_plot(loadings_figure)
            loading_tab.setMinimumHeight(400)
            tab_widget.addTab(loading_tab, "ðŸ”¬ Loading Plot")
        
        # Tab 4: Biplot
        if biplot_figure:
            biplot_tab = matplotlib_widget_class()
            biplot_tab.update_plot(biplot_figure)
            biplot_tab.setMinimumHeight(400)
            tab_widget.addTab(biplot_tab, "ðŸŽ¯ Biplot")
        
        # Tab 5: Cumulative Variance
        if cumulative_variance_figure:
            cumvar_tab = matplotlib_widget_class()
            cumvar_tab.update_plot(cumulative_variance_figure)
            cumvar_tab.setMinimumHeight(400)
            tab_widget.addTab(cumvar_tab, "ðŸ“ˆ Cumulative Variance")
        
        # Bonus: Distributions (if available)
        if distributions_figure:
            dist_tab = matplotlib_widget_class()
            dist_tab.update_plot(distributions_figure)
            dist_tab.setMinimumHeight(400)
            tab_widget.addTab(dist_tab, "ðŸ“Š Distributions")
    
    else:
        # === Standard analysis results (non-PCA) ===
        
        # === Main Plot Tab (Scores/Primary Figure) ===
        if result.primary_figure:
            plot_tab = matplotlib_widget_class()
            plot_tab.update_plot(result.primary_figure)
            plot_tab.setMinimumHeight(400)
            tab_widget.addTab(plot_tab, "ðŸ“ˆ " + localize_func("ANALYSIS_PAGE.scores_tab") if hasattr(result, "loadings_figure") else localize_func("ANALYSIS_PAGE.plot_tab"))
        
        # === Loadings Tab (for dimensionality reduction) ===
        print(f"[DEBUG] Checking loadings_figure...")
        print(f"[DEBUG]   hasattr(result, 'loadings_figure'): {hasattr(result, 'loadings_figure')}")
        if hasattr(result, 'loadings_figure'):
            print(f"[DEBUG]   result.loadings_figure is not None: {result.loadings_figure is not None}")
            print(f"[DEBUG]   result.loadings_figure type: {type(result.loadings_figure)}")
        
        if hasattr(result, "loadings_figure") and result.loadings_figure:
            print(f"[DEBUG] Creating Loadings tab...")
            loadings_tab = matplotlib_widget_class()
            loadings_tab.update_plot(result.loadings_figure)
            loadings_tab.setMinimumHeight(400)
            tab_widget.addTab(loadings_tab, "ðŸ”¬ " + localize_func("ANALYSIS_PAGE.loadings_tab"))
            print(f"[DEBUG] Loadings tab added successfully")
        else:
            print(f"[DEBUG] Loadings tab NOT created (figure missing or None)")
        
        # === Distributions Tab (for classification) ===
        if hasattr(result, "distributions_figure") and result.distributions_figure:
            dist_tab = matplotlib_widget_class()
            dist_tab.update_plot(result.distributions_figure)
            dist_tab.setMinimumHeight(400)
            tab_widget.addTab(dist_tab, "ðŸ“Š " + localize_func("ANALYSIS_PAGE.distributions_tab"))
        
        # === Legacy Secondary Figure Tab (deprecated but kept for compatibility) ===
        if hasattr(result, "secondary_figure") and result.secondary_figure:
            secondary_tab = matplotlib_widget_class()
            secondary_tab.update_plot(result.secondary_figure)
            secondary_tab.setMinimumHeight(400)
            tab_widget.addTab(secondary_tab, "ðŸ“Š " + localize_func("ANALYSIS_PAGE.secondary_plot_tab"))
    
    # === Data Table Tab ===
    if result.data_table is not None:
        table_tab = create_data_table_tab(result.data_table)
        tab_widget.addTab(table_tab, "ðŸ“‹ " + localize_func("ANALYSIS_PAGE.data_tab"))
    
    # === Summary Tab ===
    if result.detailed_summary:
        summary_tab = create_summary_tab(result.detailed_summary)
        tab_widget.addTab(summary_tab, "ðŸ“‹ " + localize_func("ANALYSIS_PAGE.summary_tab"))
    
    # === Diagnostics Tab (if available) ===
    if hasattr(result, "diagnostics") and result.diagnostics:
        diag_tab = create_summary_tab(result.diagnostics)
        tab_widget.addTab(diag_tab, "ðŸ” " + localize_func("ANALYSIS_PAGE.diagnostics_tab"))


def create_data_table_tab(data_table) -> QWidget:
    """
    Create data table tab from pandas DataFrame or dict.
    
    Args:
        data_table: DataFrame or dict containing tabular data
    
    Returns:
        Table widget
    """
    table_widget = QTableWidget()
    table_widget.setStyleSheet("""
        QTableWidget {
            border: none;
            gridline-color: #e0e0e0;
            background-color: white;
        }
        QHeaderView::section {
            background-color: #f8f9fa;
            padding: 8px;
            border: none;
            border-bottom: 2px solid #e0e0e0;
            font-weight: 600;
        }
        QTableWidget::item {
            padding: 6px;
        }
    """)
    
    # Convert to DataFrame if dict
    import pandas as pd
    if isinstance(data_table, dict):
        df = pd.DataFrame(data_table)
    else:
        df = data_table
    
    # Populate table
    table_widget.setRowCount(len(df))
    table_widget.setColumnCount(len(df.columns))
    table_widget.setHorizontalHeaderLabels([str(col) for col in df.columns])
    
    for i, row in df.iterrows():
        for j, value in enumerate(row):
            item = QTableWidgetItem(str(value))
            table_widget.setItem(i, j, item)
    
    table_widget.resizeColumnsToContents()
    return table_widget


def create_summary_tab(summary_text: str) -> QWidget:
    """
    Create summary/diagnostics text tab.
    
    Args:
        summary_text: Summary text content
    
    Returns:
        Text display widget
    """
    text_edit = QTextEdit()
    text_edit.setReadOnly(True)
    text_edit.setPlainText(summary_text)
    text_edit.setStyleSheet("""
        QTextEdit {
            border: none;
            background-color: white;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 12px;
            padding: 12px;
        }
    """)
    return text_edit


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\export_utils.py ##

"""
Export Utilities for Analysis Results

This module handles exporting analysis results to various formats:
- PNG/SVG image export
- CSV data export
- Full report generation
- Project folder integration
"""

import os
from datetime import datetime
from typing import Optional, Any
from pathlib import Path

from PySide6.QtWidgets import QFileDialog, QMessageBox
from PySide6.QtCore import QObject


class ExportManager(QObject):
    """Manages export operations for analysis results."""
    
    def __init__(self, parent_widget, localize_func, project_manager):
        """
        Initialize export manager.
        
        Args:
            parent_widget: Parent QWidget for dialogs
            localize_func: Localization function
            project_manager: ProjectManager instance
        """
        super().__init__(parent_widget)
        self.parent = parent_widget
        self.localize = localize_func
        self.project_manager = project_manager
    
    def export_plot_png(self, figure, default_filename: str = "analysis_plot.png") -> bool:
        """
        Export matplotlib figure to PNG.
        
        Args:
            figure: Matplotlib figure object
            default_filename: Default filename
        
        Returns:
            True if export succeeded
        """
        if figure is None:
            self._show_error(self.localize("ANALYSIS_PAGE.no_plot_to_export"))
            return False
        
        # Get save path
        file_path, _ = QFileDialog.getSaveFileName(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_png_title"),
            self._get_default_export_path(default_filename),
            "PNG Images (*.png);;All Files (*.*)"
        )
        
        if not file_path:
            return False
        
        try:
            figure.savefig(file_path, dpi=300, bbox_inches='tight', format='png')
            self._show_success(
                self.localize("ANALYSIS_PAGE.export_success").format(file_path)
            )
            return True
        except Exception as e:
            self._show_error(
                self.localize("ANALYSIS_PAGE.export_error").format(str(e))
            )
            return False
    
    def export_plot_svg(self, figure, default_filename: str = "analysis_plot.svg") -> bool:
        """
        Export matplotlib figure to SVG.
        
        Args:
            figure: Matplotlib figure object
            default_filename: Default filename
        
        Returns:
            True if export succeeded
        """
        if figure is None:
            self._show_error(self.localize("ANALYSIS_PAGE.no_plot_to_export"))
            return False
        
        file_path, _ = QFileDialog.getSaveFileName(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_svg_title"),
            self._get_default_export_path(default_filename),
            "SVG Images (*.svg);;All Files (*.*)"
        )
        
        if not file_path:
            return False
        
        try:
            figure.savefig(file_path, format='svg', bbox_inches='tight')
            self._show_success(
                self.localize("ANALYSIS_PAGE.export_success").format(file_path)
            )
            return True
        except Exception as e:
            self._show_error(
                self.localize("ANALYSIS_PAGE.export_error").format(str(e))
            )
            return False
    
    def export_data_csv(self, data_table, default_filename: str = "analysis_data.csv") -> bool:
        """
        Export data table to CSV.
        
        Args:
            data_table: Pandas DataFrame or dict
            default_filename: Default filename
        
        Returns:
            True if export succeeded
        """
        if data_table is None:
            self._show_error(self.localize("ANALYSIS_PAGE.no_data_to_export"))
            return False
        
        file_path, _ = QFileDialog.getSaveFileName(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_csv_title"),
            self._get_default_export_path(default_filename),
            "CSV Files (*.csv);;All Files (*.*)"
        )
        
        if not file_path:
            return False
        
        try:
            import pandas as pd
            
            # Convert to DataFrame if dict
            if isinstance(data_table, dict):
                df = pd.DataFrame(data_table)
            else:
                df = data_table
            
            df.to_csv(file_path, index=False)
            self._show_success(
                self.localize("ANALYSIS_PAGE.export_success").format(file_path)
            )
            return True
        except Exception as e:
            self._show_error(
                self.localize("ANALYSIS_PAGE.export_error").format(str(e))
            )
            return False
    
    def export_full_report(
        self, 
        result: Any, 
        method_name: str,
        parameters: dict,
        dataset_name: str
    ) -> bool:
        """
        Export complete analysis report with all components.
        
        Args:
            result: AnalysisResult object
            method_name: Analysis method name
            parameters: Analysis parameters used
            dataset_name: Dataset name
        
        Returns:
            True if export succeeded
        """
        folder_path = QFileDialog.getExistingDirectory(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_report_title"),
            self._get_default_export_path("")
        )
        
        if not folder_path:
            return False
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_folder = Path(folder_path) / f"{method_name}_{timestamp}"
            report_folder.mkdir(parents=True, exist_ok=True)
            
            # Export plot
            if result.primary_figure:
                plot_path = report_folder / "plot.png"
                result.primary_figure.savefig(plot_path, dpi=300, bbox_inches='tight')
            
            # Export data table
            if result.data_table is not None:
                import pandas as pd
                df = pd.DataFrame(result.data_table) if isinstance(result.data_table, dict) else result.data_table
                data_path = report_folder / "data.csv"
                df.to_csv(data_path, index=False)
            
            # Create report text file
            report_path = report_folder / "report.txt"
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"Analysis Report: {method_name}\n")
                f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Dataset: {dataset_name}\n")
                f.write("\n" + "="*60 + "\n\n")
                
                f.write("Parameters:\n")
                for key, value in parameters.items():
                    f.write(f"  {key}: {value}\n")
                f.write("\n" + "="*60 + "\n\n")
                
                if result.detailed_summary:
                    f.write("Summary:\n")
                    f.write(result.detailed_summary)
                    f.write("\n" + "="*60 + "\n")
                
                if hasattr(result, 'diagnostics') and result.diagnostics:
                    f.write("Diagnostics:\n")
                    f.write(result.diagnostics)
            
            self._show_success(
                self.localize("ANALYSIS_PAGE.export_report_success").format(str(report_folder))
            )
            return True
            
        except Exception as e:
            self._show_error(
                self.localize("ANALYSIS_PAGE.export_error").format(str(e))
            )
            return False
    
    def save_to_project(
        self,
        result: Any,
        method_name: str,
        parameters: dict,
        dataset_name: str
    ) -> bool:
        """
        Save analysis results to current project folder.
        
        Args:
            result: AnalysisResult object
            method_name: Analysis method name
            parameters: Analysis parameters
            dataset_name: Dataset name
        
        Returns:
            True if save succeeded
        """
        if not self.project_manager or not self.project_manager.current_project_data:
            self._show_error(self.localize("ANALYSIS_PAGE.no_project_open"))
            return False
        
        try:
            # Get project path from current_project_data dict
            project_path = Path(self.project_manager.current_project_data.get("projectPath", ""))
            if not project_path or not project_path.exists():
                self._show_error(self.localize("ANALYSIS_PAGE.invalid_project_path"))
                return False
            analysis_folder = project_path / "analyses"
            analysis_folder.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_folder = analysis_folder / f"{method_name}_{timestamp}"
            result_folder.mkdir(parents=True, exist_ok=True)
            
            # Save plot
            if result.primary_figure:
                plot_path = result_folder / "plot.png"
                result.primary_figure.savefig(plot_path, dpi=300, bbox_inches='tight')
            
            # Save data
            if result.data_table is not None:
                import pandas as pd
                df = pd.DataFrame(result.data_table) if isinstance(result.data_table, dict) else result.data_table
                df.to_csv(result_folder / "data.csv", index=False)
            
            # Save metadata
            import json
            metadata = {
                "method": method_name,
                "dataset": dataset_name,
                "parameters": parameters,
                "timestamp": timestamp,
                "summary": result.detailed_summary if result.detailed_summary else ""
            }
            with open(result_folder / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            self._show_success(
                self.localize("ANALYSIS_PAGE.save_project_success").format(str(result_folder))
            )
            return True
            
        except Exception as e:
            self._show_error(
                self.localize("ANALYSIS_PAGE.save_project_error").format(str(e))
            )
            return False
    
    def _get_default_export_path(self, filename: str) -> str:
        """
        Get default export path (project folder if available, else home).
        
        Args:
            filename: Default filename
        
        Returns:
            Full path string
        """
        if self.project_manager and self.project_manager.current_project_data:
            # Get project path from current_project_data dict
            project_path_str = self.project_manager.current_project_data.get("projectPath", "")
            if project_path_str:
                project_path = Path(project_path_str)
                export_folder = project_path / "exports"
                export_folder.mkdir(exist_ok=True)
                return str(export_folder / filename)
        
        # Fallback to home directory
        return str(Path.home() / filename)
    
    def _show_success(self, message: str):
        """Show success message box."""
        QMessageBox.information(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_success_title"),
            message
        )
    
    def _show_error(self, message: str):
        """Show error message box."""
        QMessageBox.critical(
            self.parent,
            self.localize("ANALYSIS_PAGE.export_error_title"),
            message
        )


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\group_assignment_table.py ##

"""
Professional Group Assignment Widget for Raman Spectroscopy Classification

This module implements a table-based group assignment interface specifically
designed for scientists performing classification tasks (e.g., MM vs MGUS).

Key Features:
- Table widget with [Dataset Name | Group Label] columns
- Dropdown selectors for group labels with custom entries
- Pattern-based auto-assignment (e.g., "Control_01" â†’ "Control")
- Simple, intuitive workflow without mental mapping overhead
"""

from typing import Dict, List, Callable, Optional
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QTableWidget, QTableWidgetItem, QComboBox, QHeaderView,
    QMessageBox, QLineEdit, QDialog, QDialogButtonBox
)
from PySide6.QtCore import Qt, Signal
from PySide6.QtGui import QFont
import re


class GroupAssignmentTable(QWidget):
    """
    Professional table-based group assignment widget.
    
    Designed for scientists:
    - Clear visual representation of dataset â†’ group mapping
    - Dropdown selectors for common group names
    - Auto-assign feature using intelligent pattern matching
    - Minimal cognitive overhead
    
    Signals:
        groups_changed: Emitted when group assignments change {group_name: [datasets]}
    """
    
    groups_changed = Signal(dict)
    
    def __init__(self, dataset_names: List[str], localize_func: Callable, parent=None):
        """
        Initialize group assignment table.
        
        Args:
            dataset_names: List of available dataset names
            localize_func: Localization function
            parent: Parent widget
        """
        super().__init__(parent)
        print("[DEBUG] GroupAssignmentTable __init__ called")
        print(f"[DEBUG] Number of datasets: {len(dataset_names)}")
        print(f"[DEBUG] Dataset names: {dataset_names}")
        
        self.dataset_names = dataset_names
        self.localize_func = localize_func
        self.common_groups = ["Control", "Disease", "Treatment A", "Treatment B", "MM", "MGUS", "Normal"]
        
        print("[DEBUG] Calling _init_ui()")
        self._init_ui()
        print("[DEBUG] GroupAssignmentTable initialization complete")
    
    def _init_ui(self):
        """Initialize the user interface."""
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(12)
        
        # Instructions
        instructions = QLabel(
            "ðŸ’¡ <b>Classification Mode:</b> Assign each dataset to a group for comparison. "
            "Use the dropdown in each row or click 'Auto-Assign' to map by filename patterns."
        )
        instructions.setWordWrap(True)
        instructions.setStyleSheet("""
            padding: 12px;
            background-color: #f0f8ff;
            border-left: 4px solid #0078d4;
            border-radius: 4px;
            font-size: 12px;
        """)
        main_layout.addWidget(instructions)
        
        # Action toolbar - modern toolbar design
        from PySide6.QtWidgets import QToolBar, QWidget as QW
        
        toolbar = QToolBar()
        toolbar.setMovable(False)
        toolbar.setStyleSheet("""
            QToolBar {
                background-color: #f8f9fa;
                border: 1px solid #dee2e6;
                border-radius: 4px;
                padding: 4px 8px;
                spacing: 8px;
            }
            QToolButton {
                background-color: transparent;
                border: 1px solid transparent;
                border-radius: 4px;
                padding: 6px 12px;
                font-weight: 600;
                font-size: 12px;
                color: #495057;
            }
            QToolButton:hover {
                background-color: #e9ecef;
                border-color: #dee2e6;
            }
            QToolButton:pressed {
                background-color: #dee2e6;
            }
        """)
        
        # Auto-assign action
        auto_assign_action = toolbar.addAction("ðŸ” Auto-Assign")
        auto_assign_action.setToolTip("Automatically assign groups based on filename patterns")
        auto_assign_action.triggered.connect(self._auto_assign_groups)
        
        # Reset action
        reset_action = toolbar.addAction("â†º Reset All")
        reset_action.setToolTip("Clear all group assignments")
        reset_action.triggered.connect(self._reset_all)
        
        toolbar.addSeparator()
        
        # Add custom group action
        custom_group_action = toolbar.addAction("âž• Create Group")
        custom_group_action.setToolTip("Create a custom group label")
        custom_group_action.triggered.connect(self._add_custom_group)
        
        main_layout.addWidget(toolbar)
        
        # Table widget
        self.table = QTableWidget()
        self.table.setColumnCount(2)
        self.table.setHorizontalHeaderLabels(["Dataset Name", "Group Label"])
        self.table.setRowCount(len(self.dataset_names))
        
        # Professional table styling with comfortable spacing and minimal gridlines
        self.table.setStyleSheet("""
            QTableWidget {
                border: 1px solid #dee2e6;
                border-radius: 6px;
                background-color: white;
                gridline-color: transparent;
                font-size: 13px;
            }
            QTableWidget::item {
                padding: 16px 12px;
                border-bottom: 1px solid #f1f3f5;
            }
            QTableWidget::item:hover {
                background-color: #f8f9fa;
            }
            QTableWidget::item:selected {
                background-color: #e7f3ff;
                color: #212529;
            }
            QHeaderView::section {
                background-color: #f8f9fa;
                padding: 14px 12px;
                border: none;
                border-bottom: 2px solid #dee2e6;
                font-weight: 700;
                font-size: 12px;
                color: #495057;
                text-transform: uppercase;
                letter-spacing: 0.5px;
            }
        """)
        
        # Configure columns
        header = self.table.horizontalHeader()
        header.setSectionResizeMode(0, QHeaderView.Stretch)
        header.setSectionResizeMode(1, QHeaderView.Fixed)
        self.table.setColumnWidth(1, 200)
        
        # Populate table
        print(f"[DEBUG] Populating table with {len(self.dataset_names)} datasets")
        for row, dataset_name in enumerate(self.dataset_names):
            print(f"[DEBUG] Adding dataset {row+1}/{len(self.dataset_names)}: {dataset_name}")
            # Dataset name (read-only)
            name_item = QTableWidgetItem(dataset_name)
            name_item.setFlags(name_item.flags() & ~Qt.ItemIsEditable)
            name_item.setFont(QFont("Segoe UI", 10))
            self.table.setItem(row, 0, name_item)
            
            # Group selector (dropdown)
            group_combo = QComboBox()
            group_combo.addItem("-- Select Group --")
            group_combo.addItems(self.common_groups)
            group_combo.addItem("+ Add Custom Group...")
            
            # Set larger font for better visibility
            combo_font = QFont("Segoe UI", 11)
            combo_font.setWeight(QFont.Medium)
            group_combo.setFont(combo_font)
            
            group_combo.setStyleSheet("""
                QComboBox {
                    border: 1px solid #d0d0d0;
                    border-radius: 3px;
                    padding: 8px 12px;
                    padding-right: 25px;
                    background-color: white;
                    color: #2c3e50;
                    font-size: 13px;
                    font-weight: 500;
                    min-height: 28px;
                }
                QComboBox:hover {
                    border-color: #0078d4;
                    background-color: #f8f9fa;
                }
                QComboBox:focus {
                    border-color: #0078d4;
                    border-width: 2px;
                }
                QComboBox::drop-down {
                    subcontrol-origin: padding;
                    subcontrol-position: right center;
                    width: 20px;
                    border: none;
                }
                QComboBox::down-arrow {
                    image: none;
                    border-left: 5px solid transparent;
                    border-right: 5px solid transparent;
                    border-top: 6px solid #6c757d;
                    width: 0;
                    height: 0;
                }
                QComboBox QAbstractItemView {
                    background-color: white;
                    border: 1px solid #d0d0d0;
                    selection-background-color: #0078d4;
                    selection-color: white;
                    padding: 4px;
                    font-size: 13px;
                }
                QComboBox QAbstractItemView::item {
                    padding: 8px 12px;
                    min-height: 28px;
                }
                QComboBox QAbstractItemView::item:hover {
                    background-color: #e7f3ff;
                }
            """)
            group_combo.currentTextChanged.connect(
                lambda text, r=row: self._on_group_changed(r, text)
            )
            
            print(f"[DEBUG] Created group combo for row {row} with font size 11")
            self.table.setCellWidget(row, 1, group_combo)
        
        main_layout.addWidget(self.table)
        
        # Summary label
        self.summary_label = QLabel()
        self.summary_label.setStyleSheet("""
            font-size: 11px;
            color: #6c757d;
            padding: 8px;
            background-color: #f8f9fa;
            border-radius: 3px;
        """)
        self._update_summary()
        main_layout.addWidget(self.summary_label)
    
    def _on_group_changed(self, row: int, text: str):
        """Handle group selection change."""
        if text == "+ Add Custom Group...":
            # Show custom group dialog
            custom_group = self._prompt_custom_group()
            combo = self.table.cellWidget(row, 1)
            if custom_group:
                # Add to common groups if not already there
                if custom_group not in self.common_groups:
                    self.common_groups.append(custom_group)
                    # Update all combos
                    for r in range(self.table.rowCount()):
                        cb = self.table.cellWidget(r, 1)
                        if cb.findText(custom_group) == -1:
                            cb.insertItem(cb.count() - 1, custom_group)
                # Set the new group
                combo.setCurrentText(custom_group)
            else:
                # User cancelled, reset to first item
                combo.setCurrentIndex(0)
        
        self._update_summary()
        self.groups_changed.emit(self.get_groups())
    
    def _prompt_custom_group(self) -> Optional[str]:
        """Prompt user to enter a custom group name."""
        dialog = QDialog(self)
        dialog.setWindowTitle("Add Custom Group")
        dialog.setMinimumWidth(300)
        
        layout = QVBoxLayout(dialog)
        
        label = QLabel("Enter custom group name:")
        layout.addWidget(label)
        
        input_field = QLineEdit()
        input_field.setPlaceholderText("e.g., Treatment C, Benign, Stage 1...")
        layout.addWidget(input_field)
        
        buttons = QDialogButtonBox(
            QDialogButtonBox.Ok | QDialogButtonBox.Cancel
        )
        buttons.accepted.connect(dialog.accept)
        buttons.rejected.connect(dialog.reject)
        layout.addWidget(buttons)
        
        if dialog.exec() == QDialog.Accepted:
            group_name = input_field.text().strip()
            if group_name:
                return group_name
        
        return None
    
    def _auto_assign_groups(self):
        """
        Automatically assign groups based on dataset name patterns.
        
        Enhanced Algorithm:
        1. Try date prefix pattern (YYYYMMDD_*)
        2. Try keyword pattern (MM, MGUS, Control, etc.)
        3. Try underscore/hyphen prefix pattern (Prefix_*)
        4. Try mixed patterns with multiple segments
        """
        print("[DEBUG] Auto-assign groups called (enhanced version)")
        print(f"[DEBUG] Analyzing {len(self.dataset_names)} dataset names")
        
        # Pattern extraction with multiple strategies
        patterns = {}
        
        for idx, dataset_name in enumerate(self.dataset_names):
            print(f"[DEBUG] Analyzing pattern for: {dataset_name}")
            group_assigned = False
            
            # === Strategy 1: Date prefix pattern (YYYYMMDD_*) ===
            # Example: "20220314_MgusO1_B" â†’ extract "Mgus" or "MgusO1"
            date_match = re.match(r'^\d{8}_(.+)', dataset_name)
            if date_match:
                remainder = date_match.group(1)
                print(f"[DEBUG] Date prefix detected, remainder: {remainder}")
                
                # Extract alphanumeric prefix before next separator
                parts = re.split(r'[_\-\s]', remainder)
                if parts:
                    # Try to find keyword in first part
                    first_part = parts[0]
                    print(f"[DEBUG] First part after date: {first_part}")
                    
                    # Check for known keywords in first part
                    for keyword in ['MM', 'MGUS', 'Control', 'Disease', 'Treatment', 'Normal', 'Healthy', 'Cancer']:
                        if keyword.lower() in first_part.lower():
                            group_name = keyword.upper() if len(keyword) <= 4 else keyword.capitalize()
                            print(f"[DEBUG] Keyword '{keyword}' found in '{first_part}' â†’ Group '{group_name}'")
                            
                            if group_name not in patterns:
                                patterns[group_name] = []
                            patterns[group_name].append(idx)
                            group_assigned = True
                            break
                    
                    # If no keyword found, use first part as group (e.g., "MgusO1" â†’ "Mgus")
                    if not group_assigned:
                        # Extract alpha prefix from alphanumeric string
                        alpha_prefix = re.match(r'^([A-Za-z]+)', first_part)
                        if alpha_prefix:
                            group_name = alpha_prefix.group(1).capitalize()
                            print(f"[DEBUG] Using alpha prefix '{group_name}' from '{first_part}'")
                            
                            if group_name not in patterns:
                                patterns[group_name] = []
                            patterns[group_name].append(idx)
                            group_assigned = True
            
            # === Strategy 2: Direct keyword pattern (no date prefix) ===
            if not group_assigned:
                # Extract alphanumeric words
                words = re.findall(r'[A-Za-z]+', dataset_name)
                print(f"[DEBUG] Extracted words: {words}")
                
                # Look for common group keywords
                for word in words:
                    word_lower = word.lower()
                    if word_lower in ['control', 'disease', 'treatment', 'mm', 'mgus', 'normal', 'healthy', 'cancer']:
                        # Capitalize first letter
                        group_name = word.capitalize()
                        if word_lower in ['mm', 'mgus']:
                            group_name = word.upper()
                        
                        print(f"[DEBUG] Keyword match: '{word}' â†’ Group '{group_name}'")
                        
                        if group_name not in patterns:
                            patterns[group_name] = []
                        patterns[group_name].append(idx)
                        group_assigned = True
                        break
            
            # === Strategy 3: Prefix pattern (Prefix_* or Prefix-*) ===
            if not group_assigned:
                # Split by underscore or hyphen and use first segment
                prefix_match = re.match(r'^([A-Za-z]+)[\-_]', dataset_name)
                if prefix_match:
                    group_name = prefix_match.group(1).capitalize()
                    print(f"[DEBUG] Prefix pattern: '{dataset_name}' â†’ Group '{group_name}'")
                    
                    if group_name not in patterns:
                        patterns[group_name] = []
                    patterns[group_name].append(idx)
                    group_assigned = True
            
            # === Strategy 4: Fallback - use first alpha sequence ===
            if not group_assigned:
                alpha_match = re.match(r'^([A-Za-z]+)', dataset_name)
                if alpha_match:
                    group_name = alpha_match.group(1).capitalize()
                    print(f"[DEBUG] Fallback alpha pattern: '{dataset_name}' â†’ Group '{group_name}'")
                    
                    if group_name not in patterns:
                        patterns[group_name] = []
                    patterns[group_name].append(idx)
                    group_assigned = True
            
            if not group_assigned:
                print(f"[DEBUG] No pattern detected for '{dataset_name}'")
        
        # Apply assignments
        print(f"[DEBUG] Patterns found: {patterns}")
        if patterns:
            assigned_count = 0
            for group_name, indices in patterns.items():
                print(f"[DEBUG] Processing group '{group_name}' with {len(indices)} datasets")
                # Ensure group exists
                if group_name not in self.common_groups:
                    print(f"[DEBUG] Adding new group '{group_name}' to common groups")
                    self.common_groups.append(group_name)
                    # Add to all combos
                    for r in range(self.table.rowCount()):
                        cb = self.table.cellWidget(r, 1)
                        if cb.findText(group_name) == -1:
                            cb.insertItem(cb.count() - 1, group_name)
                
                # Assign to datasets
                for idx in indices:
                    combo = self.table.cellWidget(idx, 1)
                    combo.setCurrentText(group_name)
                    assigned_count += 1
            
            # Show detailed result message
            pattern_summary = "\n".join([f"â€¢ {name}: {len(indices)} dataset(s)" for name, indices in patterns.items()])
            QMessageBox.information(
                self,
                "Auto-Assign Complete",
                f"Successfully assigned {assigned_count} dataset(s) to {len(patterns)} group(s).\n\n"
                f"Groups detected:\n{pattern_summary}"
            )
        else:
            QMessageBox.warning(
                self,
                "No Patterns Found",
                "Could not detect common patterns in dataset names.\n\n"
                "Supported patterns:\n"
                "â€¢ Date prefix: '20220314_MgusO1_B' â†’ 'Mgus'\n"
                "â€¢ Keywords: 'MM_Sample1' â†’ 'MM'\n"
                "â€¢ Prefix: 'Control_01' â†’ 'Control'\n"
                "â€¢ Alpha prefix: 'Treatment-A-1' â†’ 'Treatment'\n\n"
                "Tip: Use clear naming conventions for automatic grouping."
            )
        
        self._update_summary()
        self.groups_changed.emit(self.get_groups())
    
    def _reset_all(self):
        """Reset all group assignments."""
        reply = QMessageBox.question(
            self,
            "Reset Assignments",
            "Clear all group assignments?",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            for row in range(self.table.rowCount()):
                combo = self.table.cellWidget(row, 1)
                combo.setCurrentIndex(0)  # "-- Select Group --"
            
            self._update_summary()
            self.groups_changed.emit(self.get_groups())
    
    def _add_custom_group(self):
        """Add a custom group label to all dropdowns."""
        from PySide6.QtWidgets import QInputDialog
        
        text, ok = QInputDialog.getText(
            self,
            "Create Custom Group",
            "Enter new group label:",
            text="Group"
        )
        
        if ok and text.strip():
            new_group = text.strip()
            
            # Add to all combo boxes if not already present
            for row in range(self.table.rowCount()):
                combo = self.table.cellWidget(row, 1)
                # Check if already exists
                existing_items = [combo.itemText(i) for i in range(combo.count())]
                if new_group not in existing_items:
                    combo.addItem(new_group)
            
            QMessageBox.information(
                self,
                "Group Created",
                f"Custom group '{new_group}' has been added to all dropdowns."
            )
    
    def _update_summary(self):
        """Update the summary label."""
        groups = self.get_groups()
        
        if not groups:
            self.summary_label.setText("â„¹ï¸ No groups assigned yet. Use the dropdowns or 'Auto-Assign' button.")
        else:
            group_count = len(groups)
            total_datasets = sum(len(datasets) for datasets in groups.values())
            unassigned = len(self.dataset_names) - total_datasets
            
            summary = f"âœ“ {group_count} group(s) defined â€¢ {total_datasets} dataset(s) assigned"
            if unassigned > 0:
                summary += f" â€¢ {unassigned} unassigned"
            
            self.summary_label.setText(summary)
    
    def get_groups(self) -> Dict[str, List[str]]:
        """
        Get current group assignments.
        
        Returns:
            Dictionary mapping group labels to lists of dataset names
        """
        print("[DEBUG] get_groups() called")
        groups = {}
        
        for row in range(self.table.rowCount()):
            dataset_name = self.table.item(row, 0).text()
            combo = self.table.cellWidget(row, 1)
            group_name = combo.currentText()
            
            print(f"[DEBUG] Row {row}: Dataset='{dataset_name}', Group='{group_name}'")
            
            # Skip unassigned
            if group_name == "-- Select Group --" or group_name == "+ Add Custom Group...":
                continue
            
            if group_name not in groups:
                groups[group_name] = []
            
            groups[group_name].append(dataset_name)
        
        print(f"[DEBUG] Final groups: {groups}")
        return groups
    
    def set_groups(self, groups: Dict[str, List[str]]):
        """
        Set group assignments programmatically.
        
        Args:
            groups: Dictionary mapping group labels to dataset lists
        """
        # Reset all first
        for row in range(self.table.rowCount()):
            combo = self.table.cellWidget(row, 1)
            combo.setCurrentIndex(0)
        
        # Apply assignments
        for group_name, datasets in groups.items():
            # Ensure group exists
            if group_name not in self.common_groups:
                self.common_groups.append(group_name)
                # Add to all combos
                for r in range(self.table.rowCount()):
                    cb = self.table.cellWidget(r, 1)
                    if cb.findText(group_name) == -1:
                        cb.insertItem(cb.count() - 1, group_name)
            
            # Assign datasets
            for dataset_name in datasets:
                for row in range(self.table.rowCount()):
                    if self.table.item(row, 0).text() == dataset_name:
                        combo = self.table.cellWidget(row, 1)
                        combo.setCurrentText(group_name)
                        break
        
        self._update_summary()


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\group_widget.py ##

"""
Group Assignment Widget for Multi-Dataset Analysis

This module provides a flexible UI for assigning datasets to labeled groups.
Supports scenarios like:
- Single group with multiple datasets (e.g., analyzing "Control" with 5 replicates)
- Multiple groups (e.g., "MM" vs "MGUS" vs "NORMAL")
- Custom group labels for classification tasks
"""

from typing import Dict, List, Callable, Optional
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QLineEdit, QListWidget, QGroupBox, QAbstractItemView,
    QComboBox, QScrollArea, QFrame, QSplitter
)
from PySide6.QtCore import Qt, Signal
from PySide6.QtGui import QFont


class GroupAssignmentWidget(QWidget):
    """
    Widget for assigning datasets to labeled groups.
    
    Signals:
        groups_changed: Emitted when group assignments change
    """
    
    groups_changed = Signal(dict)  # {group_label: [dataset_names]}
    
    def __init__(self, dataset_names: List[str], localize_func: Callable, parent=None):
        """
        Initialize group assignment widget.
        
        Args:
            dataset_names: List of available dataset names
            localize_func: Localization function
            parent: Parent widget
        """
        super().__init__(parent)
        self.dataset_names = dataset_names
        self.localize_func = localize_func
        self.groups: Dict[str, List[str]] = {}  # {group_label: [dataset_names]}
        
        self._init_ui()
    
    def _init_ui(self):
        """Initialize the user interface."""
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(12)
        
        # Header with instructions
        header_label = QLabel(self.localize_func("ANALYSIS_PAGE.group_assignment_header"))
        header_label.setWordWrap(True)
        header_label.setStyleSheet("""
            font-size: 12px;
            color: #6c757d;
            padding: 8px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border-left: 3px solid #0078d4;
        """)
        main_layout.addWidget(header_label)
        
        # Splitter: Available Datasets | Group Configuration
        splitter = QSplitter(Qt.Horizontal)
        splitter.setChildrenCollapsible(False)
        
        # === LEFT: Available Datasets ===
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)
        left_layout.setContentsMargins(0, 0, 0, 0)
        
        available_label = QLabel(self.localize_func("ANALYSIS_PAGE.available_datasets"))
        available_label.setStyleSheet("font-weight: 600; font-size: 13px;")
        left_layout.addWidget(available_label)
        
        self.available_list = QListWidget()
        self.available_list.setSelectionMode(QAbstractItemView.MultiSelection)
        self.available_list.addItems(self.dataset_names)
        self.available_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #d0d0d0;
                border-radius: 4px;
                padding: 4px;
                background-color: white;
            }
            QListWidget::item {
                padding: 6px 8px;
                border-radius: 3px;
                margin: 1px;
            }
            QListWidget::item:hover {
                background-color: #f0f0f0;
            }
            QListWidget::item:selected {
                background-color: #0078d4;
                color: white;
            }
        """)
        left_layout.addWidget(self.available_list)
        
        splitter.addWidget(left_widget)
        
        # === RIGHT: Group Configuration ===
        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)
        right_layout.setContentsMargins(0, 0, 0, 0)
        
        groups_label = QLabel(self.localize_func("ANALYSIS_PAGE.groups"))
        groups_label.setStyleSheet("font-weight: 600; font-size: 13px;")
        right_layout.addWidget(groups_label)
        
        # Add group button and label input
        add_group_layout = QHBoxLayout()
        self.group_name_input = QLineEdit()
        self.group_name_input.setPlaceholderText(self.localize_func("ANALYSIS_PAGE.group_name_placeholder"))
        self.group_name_input.setMinimumHeight(32)
        self.group_name_input.setStyleSheet("""
            QLineEdit {
                border: 1px solid #d0d0d0;
                border-radius: 4px;
                padding: 4px 8px;
            }
            QLineEdit:focus {
                border-color: #0078d4;
            }
        """)
        add_group_layout.addWidget(self.group_name_input)
        
        add_group_btn = QPushButton(self.localize_func("ANALYSIS_PAGE.add_group"))
        add_group_btn.setMinimumHeight(32)
        add_group_btn.setStyleSheet("""
            QPushButton {
                background-color: #0078d4;
                color: white;
                border: none;
                border-radius: 4px;
                padding: 4px 16px;
                font-weight: 600;
            }
            QPushButton:hover {
                background-color: #005a9e;
            }
            QPushButton:pressed {
                background-color: #004578;
            }
        """)
        add_group_btn.clicked.connect(self._add_group)
        add_group_layout.addWidget(add_group_btn)
        
        right_layout.addLayout(add_group_layout)
        
        # Groups scroll area
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setFrameShape(QFrame.NoFrame)
        
        self.groups_container = QWidget()
        self.groups_layout = QVBoxLayout(self.groups_container)
        self.groups_layout.setContentsMargins(0, 0, 0, 0)
        self.groups_layout.setSpacing(8)
        self.groups_layout.addStretch()
        
        scroll_area.setWidget(self.groups_container)
        right_layout.addWidget(scroll_area)
        
        splitter.addWidget(right_widget)
        splitter.setSizes([300, 400])
        
        main_layout.addWidget(splitter)
        
        # Summary label
        self.summary_label = QLabel()
        self.summary_label.setStyleSheet("""
            font-size: 11px;
            color: #6c757d;
            padding: 6px;
            background-color: #f8f9fa;
            border-radius: 3px;
        """)
        self._update_summary()
        main_layout.addWidget(self.summary_label)
    
    def _add_group(self):
        """Add a new group with selected datasets."""
        group_name = self.group_name_input.text().strip()
        
        if not group_name:
            return
        
        if group_name in self.groups:
            # Group already exists, just add selected datasets
            pass
        
        # Get selected datasets
        selected_items = self.available_list.selectedItems()
        if not selected_items:
            return
        
        selected_datasets = [item.text() for item in selected_items]
        
        # Add or update group
        if group_name in self.groups:
            # Append new datasets (avoid duplicates)
            existing = set(self.groups[group_name])
            for ds in selected_datasets:
                if ds not in existing:
                    self.groups[group_name].append(ds)
        else:
            self.groups[group_name] = selected_datasets
            self._add_group_widget(group_name)
        
        # Clear selection and input
        self.available_list.clearSelection()
        self.group_name_input.clear()
        
        self._update_summary()
        self.groups_changed.emit(self.groups)
    
    def _add_group_widget(self, group_name: str):
        """Add a visual group widget to the UI."""
        group_box = QGroupBox(group_name)
        group_box.setObjectName(f"group_{group_name}")
        group_box.setStyleSheet("""
            QGroupBox {
                font-weight: 600;
                border: 2px solid #0078d4;
                border-radius: 6px;
                margin-top: 8px;
                padding-top: 16px;
                background-color: #f8f9fa;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 12px;
                padding: 0 8px;
                background-color: white;
            }
        """)
        
        group_layout = QVBoxLayout(group_box)
        
        # Dataset list for this group
        dataset_list = QListWidget()
        dataset_list.setMaximumHeight(100)
        dataset_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #d0d0d0;
                border-radius: 3px;
                background-color: white;
            }
            QListWidget::item {
                padding: 4px 6px;
            }
        """)
        group_layout.addWidget(dataset_list)
        
        # Remove button
        button_layout = QHBoxLayout()
        button_layout.addStretch()
        
        remove_btn = QPushButton(self.localize_func("ANALYSIS_PAGE.remove_group"))
        remove_btn.setStyleSheet("""
            QPushButton {
                background-color: #dc3545;
                color: white;
                border: none;
                border-radius: 3px;
                padding: 4px 12px;
                font-size: 11px;
            }
            QPushButton:hover {
                background-color: #c82333;
            }
        """)
        remove_btn.clicked.connect(lambda: self._remove_group(group_name))
        button_layout.addWidget(remove_btn)
        
        group_layout.addLayout(button_layout)
        
        # Insert before stretch
        self.groups_layout.insertWidget(self.groups_layout.count() - 1, group_box)
        
        # Update dataset list
        self._update_group_widget(group_name)
    
    def _update_group_widget(self, group_name: str):
        """Update the dataset list in a group widget."""
        group_box = self.groups_container.findChild(QGroupBox, f"group_{group_name}")
        if group_box:
            dataset_list = group_box.findChild(QListWidget)
            if dataset_list:
                dataset_list.clear()
                dataset_list.addItems(self.groups[group_name])
    
    def _remove_group(self, group_name: str):
        """Remove a group."""
        if group_name in self.groups:
            del self.groups[group_name]
        
        # Remove widget
        group_box = self.groups_container.findChild(QGroupBox, f"group_{group_name}")
        if group_box:
            self.groups_layout.removeWidget(group_box)
            group_box.deleteLater()
        
        self._update_summary()
        self.groups_changed.emit(self.groups)
    
    def _update_summary(self):
        """Update the summary label."""
        if not self.groups:
            summary_text = self.localize_func("ANALYSIS_PAGE.no_groups_defined")
        else:
            group_count = len(self.groups)
            total_datasets = sum(len(datasets) for datasets in self.groups.values())
            summary_text = self.localize_func(
                "ANALYSIS_PAGE.group_summary",
                group_count=group_count,
                dataset_count=total_datasets
            )
        
        self.summary_label.setText(summary_text)
    
    def get_groups(self) -> Dict[str, List[str]]:
        """
        Get the current group assignments.
        
        Returns:
            Dictionary mapping group labels to lists of dataset names
        """
        return self.groups.copy()
    
    def set_groups(self, groups: Dict[str, List[str]]):
        """
        Set group assignments programmatically.
        
        Args:
            groups: Dictionary mapping group labels to dataset lists
        """
        # Clear existing groups
        for group_name in list(self.groups.keys()):
            self._remove_group(group_name)
        
        # Add new groups
        self.groups = groups.copy()
        for group_name in self.groups:
            self._add_group_widget(group_name)
            self._update_group_widget(group_name)
        
        self._update_summary()
    
    def clear_groups(self):
        """Clear all group assignments."""
        self.set_groups({})


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\method_view.py ##

"""
Method View Components

This module handles the method-specific view with input forms and results display.
Includes dynamic parameter widget generation and results visualization.
"""

from typing import Dict, Any, Callable, Optional
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QFrame, QScrollArea, QTabWidget, QGroupBox, QComboBox,
    QSplitter, QTextEdit, QTableWidget, QTableWidgetItem, QListWidget,
    QAbstractItemView, QStackedWidget, QButtonGroup, QRadioButton, QCheckBox, QMessageBox
)
from PySide6.QtCore import Qt, QSize
from PySide6.QtGui import QFont

from components.widgets import load_icon, GroupTreeManager, DynamicParameterWidget

from .registry import ANALYSIS_METHODS
from .group_assignment_table import GroupAssignmentTable

# Import PROJECT_MANAGER for group persistence
from utils import PROJECT_MANAGER

# Import visualization helpers
from .methods.exploratory import create_spectrum_preview_figure
import matplotlib.pyplot as plt
import numpy as np


def _v1_create_method_view(
    category: str,
    method_key: str,
    dataset_names: list,
    localize_func: Callable,
    on_run_analysis: Callable,
    on_back: Callable
) -> QWidget:
    """
    Create method-specific view with input form and results display (Image 2 reference).
    
    Args:
        category: Method category
        method_key: Method identifier
        dataset_names: Available dataset names list (strings)
        localize_func: Localization function
        on_run_analysis: Callback when Run Analysis is clicked
        on_back: Callback for back button
    
    Returns:
        Method view widget with accessible components
    """
    method_info = ANALYSIS_METHODS[category][method_key]
    
    method_widget = QWidget()
    method_widget.setObjectName("methodView")
    
    main_layout = QVBoxLayout(method_widget)
    main_layout.setContentsMargins(0, 0, 0, 0)
    main_layout.setSpacing(0)
    
    # Splitter: Left (Input Form) | Right (Results)
    splitter = QSplitter(Qt.Horizontal)
    splitter.setChildrenCollapsible(False)
    
    # === LEFT PANEL: Input Form ===
    left_panel = QWidget()
    left_layout = QVBoxLayout(left_panel)
    left_layout.setContentsMargins(24, 24, 24, 24)
    left_layout.setSpacing(16)
    
    # Method header
    method_name_label = QLabel(method_info["name"])
    method_name_label.setStyleSheet("""
        font-size: 20px;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 8px;
    """)
    left_layout.addWidget(method_name_label)
    
    # Use localized description from locales, not hardcoded from registry
    method_desc_text = localize_func(f"ANALYSIS_PAGE.METHOD_DESC.{method_key}")
    method_desc_label = QLabel(method_desc_text)
    method_desc_label.setWordWrap(True)
    method_desc_label.setStyleSheet("""
        font-size: 13px;
        color: #6c757d;
        line-height: 1.5;
        margin-bottom: 16px;
    """)
    left_layout.addWidget(method_desc_label)
    
    # Dataset selection - conditional widget based on method requirements
    dataset_selection_mode = method_info.get("dataset_selection_mode", "single")
    min_datasets = method_info.get("min_datasets", 1)
    
    dataset_card = QFrame()
    dataset_card.setObjectName("datasetCard")
    dataset_card.setStyleSheet("""
        QFrame#datasetCard {
            background-color: #ffffff;
            border: 1px solid #dfe3ea;
            border-radius: 16px;
            padding: 0px;
        }
    """)
    dataset_card_layout = QVBoxLayout(dataset_card)
    dataset_card_layout.setContentsMargins(24, 24, 24, 24)
    dataset_card_layout.setSpacing(18)

    # Card header with icon + badges
    dataset_header = QHBoxLayout()
    dataset_header.setSpacing(12)

    dataset_title = QLabel("ðŸ“‚ " + localize_func("ANALYSIS_PAGE.dataset_selection"))
    dataset_title.setStyleSheet("""
        font-size: 18px;
        font-weight: 600;
        color: #1f2a37;
    """)
    dataset_header.addWidget(dataset_title)

    dataset_header.addStretch()

    selection_badge = QLabel(
        localize_func("ANALYSIS_PAGE.dataset_mode_multi")
        if dataset_selection_mode == "multi"
        else localize_func("ANALYSIS_PAGE.dataset_mode_single")
    )
    selection_badge.setStyleSheet("""
        background-color: #eef2ff;
        color: #4338ca;
        border-radius: 999px;
        padding: 4px 14px;
        font-size: 12px;
        font-weight: 600;
    """)
    dataset_header.addWidget(selection_badge)

    min_badge_text = localize_func("ANALYSIS_PAGE.min_datasets").format(count=min_datasets)
    min_badge = QLabel(min_badge_text)
    min_badge.setStyleSheet("""
        background-color: #ecfdf5;
        color: #047857;
        border-radius: 999px;
        padding: 4px 14px;
        font-size: 12px;
        font-weight: 600;
    """)
    dataset_header.addWidget(min_badge)

    dataset_card_layout.addLayout(dataset_header)

    dataset_subtitle = QLabel(localize_func("ANALYSIS_PAGE.dataset_selection_subtitle"))
    dataset_subtitle.setWordWrap(True)
    dataset_subtitle.setStyleSheet("""
        font-size: 13px;
        color: #4b5563;
        line-height: 1.5;
    """)
    dataset_card_layout.addWidget(dataset_subtitle)

    dataset_layout = QVBoxLayout()
    dataset_layout.setSpacing(16)
    dataset_layout.setContentsMargins(0, 0, 0, 0)
    dataset_card_layout.addLayout(dataset_layout)
    
    # For multi-dataset methods, add professional pill-shaped segmented control
    mode_toggle = None
    comparison_radio = None
    classification_radio = None
    
    if dataset_selection_mode == "multi":
        # Modern pill-shaped segmented control container
        toggle_frame = QFrame()
        toggle_frame.setStyleSheet("""
            QFrame {
                background-color: #e9ecef;
                border: 1px solid #dee2e6;
                border-radius: 25px;
                padding: 3px;
                max-width: 500px;
            }
        """)
        toggle_layout = QHBoxLayout(toggle_frame)
        toggle_layout.setContentsMargins(3, 3, 3, 3)
        toggle_layout.setSpacing(3)
        
        # Comparison mode button - pill shaped
        comparison_radio = QRadioButton("ðŸ“Š Unsupervised")
        comparison_radio.setObjectName("comparison_radio")
        comparison_radio.setChecked(True)
        comparison_radio.setCursor(Qt.PointingHandCursor)
        comparison_radio.setStyleSheet("""
            QRadioButton {
                background-color: transparent;
                border-radius: 22px;
                padding: 12px 32px;
                font-weight: 600;
                font-size: 14px;
                color: #495057;
            }
            QRadioButton:hover {
                background-color: rgba(0, 120, 212, 0.1);
            }
            QRadioButton:checked {
                background-color: #0078d4;
                color: white;
            }
            QRadioButton::indicator {
                width: 0px;
                height: 0px;
            }
        """)
        toggle_layout.addWidget(comparison_radio)
        
        # Classification mode button - pill shaped
        classification_radio = QRadioButton("ðŸ”¬ Grouped Classification")
        classification_radio.setObjectName("classification_radio")
        classification_radio.setCursor(Qt.PointingHandCursor)
        classification_radio.setStyleSheet("""
            QRadioButton {
                background-color: transparent;
                border-radius: 22px;
                padding: 12px 32px;
                font-weight: 600;
                font-size: 14px;
                color: #495057;
            }
            QRadioButton:hover {
                background-color: rgba(40, 167, 69, 0.1);
            }
            QRadioButton:checked {
                background-color: #28a745;
                color: white;
            }
            QRadioButton::indicator {
                width: 0px;
                height: 0px;
            }
        """)
        toggle_layout.addWidget(classification_radio)
        
        # Button group for mutual exclusion
        mode_toggle = QButtonGroup()
        mode_toggle.addButton(comparison_radio, 0)
        mode_toggle.addButton(classification_radio, 1)
        
        dataset_layout.addWidget(toggle_frame)
    
    # Create stacked widget for simple vs group mode
    dataset_stack = QStackedWidget()
    
    # === PAGE 0: Simple Selection (Comparison Mode) ===
    simple_widget = QWidget()
    simple_layout = QVBoxLayout(simple_widget)
    simple_layout.setContentsMargins(0, 0, 0, 0)
    
    # Add professional hint label
    if dataset_selection_mode == "multi":
        hint_label = QLabel("ðŸ’¡ <b>Unsupervised Mode:</b> Select multiple datasets for combined analysis. Click checkboxes or use 'Select All' below.")
        hint_label.setWordWrap(True)
        hint_label.setStyleSheet("""
            font-size: 12px;
            color: #495057;
            padding: 12px;
            background-color: #e7f3ff;
            border-left: 4px solid #0078d4;
            border-radius: 4px;
            margin-top: 8px;
        """)
        simple_layout.addWidget(hint_label)
    
    # Create appropriate widget based on selection mode
    dataset_widget = None
    select_all_checkbox = None
    
    if dataset_selection_mode == "single":
        # Single dropdown for single-dataset methods
        dataset_combo = QComboBox()
        dataset_combo.setObjectName("datasetComboBox")
        dataset_combo.setMinimumHeight(36)
        dataset_combo.addItems(dataset_names)
        dataset_combo.setStyleSheet("""
            QComboBox {
                border: 1px solid #d0d0d0;
                border-radius: 4px;
                padding: 6px 12px;
                background-color: white;
                font-size: 13px;
            }
            QComboBox:hover {
                border-color: #0078d4;
            }
            QComboBox::drop-down {
                border: none;
                width: 24px;
            }
            QComboBox::down-arrow {
                image: url(none);
                border-left: 5px solid transparent;
                border-right: 5px solid transparent;
                border-top: 5px solid #6c757d;
                width: 0;
                height: 0;
            }
        """)
        dataset_widget = dataset_combo
        simple_layout.addWidget(dataset_combo)
    else:
        # Create toolbar with Select All checkbox
        from PySide6.QtWidgets import QCheckBox
        toolbar_layout = QHBoxLayout()
        toolbar_layout.setContentsMargins(8, 8, 8, 4)
        
        select_all_checkbox = QCheckBox("Select All")
        select_all_checkbox.setObjectName("selectAllCheckbox")
        select_all_checkbox.setStyleSheet("""
            QCheckBox {
                font-weight: 600;
                font-size: 13px;
                color: #495057;
                spacing: 8px;
            }
            QCheckBox::indicator {
                width: 18px;
                height: 18px;
                border: 2px solid #adb5bd;
                border-radius: 3px;
                background-color: white;
            }
            QCheckBox::indicator:hover {
                border-color: #0078d4;
            }
            QCheckBox::indicator:checked {
                background-color: #0078d4;
                border-color: #0078d4;
                image: url(none);
            }
            QCheckBox::indicator:checked:after {
                content: "âœ“";
                color: white;
            }
        """)
        toolbar_layout.addWidget(select_all_checkbox)
        toolbar_layout.addStretch()
        simple_layout.addLayout(toolbar_layout)
        
        # Enhanced list with larger rows and hover effects
        dataset_list = QListWidget()
        dataset_list.setObjectName("datasetListWidget")
        dataset_list.setSelectionMode(QAbstractItemView.MultiSelection)
        dataset_list.setMinimumHeight(180)
        dataset_list.setMaximumHeight(300)
        dataset_list.addItems(dataset_names)
        dataset_list.setSpacing(2)
        dataset_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #dee2e6;
                border-radius: 4px;
                padding: 6px;
                background-color: white;
            }
            QListWidget::item {
                padding: 12px 16px;
                border-radius: 4px;
                margin: 1px 0;
                border: 1px solid transparent;
                font-size: 13px;
            }
            QListWidget::item:hover {
                background-color: #f8f9fa;
                border-color: #e9ecef;
            }
            QListWidget::item:selected {
                background-color: #e7f3ff;
                color: #0078d4;
                border-left: 3px solid #0078d4;
                font-weight: 600;
            }
        """)
        
        # Connect Select All functionality
        def toggle_select_all(checked):
            if checked:
                dataset_list.selectAll()
            else:
                dataset_list.clearSelection()
        
        select_all_checkbox.toggled.connect(toggle_select_all)
        
        # Update Select All state when list selection changes
        def update_select_all_state():
            total = dataset_list.count()
            selected = len(dataset_list.selectedItems())
            select_all_checkbox.blockSignals(True)
            select_all_checkbox.setChecked(selected == total and total > 0)
            select_all_checkbox.blockSignals(False)
        
        dataset_list.itemSelectionChanged.connect(update_select_all_state)
        
        dataset_widget = dataset_list
        simple_layout.addWidget(dataset_list)
    
    dataset_stack.addWidget(simple_widget)
    
    # === PAGE 1: Group Assignment (Classification Mode) ===
    group_widget = None
    if dataset_selection_mode == "multi":
        group_widget = GroupAssignmentTable(dataset_names, localize_func)
        group_widget.setMinimumHeight(400)
        dataset_stack.addWidget(group_widget)
        
        # Load saved groups from ProjectManager
        saved_groups = PROJECT_MANAGER.get_analysis_groups()
        if saved_groups:
            print(f"[DEBUG] Loading {len(saved_groups)} saved groups from project")
            group_widget.set_groups(saved_groups)
        else:
            print("[DEBUG] No saved groups found in project")
        
        # Connect groups_changed signal to save groups to ProjectManager
        def on_groups_changed(groups: Dict[str, list]):
            print(f"[DEBUG] Groups changed, saving {len(groups)} groups to ProjectManager")
            PROJECT_MANAGER.set_analysis_groups(groups)
        
        group_widget.groups_changed.connect(on_groups_changed)
        
        # Connect mode toggle to switch between modes
        def toggle_mode(button):
            print("[DEBUG] toggle_mode called")
            print(f"[DEBUG] Button clicked: {button}")
            print(f"[DEBUG] Button objectName: {button.objectName()}")
            print(f"[DEBUG] comparison_radio: {comparison_radio}")
            print(f"[DEBUG] classification_radio: {classification_radio}")
            print(f"[DEBUG] Current stack index BEFORE: {dataset_stack.currentIndex()}")
            
            # Check which button was clicked and switch pages
            if button == comparison_radio:
                print("[DEBUG] Switching to Comparison Mode (page 0)")
                dataset_stack.setCurrentIndex(0)  # Show simple selection
                print(f"[DEBUG] Stack index AFTER: {dataset_stack.currentIndex()}")
            elif button == classification_radio:
                print("[DEBUG] Switching to Classification Mode (page 1)")
                dataset_stack.setCurrentIndex(1)  # Show group assignment table
                print(f"[DEBUG] Stack index AFTER: {dataset_stack.currentIndex()}")
            else:
                print("[DEBUG] WARNING: Button not recognized!")
            
            print(f"[DEBUG] Current visible widget: {dataset_stack.currentWidget()}")
        
        # CRITICAL FIX: Connect individual button toggled signals instead of buttonClicked
        # buttonClicked sometimes fails silently, toggled is more reliable
        comparison_radio.toggled.connect(lambda checked: toggle_mode(comparison_radio) if checked else None)
        classification_radio.toggled.connect(lambda checked: toggle_mode(classification_radio) if checked else None)
        
        # Also try buttonClicked as backup
        mode_toggle.buttonClicked.connect(toggle_mode)
        
        print("[DEBUG] Mode toggle signals connected (toggled + buttonClicked)")
        print(f"[DEBUG] comparison_radio.toggled: {comparison_radio.toggled}")
        print(f"[DEBUG] classification_radio.toggled: {classification_radio.toggled}")
        print(f"[DEBUG] mode_toggle.buttonClicked: {mode_toggle.buttonClicked}")
        print(f"[DEBUG] Toggle function object: {toggle_mode}")
        print(f"[DEBUG] Initial stack index: {dataset_stack.currentIndex()}")
        print(f"[DEBUG] Initial visible widget: {dataset_stack.currentWidget()}")
        print(f"[DEBUG] comparison_radio checked: {comparison_radio.isChecked()}")
        print(f"[DEBUG] classification_radio checked: {classification_radio.isChecked()}")
        
        # Set initial page to Comparison Mode
        dataset_stack.setCurrentIndex(0)
        comparison_radio.setChecked(True)
        print("[DEBUG] Set initial mode to Comparison (index 0)")
        print(f"[DEBUG] After init - comparison_radio checked: {comparison_radio.isChecked()}")
    
    dataset_layout.addWidget(dataset_stack)
    
    left_layout.addWidget(dataset_card)
    
    # Parameters section
    params_group = QGroupBox(localize_func("ANALYSIS_PAGE.parameters"))
    params_group.setStyleSheet("""
        QGroupBox {
            font-weight: 600;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            margin-top: 8px;
            padding-top: 16px;
        }
        QGroupBox::title {
            subcontrol-origin: margin;
            left: 12px;
            padding: 0 4px;
        }
    """)
    params_layout = QVBoxLayout(params_group)
    
    # Create dynamic parameter widget
    # Convert registry format to DynamicParameterWidget format
    # Registry uses: "spinbox"/"double_spinbox"/"combo"/"checkbox"
    # DynamicParameterWidget expects: "int"/"float"/"choice"/"bool"
    
    type_mapping = {
        "spinbox": "int",
        "double_spinbox": "float",
        "combo": "choice",
        "checkbox": "bool"
    }
    
    # Convert params from registry format to param_info format
    params_dict = method_info.get("params", {})
    param_info = {}
    default_params = {}
    
    for param_name, param_config in params_dict.items():
        # Map the type
        registry_type = param_config.get("type", "float")
        widget_type = type_mapping.get(registry_type, registry_type)
        
        # Build param_info entry
        param_info[param_name] = {
            "type": widget_type,
            "description": param_config.get("label", param_name)
        }
        
        # Add range if exists
        if "range" in param_config:
            param_info[param_name]["range"] = param_config["range"]
        
        # Add step if exists
        if "step" in param_config:
            param_info[param_name]["step"] = param_config["step"]
        
        # Add choices if exists (for combo/choice type)
        if "options" in param_config:
            param_info[param_name]["choices"] = param_config["options"]
        
        # Store default value
        if "default" in param_config:
            default_params[param_name] = param_config["default"]
    
    # Create widget with converted format
    param_widget = DynamicParameterWidget(
        method_info={
            "param_info": param_info,
            "default_params": default_params
        },
        saved_params={},
        data_range=None,
        parent=params_group
    )
    params_layout.addWidget(param_widget)
    
    left_layout.addWidget(params_group)
    left_layout.addStretch()
    
    # Action buttons
    button_layout = QHBoxLayout()
    button_layout.setSpacing(12)
    
    back_btn = QPushButton("â† " + localize_func("ANALYSIS_PAGE.back_button"))
    back_btn.setObjectName("secondaryButton")
    back_btn.setMinimumHeight(40)
    back_btn.clicked.connect(on_back)
    button_layout.addWidget(back_btn)
    
    run_btn = QPushButton(localize_func("ANALYSIS_PAGE.run_analysis"))
    run_btn.setObjectName("primaryButton")
    run_btn.setMinimumHeight(40)
    run_btn.setStyleSheet("""
        QPushButton#primaryButton {
            background-color: #0078d4;
            color: white;
            border: none;
            border-radius: 4px;
            font-weight: 600;
            font-size: 14px;
        }
        QPushButton#primaryButton:hover {
            background-color: #006abc;
        }
        QPushButton#primaryButton:pressed {
            background-color: #005a9e;
        }
        QPushButton#primaryButton:disabled {
            background-color: #c0c0c0;
        }
    """)
    
    # Connect run button - extract selected dataset(s) correctly
    def _get_selected_datasets():
        """
        Extract selected dataset names based on widget type and mode.
        
        Returns:
            For Comparison Mode:
                - Single string (single-dataset methods)
                - List of strings (multi-dataset methods)
            For Classification Mode:
                - Dict[str, List[str]] mapping group names to dataset lists
        """
        # Check if Classification Mode is active (for multi-dataset methods)
        if classification_radio and classification_radio.isChecked() and group_widget:
            # Return group assignments
            groups = group_widget.get_groups()
            if not groups:
                # No groups assigned - show warning
                return None
            return groups
        
        # Comparison Mode (simple selection)
        if dataset_selection_mode == "single":
            return dataset_widget.currentText()  # Single string
        else:
            # Multi-select list widget
            selected_items = dataset_widget.selectedItems()
            return [item.text() for item in selected_items]  # List of strings
    
    run_btn.clicked.connect(lambda: on_run_analysis(
        category, method_key, _get_selected_datasets(), param_widget
    ))
    button_layout.addWidget(run_btn)
    
    left_layout.addLayout(button_layout)
    
    # === RIGHT PANEL: Results Display ===
    right_panel = create_results_panel(localize_func)
    
    # Add panels to splitter
    splitter.addWidget(left_panel)
    splitter.addWidget(right_panel)
    splitter.setSizes([400, 600])  # Initial sizes
    
    main_layout.addWidget(splitter)
    
    # Store references for external access
    method_widget.dataset_widget = dataset_widget  # Store the actual widget (QComboBox or QListWidget)
    method_widget.group_widget = group_widget  # Store group widget (GroupAssignmentTable)
    method_widget.comparison_radio = comparison_radio  # Store comparison mode button
    method_widget.classification_radio = classification_radio  # Store classification mode button
    method_widget.dataset_selection_mode = dataset_selection_mode
    method_widget.param_widget = param_widget
    method_widget.run_btn = run_btn
    method_widget.back_btn = back_btn
    method_widget.results_panel = right_panel
    method_widget.category = category
    method_widget.method_key = method_key
    
    return method_widget

def _v1_create_results_panel(localize_func: Callable) -> QWidget:
    """
    Create results display panel with tabs for different result types.
    
    Args:
        localize_func: Localization function
    
    Returns:
        Results panel widget with tab_widget attribute
    """
    results_panel = QWidget()
    results_panel.setObjectName("resultsPanel")
    results_panel.setStyleSheet("""
        QWidget#resultsPanel {
            background-color: #ffffff;
            border-left: 1px solid #e0e0e0;
        }
    """)
    
    layout = QVBoxLayout(results_panel)
    layout.setContentsMargins(24, 24, 24, 24)
    layout.setSpacing(16)
    
    # Header with export buttons
    header_layout = QHBoxLayout()
    
    results_title = QLabel("ðŸ“Š " + localize_func("ANALYSIS_PAGE.results_title"))
    results_title.setStyleSheet("""
        font-size: 18px;
        font-weight: 600;
        color: #2c3e50;
    """)
    header_layout.addWidget(results_title)
    header_layout.addStretch()
    
    # Export CSV button (hidden until results available)
    # Note: Plot export (PNG/SVG) available via matplotlib toolbar right-click
    export_data_btn = QPushButton(localize_func("ANALYSIS_PAGE.export_csv"))
    export_data_btn.setObjectName("exportButton")
    export_data_btn.setMinimumHeight(32)
    export_data_btn.setVisible(False)
    header_layout.addWidget(export_data_btn)
    
    layout.addLayout(header_layout)
    
    # Tab widget for different result views
    tab_widget = QTabWidget()
    tab_widget.setObjectName("resultsTabWidget")
    tab_widget.setStyleSheet("""
        QTabWidget::pane {
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            background-color: white;
        }
        QTabBar::tab {
            background-color: #f8f9fa;
            border: 1px solid #e0e0e0;
            padding: 8px 16px;
            margin-right: 2px;
        }
        QTabBar::tab:selected {
            background-color: white;
            border-bottom-color: white;
            font-weight: 600;
        }
        QTabBar::tab:hover {
            background-color: #e7f3ff;
        }
    """)
    
    # Placeholder tabs (will be populated with actual results)
    placeholder_label = QLabel(localize_func("ANALYSIS_PAGE.no_results_yet"))
    placeholder_label.setAlignment(Qt.AlignCenter)
    placeholder_label.setStyleSheet("""
        font-size: 14px;
        color: #6c757d;
        padding: 40px;
    """)
    tab_widget.addTab(placeholder_label, localize_func("ANALYSIS_PAGE.results_tab"))
    
    layout.addWidget(tab_widget)
    
    # Store references for external access
    results_panel.tab_widget = tab_widget
    results_panel.export_data_btn = export_data_btn
    results_panel.results_title = results_title
    
    return results_panel

class MethodParametersWidget(QWidget):
    """
    A styled 'Card' widget that holds the dynamic parameter inputs.
    Replaces the generic QGroupBox with a clean, SaaS-style look.
    """
    def __init__(self, method_info, parent=None):
        super().__init__(parent)
        self.method_info = method_info
        self.dynamic_widget = None 
        self._setup_ui()

    def _setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 10, 0, 10)
        layout.setSpacing(8)

        # 1. Header (Clean Text)
        header = QLabel("âš™ï¸ Configuration")  # You can localize this
        header.setStyleSheet("""
            font-size: 13px;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 4px;
        """)
        layout.addWidget(header)

        # 2. Card Container (White box with subtle border)
        card = QFrame()
        card.setStyleSheet("""
            QFrame {
                background-color: #ffffff;
                border: 1px solid #dfe3ea;
                border-radius: 8px;
            }
        """)
        card_layout = QVBoxLayout(card)
        card_layout.setContentsMargins(16, 16, 16, 16)
        
        # --- Data Conversion for DynamicParameterWidget ---
        # We map the registry types to the types your widget expects
        type_mapping = {
            "spinbox": "int", 
            "double_spinbox": "float", 
            "combo": "choice", 
            "checkbox": "bool"
        }
        
        params_dict = self.method_info.get("params", {})
        param_info = {}
        default_params = {}
        
        for p_name, p_config in params_dict.items():
            reg_type = p_config.get("type", "float")
            w_type = type_mapping.get(reg_type, reg_type)
            
            # Build the info dict
            param_info[p_name] = {
                "type": w_type, 
                "description": p_config.get("label", p_name)
            }
            
            # Transfer constraints
            if "range" in p_config: param_info[p_name]["range"] = p_config["range"]
            if "step" in p_config: param_info[p_name]["step"] = p_config["step"]
            if "options" in p_config: param_info[p_name]["choices"] = p_config["options"]
            if "default" in p_config: default_params[p_name] = p_config["default"]

        # Instantiate the Dynamic Logic
        # Note: We assume DynamicParameterWidget is available in your imports
        self.dynamic_widget = DynamicParameterWidget(
            method_info={"param_info": param_info, "default_params": default_params},
            saved_params={}, 
            data_range=None, 
            parent=card
        )
        
        card_layout.addWidget(self.dynamic_widget)
        layout.addWidget(card)

    def get_params(self):
        """Bridge to get data from the inner widget"""
        if self.dynamic_widget:
            return self.dynamic_widget.get_params()
        return {}


class DatasetSelectionWidget(QWidget):
    def __init__(self, dataset_names, mode="single", localize_func=None, parent=None):
        super().__init__(parent)
        self.dataset_names = dataset_names
        self.mode = mode
        self.localize = localize_func
        
        # Widgets
        self.simple_input = None
        self.group_manager = None
        self.radio_group = None
        self.select_all_cb = None # Reference for logic
        
        self._setup_ui()

    def _setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(12) # Consistent spacing

        # --- 1. HEADER ROW (Label + Toggle) ---
        header_container = QWidget()
        header_layout = QHBoxLayout(header_container)
        header_layout.setContentsMargins(0, 0, 0, 0)
        
        # Label
        label_text = self.localize("ANALYSIS_PAGE.dataset_selection") if self.localize else "Select Datasets"
        label = QLabel("ðŸ“‚ " + label_text)
        # Using color #2c3e50 from stylesheets.py
        label.setStyleSheet("font-size: 14px; font-weight: 600; color: #2c3e50;")
        header_layout.addWidget(label)
        
        header_layout.addStretch()

        # Toggle (Only for multi mode)
        if self.mode == "multi":
            self.stack = QStackedWidget()
            self._create_toggle(header_layout)
        
        layout.addWidget(header_container)

        # --- 2. CONTENT AREA ---
        if self.mode == "single":
            # Single Selection (ComboBox)
            self.simple_input = QComboBox()
            self.simple_input.addItems(self.dataset_names)
            self.simple_input.setMinimumHeight(40)
            # Applying 'combo_box' style logic from stylesheets.py
            self.simple_input.setStyleSheet("""
                QComboBox {
                    padding: 8px;
                    border: 1px solid #ced4da;
                    border-radius: 4px;
                    background-color: white;
                    font-size: 13px;
                    color: #2c3e50;
                }
                QComboBox:hover { border-color: #0078d4; }
                QComboBox::drop-down { border: none; width: 24px; }
                QComboBox QAbstractItemView {
                    border: 1px solid #ced4da;
                    selection-background-color: #e3f2fd;
                    selection-color: #1976d2;
                }
            """)
            layout.addWidget(self.simple_input)
            
        else:
            # Multi Selection (Stack)
            
            # PAGE 0: Optimized Simple List (List + Toolbar)
            page_simple = QWidget()
            layout_s = QVBoxLayout(page_simple)
            layout_s.setContentsMargins(0,0,0,0)
            layout_s.setSpacing(0) # Toolbar sits flush with list
            
            # A. Toolbar (Select All)
            toolbar = QFrame()
            toolbar.setStyleSheet("""
                QFrame {
                    background-color: #f8f9fa;
                    border: 1px solid #ced4da;
                    border-bottom: none;
                    border-top-left-radius: 4px;
                    border-top-right-radius: 4px;
                }
            """)
            tb_layout = QHBoxLayout(toolbar)
            tb_layout.setContentsMargins(12, 8, 12, 8)
            
            self.select_all_cb = QCheckBox("Select All")
            self.select_all_cb.setCursor(Qt.PointingHandCursor)
            self.select_all_cb.setStyleSheet("""
                QCheckBox { font-size: 13px; font-weight: 500; color: #495057; }
                QCheckBox::indicator { width: 16px; height: 16px; }
            """)
            tb_layout.addWidget(self.select_all_cb)
            tb_layout.addStretch()
            
            layout_s.addWidget(toolbar)
            
            # B. The Rich List Widget
            self.simple_input = QListWidget()
            self.simple_input.setSelectionMode(QAbstractItemView.MultiSelection)
            self.simple_input.addItems(self.dataset_names)
            self.simple_input.setMinimumHeight(200)
            
            # Applying 'dataset_list' style from stylesheets.py PREPROCESS_PAGE_STYLES
            self.simple_input.setStyleSheet("""
                QListWidget {
                    border: 1px solid #ced4da;
                    border-top: none; /* Merge with toolbar */
                    border-bottom-left-radius: 4px;
                    border-bottom-right-radius: 4px;
                    background-color: white;
                    padding: 4px;
                    outline: none;
                }
                QListWidget::item {
                    padding: 10px;
                    border-bottom: 1px solid #f1f3f4;
                    background-color: #ffffff;
                    margin-bottom: 2px;
                    border-radius: 3px;
                    color: #2c3e50;
                }
                QListWidget::item:hover {
                    background-color: #f5f5f5;
                }
                QListWidget::item:selected {
                    background-color: #e3f2fd; /* Light blue from theme */
                    color: #0078d4; /* Primary blue text */
                    border: 1px solid #0078d4;
                    font-weight: 600;
                }
                QListWidget::item:selected:hover {
                    background-color: #d0e7ff;
                }
            """)
            
            # Logic: Connect Select All
            self.select_all_cb.toggled.connect(self._toggle_select_all)
            self.simple_input.itemSelectionChanged.connect(self._update_checkbox_state)
            
            layout_s.addWidget(self.simple_input)
            
            # PAGE 1: Group Tree
            self.group_manager = GroupTreeManager(self.dataset_names, self.localize)
            
            self.stack.addWidget(page_simple)
            self.stack.addWidget(self.group_manager)
            layout.addWidget(self.stack)

    def _create_toggle(self, layout):
        container = QFrame()
        # Matches 'input_field' border color #ced4da
        container.setStyleSheet("background-color: white; border-radius: 16px; border: 1px solid #ced4da;")
        l = QHBoxLayout(container)
        l.setContentsMargins(2, 2, 2, 2)
        l.setSpacing(0)
        
        self.radio_group = QButtonGroup(self)
        btn_simple = self._make_pill(self.localize("ANALYSIS_PAGE.simple_mode"))
        btn_group = self._make_pill(self.localize("ANALYSIS_PAGE.grouped_mode"))
        
        self.radio_group.addButton(btn_simple, 0)
        self.radio_group.addButton(btn_group, 1)
        btn_simple.setChecked(True)
        
        self.radio_group.idToggled.connect(self.stack.setCurrentIndex)
        l.addWidget(btn_simple)
        l.addWidget(btn_group)
        layout.addWidget(container)

    def _make_pill(self, text):
        r = QRadioButton(text)
        r.setCursor(Qt.PointingHandCursor)
        # Uses primary color #0078d4 for active state
        r.setStyleSheet("""
            QRadioButton {
                background: transparent;
                color: #6c757d;
                padding: 6px 16px;
                font-size: 12px;
                font-weight: 600;
                border-radius: 14px;
                border: none;
            }
            QRadioButton:checked {
                background-color: #e3f2fd; /* Very light blue bg */
                color: #0078d4; /* Primary blue text */
            }
            QRadioButton:hover:!checked {
                background-color: #f8f9fa;
                color: #495057;
            }
            QRadioButton::indicator { width: 0; height: 0; }
        """)
        return r

    def _toggle_select_all(self, checked):
        """Selects or Deselects all items in the list."""
        if checked:
            self.simple_input.selectAll()
        else:
            self.simple_input.clearSelection()

    def _update_checkbox_state(self):
        """Updates checkbox if user manually selects/deselects items."""
        if not self.simple_input: return
        count = self.simple_input.count()
        selected = len(self.simple_input.selectedItems())
        
        self.select_all_cb.blockSignals(True)
        if selected == count and count > 0:
            self.select_all_cb.setCheckState(Qt.Checked)
        elif selected > 0:
            self.select_all_cb.setCheckState(Qt.PartiallyChecked)
        else:
            self.select_all_cb.setCheckState(Qt.Unchecked)
        self.select_all_cb.blockSignals(False)

    def get_selection(self):
        if self.mode == "single":
            return self.simple_input.currentText()
        
        if self.radio_group.checkedId() == 1:
            # Grouped Mode
            return self.group_manager.get_groups()
        else:
            # Simple Mode
            items = self.simple_input.selectedItems()
            return [i.text() for i in items]


class ResultsPanel(QWidget):
    """
    A styled container for Analysis Results.
    Manages the header, export actions, and the tabbed result views.
    """
    def __init__(self, localize_func, parent=None):
        super().__init__(parent)
        self.localize = localize_func
        self._setup_ui()

    def _setup_ui(self):
        self.setObjectName("resultsPanel")
        
        # 1. Main Layout
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0) # Clean edges
        layout.setSpacing(0)

        # 2. Header Section (Title + Export)
        header_frame = QFrame()
        header_frame.setStyleSheet("""
            QFrame {
                background-color: #ffffff;
                border-bottom: 1px solid #e0e0e0;
            }
        """)
        header_layout = QHBoxLayout(header_frame)
        header_layout.setContentsMargins(24, 16, 24, 16)
        header_layout.setSpacing(16)

        self.title_label = QLabel("ðŸ“Š " + self.localize("ANALYSIS_PAGE.results_title"))
        self.title_label.setStyleSheet("""
            font-size: 16px;
            font-weight: 700;
            color: #2c3e50;
        """)
        
        self.export_btn = QPushButton(self.localize("ANALYSIS_PAGE.export_csv"))
        self.export_btn.setCursor(Qt.PointingHandCursor)
        self.export_btn.setVisible(False) # Hidden by default
        self.export_btn.setStyleSheet("""
            QPushButton {
                background-color: white;
                color: #333;
                border: 1px solid #d0d0d0;
                padding: 6px 16px;
                border-radius: 4px;
                font-weight: 600;
                font-size: 13px;
            }
            QPushButton:hover {
                background-color: #f8f9fa;
                border-color: #b0b0b0;
                color: #000;
            }
        """)

        header_layout.addWidget(self.title_label)
        header_layout.addStretch()
        header_layout.addWidget(self.export_btn)

        layout.addWidget(header_frame)

        # 3. The Tab Widget (Modern Styling)
        self.tab_widget = QTabWidget()
        self.tab_widget.setDocumentMode(True) # Removes the heavy outer frame
        
        # PROFESSIONAL TAB STYLING
        self.tab_widget.setStyleSheet("""
            QTabWidget::pane {
                border: none;
                background: #ffffff;
                padding-top: 10px;
            }
            
            QTabWidget::tab-bar {
                alignment: left;
            }
            
            QTabBar::tab {
                background: transparent;
                color: #6c757d;
                font-size: 13px;
                font-weight: 600;
                padding: 12px 20px;
                border-bottom: 2px solid transparent;
                margin-left: 8px;
            }
            
            QTabBar::tab:hover {
                color: #0078d4;
                background-color: #f8f9fa;
                border-radius: 4px 4px 0 0;
            }
            
            QTabBar::tab:selected {
                color: #0078d4;
                border-bottom: 2px solid #0078d4; /* The modern underline indicator */
            }
        """)

        layout.addWidget(self.tab_widget)
        
        # 4. Initial Empty State
        self.show_placeholder()

    @property
    def export_data_btn(self):
        return self.export_btn
    
    def show_placeholder(self):
        """Displays the 'No Results' state."""
        self.tab_widget.clear()
        
        placeholder = QWidget()
        p_layout = QVBoxLayout(placeholder)
        p_layout.setAlignment(Qt.AlignCenter)
        
        icon_label = QLabel("ðŸ“‰")
        icon_label.setStyleSheet("font-size: 48px; margin-bottom: 10px;")
        
        text_label = QLabel(self.localize("ANALYSIS_PAGE.no_results_yet"))
        text_label.setStyleSheet("font-size: 16px; color: #adb5bd; font-weight: 500;")
        
        p_layout.addWidget(icon_label, 0, Qt.AlignCenter)
        p_layout.addWidget(text_label, 0, Qt.AlignCenter)
        
        self.tab_widget.addTab(placeholder, "Info")
        self.export_btn.setVisible(False)

    def add_result_tab(self, widget, title, icon=None):
        """Helper to add tabs easily."""
        index = self.tab_widget.addTab(widget, title)
        if icon:
            self.tab_widget.setTabIcon(index, icon)
        self.tab_widget.setCurrentIndex(index)
        self.export_btn.setVisible(True)

    def clear_results(self):
        """Clears all tabs and shows placeholder."""
        self.tab_widget.clear()
        self.show_placeholder()

class MethodView(QWidget):
    """
    The main controller for a specific Analysis Method View.
    Orchestrates the Input Panel (Left) and Results Panel (Right).
    """
    def __init__(self, category, method_key, dataset_names, localize_func, on_run, on_back, parent=None):
        super().__init__(parent)
        
        # Store Context
        self.category = category
        self.method_key = method_key
        self.dataset_names = dataset_names
        self.localize = localize_func
        self.on_run_callback = on_run
        self.on_back_callback = on_back
        
        # Load Configuration
        self.method_info = ANALYSIS_METHODS[category][method_key]
        
        # UI References (to be filled during build)
        self.dataset_widget = None
        self.params_widget = None
        self.results_panel = None
        
        # Build the UI
        self._init_ui()

    def _init_ui(self):
        """Main build orchestrator."""
        self.setObjectName("methodView")
        
        # 1. Root Layout (No Margins)
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        # 2. Splitter
        self.splitter = QSplitter(Qt.Horizontal)
        self.splitter.setChildrenCollapsible(False)
        
        # 3. Build Panels
        left_panel = self._build_left_panel()
        self.results_panel = self._build_right_panel()
        
        # 4. Add to Splitter
        self.splitter.addWidget(left_panel)
        self.splitter.addWidget(self.results_panel)
        self.splitter.setSizes([380, 620]) # Default ratio
        
        main_layout.addWidget(self.splitter)

    def _build_left_panel(self):
        """Constructs the Input Form (Left Side)."""
        panel = QWidget()
        panel.setStyleSheet("background-color: #fcfcfc; border-right: 1px solid #dfe3ea;")
        
        layout = QVBoxLayout(panel)
        layout.setContentsMargins(24, 24, 24, 24)
        layout.setSpacing(20)
        
        # A. Header
        self._build_header(layout)
        
        # B. Scroll Area for Inputs (In case parameters are long)
        # We wrap inputs in a scroll area for responsiveness
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setFrameShape(QFrame.NoFrame)
        scroll.setStyleSheet("background: transparent;")
        
        content_widget = QWidget()
        content_layout = QVBoxLayout(content_widget)
        content_layout.setContentsMargins(0, 0, 0, 0)
        content_layout.setSpacing(24)
        
        # --- Input Components ---
        self._build_dataset_section(content_layout)
        self._build_parameter_section(content_layout)
        
        content_layout.addStretch() # Push contents up
        scroll.setWidget(content_widget)
        layout.addWidget(scroll)
        
        # C. Footer Actions
        self._build_action_buttons(layout)
        
        return panel

    def _build_header(self, parent_layout):
        """Creates Title and Description."""
        title = QLabel(self.method_info["name"])
        title.setStyleSheet("font-size: 20px; font-weight: 600; color: #2c3e50;")
        
        desc_text = self.localize(f"ANALYSIS_PAGE.METHOD_DESC.{self.method_key}")
        desc = QLabel(desc_text)
        desc.setWordWrap(True)
        desc.setStyleSheet("font-size: 13px; color: #6c757d; line-height: 1.5;")
        
        parent_layout.addWidget(title)
        parent_layout.addWidget(desc)

    def _build_dataset_section(self, parent_layout):
        """Instantiates the DatasetSelectionWidget."""
        mode = self.method_info.get("dataset_selection_mode", "single")
        
        self.dataset_widget = DatasetSelectionWidget(
            self.dataset_names, 
            mode, 
            self.localize
        )
        parent_layout.addWidget(self.dataset_widget)

    def _build_parameter_section(self, parent_layout):
        """Instantiates the MethodParametersWidget."""
        self.params_widget = MethodParametersWidget(
            self.method_info
        )
        parent_layout.addWidget(self.params_widget)

    def _build_action_buttons(self, parent_layout):
        """Creates Back and Run buttons."""
        row = QHBoxLayout()
        row.setSpacing(12)
        
        self.back_btn = QPushButton(self.localize("ANALYSIS_PAGE.back_button"))
        self.back_btn.setMinimumHeight(40)
        self.back_btn.setCursor(Qt.PointingHandCursor)
        self.back_btn.setStyleSheet("""
            QPushButton { 
                border: 1px solid #dfe3ea; background: white; color: #2c3e50; 
                border-radius: 6px; font-weight: 600; font-size: 13px;
            }
            QPushButton:hover { background: #f8f9fa; border-color: #adb5bd; }
        """)
        self.back_btn.clicked.connect(self.on_back_callback)
        
        self.run_btn = QPushButton(self.localize("ANALYSIS_PAGE.run_analysis"))
        self.run_btn.setMinimumHeight(40)
        self.run_btn.setCursor(Qt.PointingHandCursor)
        self.run_btn.setStyleSheet("""
            QPushButton { 
                background-color: #0078d4; color: white; border: none; 
                border-radius: 6px; font-weight: 600; font-size: 14px; 
            }
            QPushButton:hover { background-color: #006abc; }
            QPushButton:pressed { background-color: #005a9e; }
        """)
        self.run_btn.clicked.connect(self._handle_run_click)
        
        row.addWidget(self.back_btn)
        row.addWidget(self.run_btn)
        parent_layout.addLayout(row)

    def _build_right_panel(self):
        """Creates the Results Panel."""
        # Uses your existing utility function
        return ResultsPanel(localize_func=self.localize, parent=self)

    def _handle_run_click(self):
        """Collects data and triggers the run callback."""
        # 1. Get Datasets
        selected_data = self.dataset_widget.get_selection()
        
        if not selected_data:
            QMessageBox.warning(self, "Input Error", "Please select at least one dataset.")
            return
            
        # 2. Get Parameters (Pass the widget itself, logic handled downstream)
        # The runner expects the widget to extract params, or we pass values
        # Currently your logic passes the widget, so we keep that pattern:
        self.on_run_callback(
            self.category, 
            self.method_key, 
            selected_data, 
            self.params_widget.dynamic_widget # Pass the inner dynamic widget
        )

    def _build_right_panel(self):
        """Creates the Results Panel using the new Class."""
        # Instantiate the class
        self.results_panel = ResultsPanel(self.localize)
        
        # If you need to connect the export button signal to a handler in MethodView
        self.results_panel.export_btn.clicked.connect(self._handle_export_csv)
        
        return self.results_panel

    def _handle_export_csv(self):
        # Logic to handle export
        pass



def populate_results_tabs(
    results_panel: QWidget,
    result: Any,
    localize_func: Callable,
    matplotlib_widget_class: type
) -> None:
    """
    Populate results tabs with analysis output.
    
    Args:
        results_panel: Results panel widget from create_results_panel
        result: AnalysisResult object
        localize_func: Localization function
        matplotlib_widget_class: MatplotlibWidget class for plot rendering
    """
    tab_widget = results_panel.tab_widget
    
    # Clear existing tabs
    while tab_widget.count() > 0:
        tab_widget.removeTab(0)
    
    # Show CSV export button (plot export via matplotlib toolbar)
    results_panel.export_data_btn.setVisible(True)
    
    # === Tab 0: Spectrum Preview (New Feature) ===
    if result.dataset_data:
        try:
            spectrum_fig = create_spectrum_preview_figure(result.dataset_data)
            spectrum_tab = matplotlib_widget_class()
            spectrum_tab.update_plot(spectrum_fig)
            spectrum_tab.setMinimumHeight(400)
            tab_widget.addTab(spectrum_tab, "ðŸ“ˆ Spectrum Preview")
        except Exception as e:
            print(f"[ERROR] Failed to create spectrum preview: {e}")
    
    # === Special handling for PCA Analysis: Create 5-tab visualization ===
    is_pca = hasattr(result, "raw_results") and "pca_model" in result.raw_results
    
    if is_pca:
        print("[DEBUG] PCA Analysis detected - creating 5-tab visualization")
        
        # Extract figures from raw_results
        scree_figure = result.raw_results.get("scree_figure")
        loadings_figure = result.raw_results.get("loadings_figure")
        biplot_figure = result.raw_results.get("biplot_figure")
        cumulative_variance_figure = result.raw_results.get("cumulative_variance_figure")
        distributions_figure = result.raw_results.get("distributions_figure")
        
        print(f"[DEBUG] PCA figures found:")
        print(f"[DEBUG]   scree_figure: {scree_figure is not None}")
        print(f"[DEBUG]   loadings_figure: {loadings_figure is not None}")
        print(f"[DEBUG]   biplot_figure: {biplot_figure is not None}")
        print(f"[DEBUG]   cumulative_variance_figure: {cumulative_variance_figure is not None}")
        print(f"[DEBUG]   distributions_figure: {distributions_figure is not None}")
        
        # Tab 1: Score Plot (PC1 vs PC2)
        if result.primary_figure:
            score_tab = matplotlib_widget_class()
            score_tab.update_plot(result.primary_figure)
            score_tab.setMinimumHeight(400)
            tab_widget.addTab(score_tab, "ðŸ“ˆ Score Plot")
        
        # Tab 2: Scree Plot
        if scree_figure:
            scree_tab = matplotlib_widget_class()
            scree_tab.update_plot(scree_figure)
            scree_tab.setMinimumHeight(400)
            tab_widget.addTab(scree_tab, "ðŸ“Š Scree Plot")
        
        # Tab 3: Loading Plot with Component Selection
        if loadings_figure and "pca_model" in result.raw_results:
            # Create container
            loading_container = QWidget()
            loading_layout = QVBoxLayout(loading_container)
            loading_layout.setContentsMargins(0, 5, 0, 0)
            
            # Controls
            controls_layout = QHBoxLayout()
            controls_layout.addStretch()
            controls_layout.addWidget(QLabel("Show Component:"))
            
            comp_combo = QComboBox()
            pca_model = result.raw_results["pca_model"]
            n_comps = pca_model.n_components_
            comp_combo.addItem("All Components")
            for i in range(n_comps):
                comp_combo.addItem(f"PC{i+1}")
            
            controls_layout.addWidget(comp_combo)
            loading_layout.addLayout(controls_layout)
            
            # Plot
            loading_tab = matplotlib_widget_class()
            loading_tab.update_plot(loadings_figure)
            loading_layout.addWidget(loading_tab)
            
            # Update logic
            def update_loadings(index):
                try:
                    # Get wavenumbers from dataset_data
                    if not result.dataset_data:
                        return
                    
                    # Assume all datasets have same wavenumbers
                    first_df = next(iter(result.dataset_data.values()))
                    wavenumbers = first_df.index.values
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    if index == 0: # All components
                        # Recreate the original multi-subplot figure (simplified)
                        # Actually, better to just show all in one plot or subplots
                        # For simplicity, let's plot all in one axis if "All" is selected, 
                        # OR revert to the original figure if possible.
                        # But we can't easily revert to original figure object without storing it.
                        # So let's plot all lines on one axis for "All Components" in this view
                        # OR just use the original figure if index == 0?
                        # The original figure was passed as loadings_figure.
                        # We can re-use it!
                        loading_tab.update_plot(loadings_figure)
                        return
                    else:
                        # Specific component (index-1)
                        pc_idx = index - 1
                        component = pca_model.components_[pc_idx]
                        explained_var = pca_model.explained_variance_ratio_[pc_idx] * 100
                        
                        ax.plot(wavenumbers, component, color='#1f77b4', linewidth=1.5)
                        ax.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
                        ax.set_ylabel('Loading Value', fontsize=12)
                        ax.set_title(f'PC{pc_idx+1} Loadings ({explained_var:.2f}%)', fontsize=14, fontweight='bold')
                        ax.grid(True, alpha=0.3)
                        ax.invert_xaxis()
                        ax.axhline(y=0, color='k', linestyle='--', linewidth=0.5)
                        
                        # Annotate peaks
                        abs_loadings = np.abs(component)
                        top_indices = np.argsort(abs_loadings)[-5:]
                        for peak_idx in top_indices:
                            peak_wn = wavenumbers[peak_idx]
                            peak_val = component[peak_idx]
                            ax.plot(peak_wn, peak_val, 'o', color='red', markersize=5)
                            ax.annotate(f'{peak_wn:.0f}', xy=(peak_wn, peak_val), xytext=(0, 10),
                                       textcoords='offset points', ha='center', fontsize=8)
                        
                        fig.tight_layout()
                        loading_tab.update_plot(fig)
                        plt.close(fig)
                        
                except Exception as e:
                    print(f"[ERROR] Failed to update loadings plot: {e}")

            comp_combo.currentIndexChanged.connect(update_loadings)
            
            tab_widget.addTab(loading_container, "ðŸ”¬ Loading Plot")
        elif loadings_figure:
            # Fallback if no model
            loading_tab = matplotlib_widget_class()
            loading_tab.update_plot(loadings_figure)
            loading_tab.setMinimumHeight(400)
            tab_widget.addTab(loading_tab, "ðŸ”¬ Loading Plot")
        
        # Tab 4: Biplot
        if biplot_figure:
            biplot_tab = matplotlib_widget_class()
            biplot_tab.update_plot(biplot_figure)
            biplot_tab.setMinimumHeight(400)
            tab_widget.addTab(biplot_tab, "ðŸŽ¯ Biplot")
        
        # Tab 5: Cumulative Variance
        if cumulative_variance_figure:
            cumvar_tab = matplotlib_widget_class()
            cumvar_tab.update_plot(cumulative_variance_figure)
            cumvar_tab.setMinimumHeight(400)
            tab_widget.addTab(cumvar_tab, "ðŸ“ˆ Cumulative Variance")
        
        # Bonus: Distributions (if available)
        if distributions_figure:
            dist_tab = matplotlib_widget_class()
            dist_tab.update_plot(distributions_figure)
            dist_tab.setMinimumHeight(400)
            tab_widget.addTab(dist_tab, "ðŸ“Š Distributions")
    
    else:
        # === Standard analysis results (non-PCA) ===
        
        # === Main Plot Tab (Scores/Primary Figure) ===
        if result.primary_figure:
            plot_tab = matplotlib_widget_class()
            plot_tab.update_plot(result.primary_figure)
            plot_tab.setMinimumHeight(400)
            tab_widget.addTab(plot_tab, "ðŸ“ˆ " + localize_func("ANALYSIS_PAGE.scores_tab") if hasattr(result, "loadings_figure") else localize_func("ANALYSIS_PAGE.plot_tab"))
        
        # === Loadings Tab (for dimensionality reduction) ===
        print(f"[DEBUG] Checking loadings_figure...")
        print(f"[DEBUG]   hasattr(result, 'loadings_figure'): {hasattr(result, 'loadings_figure')}")
        if hasattr(result, 'loadings_figure'):
            print(f"[DEBUG]   result.loadings_figure is not None: {result.loadings_figure is not None}")
            print(f"[DEBUG]   result.loadings_figure type: {type(result.loadings_figure)}")
        
        if hasattr(result, "loadings_figure") and result.loadings_figure:
            print(f"[DEBUG] Creating Loadings tab...")
            loadings_tab = matplotlib_widget_class()
            loadings_tab.update_plot(result.loadings_figure)
            loadings_tab.setMinimumHeight(400)
            tab_widget.addTab(loadings_tab, "ðŸ”¬ " + localize_func("ANALYSIS_PAGE.loadings_tab"))
            print(f"[DEBUG] Loadings tab added successfully")
        else:
            print(f"[DEBUG] Loadings tab NOT created (figure missing or None)")
        
        # === Distributions Tab (for classification) ===
        if hasattr(result, "distributions_figure") and result.distributions_figure:
            dist_tab = matplotlib_widget_class()
            dist_tab.update_plot(result.distributions_figure)
            dist_tab.setMinimumHeight(400)
            tab_widget.addTab(dist_tab, "ðŸ“Š " + localize_func("ANALYSIS_PAGE.distributions_tab"))
        
        # === Legacy Secondary Figure Tab (deprecated but kept for compatibility) ===
        if hasattr(result, "secondary_figure") and result.secondary_figure:
            secondary_tab = matplotlib_widget_class()
            secondary_tab.update_plot(result.secondary_figure)
            secondary_tab.setMinimumHeight(400)
            tab_widget.addTab(secondary_tab, "ðŸ“Š " + localize_func("ANALYSIS_PAGE.secondary_plot_tab"))
    
    # === Data Table Tab ===
    if result.data_table is not None:
        table_tab = create_data_table_tab(result.data_table)
        tab_widget.addTab(table_tab, "ðŸ“‹ " + localize_func("ANALYSIS_PAGE.data_tab"))
    
    # === Summary Tab ===
    if result.detailed_summary:
        summary_tab = create_summary_tab(result.detailed_summary)
        tab_widget.addTab(summary_tab, "ðŸ“‹ " + localize_func("ANALYSIS_PAGE.summary_tab"))
    
    # === Diagnostics Tab (if available) ===
    if hasattr(result, "diagnostics") and result.diagnostics:
        diag_tab = create_summary_tab(result.diagnostics)
        tab_widget.addTab(diag_tab, "ðŸ” " + localize_func("ANALYSIS_PAGE.diagnostics_tab"))


def create_data_table_tab(data_table) -> QWidget:
    """
    Create data table tab from pandas DataFrame or dict.
    
    Args:
        data_table: DataFrame or dict containing tabular data
    
    Returns:
        Table widget
    """
    table_widget = QTableWidget()
    table_widget.setStyleSheet("""
        QTableWidget {
            border: none;
            gridline-color: #e0e0e0;
            background-color: white;
        }
        QHeaderView::section {
            background-color: #f8f9fa;
            padding: 8px;
            border: none;
            border-bottom: 2px solid #e0e0e0;
            font-weight: 600;
        }
        QTableWidget::item {
            padding: 6px;
        }
    """)
    
    # Convert to DataFrame if dict
    import pandas as pd
    if isinstance(data_table, dict):
        df = pd.DataFrame(data_table)
    else:
        df = data_table
    
    # Populate table
    table_widget.setRowCount(len(df))
    table_widget.setColumnCount(len(df.columns))
    table_widget.setHorizontalHeaderLabels([str(col) for col in df.columns])
    
    for i, row in df.iterrows():
        for j, value in enumerate(row):
            item = QTableWidgetItem(str(value))
            table_widget.setItem(i, j, item)
    
    table_widget.resizeColumnsToContents()
    return table_widget


def create_summary_tab(summary_text: str) -> QWidget:
    """
    Create summary/diagnostics text tab.
    
    Args:
        summary_text: Summary text content
    
    Returns:
        Text display widget
    """
    text_edit = QTextEdit()
    text_edit.setReadOnly(True)
    text_edit.setPlainText(summary_text)
    text_edit.setStyleSheet("""
        QTextEdit {
            border: none;
            background-color: white;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 12px;
            padding: 12px;
        }
    """)
    return text_edit


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\methods\__init__.py ##

"""
Analysis Method Implementations

This module provides all analysis method implementations that
operate on Raman spectral datasets.
"""

from .exploratory import (
    perform_pca_analysis,
    perform_umap_analysis,
    perform_tsne_analysis,
    perform_hierarchical_clustering,
    perform_kmeans_clustering
)

from .statistical import (
    perform_spectral_comparison,
    perform_peak_analysis,
    perform_correlation_analysis,
    perform_anova_test
)

# Import visualization functions from functions.visualization package
from functions.visualization import (
    create_spectral_heatmap,
    create_mean_spectra_overlay,
    create_waterfall_plot,
    create_correlation_heatmap,
    create_peak_scatter
)

__all__ = [
    # Exploratory
    "perform_pca_analysis",
    "perform_umap_analysis",
    "perform_tsne_analysis",
    "perform_hierarchical_clustering",
    "perform_kmeans_clustering",
    
    # Statistical
    "perform_spectral_comparison",
    "perform_peak_analysis",
    "perform_correlation_analysis",
    "perform_anova_test",
    
    # Visualization
    "create_spectral_heatmap",
    "create_mean_spectra_overlay",
    "create_waterfall_plot",
    "create_correlation_heatmap",
    "create_peak_scatter"
]


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\methods\exploratory.py ##

"""
Exploratory Analysis Methods

This module implements exploratory data analysis methods like PCA, UMAP,
t-SNE, and clustering techniques.
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Callable, Optional
import matplotlib
matplotlib.use('Agg')  # Use non-GUI backend for thread safety
from matplotlib import pyplot as plt
from matplotlib.figure import Figure
from matplotlib.patches import Ellipse

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import pdist
from scipy import stats

try:
    import umap
    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False


def add_confidence_ellipse(ax, x, y, n_std=1.96, facecolor='none', edgecolor='red', linestyle='--', linewidth=2, alpha=0.7, label=None):
    """
    Add a confidence ellipse to a matplotlib axis.
    
    For Raman spectroscopy Chemometrics, 95% confidence ellipses (n_std=1.96) are critical
    for proving statistical group separation in PCA plots.
    
    Args:
        ax: matplotlib axis object
        x, y: Data coordinates (numpy arrays)
        n_std: Number of standard deviations (1.96 for 95% CI)
        facecolor, edgecolor, linestyle, linewidth, alpha: matplotlib styling
        label: Legend label for the ellipse
    
    Returns:
        Ellipse patch object
    """
    if x.size == 0 or y.size == 0:
        return None
    
    # Calculate covariance matrix
    cov = np.cov(x, y)
    
    # Calculate eigenvalues and eigenvectors (principal axes of ellipse)
    eigenvalues, eigenvectors = np.linalg.eigh(cov)
    
    # Sort eigenvalues and eigenvectors (largest first)
    order = eigenvalues.argsort()[::-1]
    eigenvalues = eigenvalues[order]
    eigenvectors = eigenvectors[:, order]
    
    # Calculate angle of rotation
    angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))
    
    # Width and height are "full" widths, not radii
    width, height = 2 * n_std * np.sqrt(eigenvalues)
    
    # Mean position (center of ellipse)
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    # Create ellipse
    ellipse = Ellipse(xy=(mean_x, mean_y), width=width, height=height, angle=angle,
                      facecolor=facecolor, edgecolor=edgecolor, linestyle=linestyle,
                      linewidth=linewidth, alpha=alpha, label=label)
    
    ax.add_patch(ellipse)
    print(f"[DEBUG] Ellipse added to axis at ({mean_x:.2f}, {mean_y:.2f}), size: {width:.2f}x{height:.2f}")
    return ellipse


def perform_pca_analysis(dataset_data: Dict[str, pd.DataFrame],
                        params: Dict[str, Any],
                        progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform Principal Component Analysis on spectral data with multi-dataset support.
    
    Critical Raman Spectroscopy Context:
    - For multi-dataset comparison, ALL datasets are concatenated into ONE matrix
    - PCA is performed on the combined matrix to find variance patterns across groups
    - This allows visualization of group separation in the same PC space
    - Score distributions show overlap/separation between groups (key for classification)
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
            - Wavenumbers as index, spectra as columns
            - Multiple datasets for group comparison (e.g., "Control" vs "Disease")
        params: Analysis parameters
            - n_components: Number of components (default 3)
            - scaling: Scaler type ('StandardScaler', 'MinMaxScaler', 'None')
            - show_loadings: Show PC loadings plot (spectral interpretation)
            - show_scree: Show scree plot (variance explained)
            - show_distributions: Show score distribution plots (group comparison)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary containing:
            - primary_figure: Scores plot (PC1 vs PC2 scatter)
            - secondary_figure: Score distributions (PC1, PC2, PC3 histograms/KDE)
            - data_table: PC scores DataFrame with dataset labels
            - summary_text: Analysis summary
            - raw_results: Full PCA results (model, scores, loadings, variance)
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    n_components = params.get("n_components", 3)
    scaling_type = params.get("scaling", "StandardScaler")
    show_ellipses = params.get("show_ellipses", True)  # Confidence ellipses (critical for Chemometrics)
    show_loadings = params.get("show_loadings", True)
    show_scree = params.get("show_scree", True)
    show_distributions = params.get("show_distributions", True)
    group_labels_map = params.get("_group_labels", None)  # {dataset_name: group_label}
    
    print(f"[DEBUG] PCA parameters: n_components={n_components}, show_ellipses={show_ellipses}")
    print(f"[DEBUG] show_loadings={show_loadings}, show_scree={show_scree}, show_distributions={show_distributions}")
    
    # CRITICAL: Concatenate ALL datasets into ONE matrix for group comparison
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        spectra_matrix = df.values.T  # Shape: (n_spectra, n_wavenumbers)
        all_spectra.append(spectra_matrix)
        
        # Use group label if available, otherwise use dataset name
        if group_labels_map and dataset_name in group_labels_map:
            label = group_labels_map[dataset_name]
        else:
            label = dataset_name
        
        labels.extend([label] * spectra_matrix.shape[0])
    
    X = np.vstack(all_spectra)  # Combined matrix: (total_spectra, n_wavenumbers)
    wavenumbers = dataset_data[list(dataset_data.keys())[0]].index.values
    
    if progress_callback:
        progress_callback(30)
    
    # Apply scaling (essential for comparing datasets with different intensities)
    if scaling_type == "StandardScaler":
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    elif scaling_type == "MinMaxScaler":
        scaler = MinMaxScaler()
        X_scaled = scaler.fit_transform(X)
    else:
        X_scaled = X
    
    if progress_callback:
        progress_callback(50)
    
    # Perform PCA on COMBINED matrix (key for group comparison)
    pca = PCA(n_components=n_components)
    scores = pca.fit_transform(X_scaled)  # Shape: (total_spectra, n_components)
    
    if progress_callback:
        progress_callback(70)
    
    # === FIGURE 1: PC1 vs PC2 scores scatter plot WITH confidence ellipses ===
    print("[DEBUG] Creating PCA scores plot")
    fig1, ax1 = plt.subplots(figsize=(10, 8))
    
    unique_labels = sorted(set(labels))
    num_groups = len(unique_labels)
    print(f"[DEBUG] Number of groups/datasets: {num_groups}")
    print(f"[DEBUG] Group labels: {unique_labels}")
    
    # Use HIGH-CONTRAST color palette for clear distinction
    # For 2 datasets: blue (#1f77b4) and yellow/gold (#ffd700)
    # For 3+ datasets: use qualitative palettes with maximum contrast
    if num_groups == 2:
        # Maximum contrast for 2 groups: blue and yellow-gold
        colors = np.array([[0.12, 0.47, 0.71, 1.0],  # Blue
                          [1.0, 0.84, 0.0, 1.0]])    # Gold/Yellow
        print("[DEBUG] Using high-contrast 2-color palette: Blue and Gold")
    elif num_groups == 3:
        # High contrast for 3 groups: blue, red, green
        colors = np.array([[0.12, 0.47, 0.71, 1.0],  # Blue
                          [0.84, 0.15, 0.16, 1.0],   # Red
                          [0.17, 0.63, 0.17, 1.0]])  # Green
        print("[DEBUG] Using high-contrast 3-color palette: Blue, Red, Green")
    else:
        # For 4+ groups, use tab10 but with better spacing
        colors = plt.cm.tab10(np.linspace(0, 0.9, num_groups))
        print(f"[DEBUG] Using tab10 palette for {num_groups} groups")
    
    # Plot each dataset with distinct color
    for i, dataset_label in enumerate(unique_labels):
        mask = np.array([l == dataset_label for l in labels])
        num_points = np.sum(mask)
        print(f"[DEBUG] Group '{dataset_label}': {num_points} spectra")
        
        ax1.scatter(scores[mask, 0], scores[mask, 1],
                   c=[colors[i]], label=dataset_label,
                   alpha=0.7, s=100, edgecolors='white', linewidth=1.0)
        
        # Add 95% confidence ellipse (CRITICAL for Chemometrics) - controlled by parameter
        if show_ellipses and num_points >= 3:  # User-controlled + need at least 3 points
            print(f"[DEBUG] Adding 95% CI ellipse for '{dataset_label}' ({num_points} points, show_ellipses=True)")
            add_confidence_ellipse(
                ax1, 
                scores[mask, 0], 
                scores[mask, 1],
                n_std=1.96,  # 95% confidence interval
                edgecolor=colors[i],
                linestyle='--',
                linewidth=2,
                alpha=0.6,
                label=f'{dataset_label} 95% CI'
            )
        elif not show_ellipses:
            print(f"[DEBUG] Ellipses disabled by user (show_ellipses=False) for '{dataset_label}'")
        else:
            print(f"[DEBUG] Skipping ellipse for '{dataset_label}' (only {num_points} points, need â‰¥3)")
    
    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)',
                   fontsize=12, fontweight='bold')
    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)',
                   fontsize=12, fontweight='bold')
    
    # Title changes based on whether ellipses are shown
    if show_ellipses:
        ax1.set_title('PCA Score Plot with 95% Confidence Ellipses', fontsize=14, fontweight='bold')
    else:
        ax1.set_title('PCA Score Plot', fontsize=14, fontweight='bold')
    
    # Larger legend with better visibility
    ax1.legend(loc='best', framealpha=0.95, fontsize=10, 
              edgecolor='#cccccc', fancybox=True, shadow=True)
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='k', linestyle='--', linewidth=0.5, alpha=0.5)
    ax1.axvline(x=0, color='k', linestyle='--', linewidth=0.5, alpha=0.5)
    
    print("[DEBUG] PCA scores plot created successfully")
    
    # === FIGURE 3: Scree Plot (Variance Explained) ===
    fig_scree = None
    if show_scree:
        print("[DEBUG] Creating scree plot...")
        fig_scree, ax_scree = plt.subplots(figsize=(10, 6))
        
        # Plot cumulative and individual variance
        pc_indices = np.arange(1, n_components + 1)
        explained_variance = pca.explained_variance_ratio_ * 100
        cumulative_variance = np.cumsum(explained_variance)
        
        # Bar plot for individual variance
        ax_scree.bar(pc_indices, explained_variance, alpha=0.7, color='#0078d4', 
                    edgecolor='#005a9e', linewidth=1.5, label='Individual Variance')
        
        # Line plot for cumulative variance
        ax2 = ax_scree.twinx()
        ax2.plot(pc_indices, cumulative_variance, color='#d13438', marker='o', 
                linewidth=2.5, markersize=8, label='Cumulative Variance')
        
        # Add value labels
        for i, (var, cum) in enumerate(zip(explained_variance, cumulative_variance)):
            ax_scree.text(i+1, var + 1, f'{var:.1f}%', ha='center', va='bottom', 
                         fontsize=10, fontweight='bold')
            if i < 5:  # Only label first 5 components
                ax2.text(i+1, cum - 3, f'{cum:.1f}%', ha='center', va='top',
                        fontsize=9, color='#d13438', fontweight='bold')
        
        ax_scree.set_xlabel('Principal Component', fontsize=12, fontweight='bold')
        ax_scree.set_ylabel('Variance Explained (%)', fontsize=12, fontweight='bold', color='#0078d4')
        ax2.set_ylabel('Cumulative Variance (%)', fontsize=12, fontweight='bold', color='#d13438')
        ax_scree.set_title('Scree Plot: Variance Explained by Each PC', fontsize=14, fontweight='bold')
        ax_scree.set_xticks(pc_indices)
        ax_scree.set_ylim(0, max(explained_variance) * 1.15)
        ax2.set_ylim(0, 105)
        ax_scree.grid(True, alpha=0.3, axis='y')
        ax_scree.legend(loc='upper left', fontsize=11)
        ax2.legend(loc='upper right', fontsize=11)
        ax_scree.tick_params(axis='y', labelcolor='#0078d4')
        ax2.tick_params(axis='y', labelcolor='#d13438')
        fig_scree.tight_layout()
        print("[DEBUG] Scree plot created successfully")
    
    # === FIGURE 4: Biplot (Scores + Loadings Overlay) ===
    fig_biplot = None
    if show_loadings and n_components >= 2:
        print("[DEBUG] Creating biplot...")
        fig_biplot, ax_biplot = plt.subplots(figsize=(12, 10))
        
        # Plot scores (same as primary figure but without ellipses for clarity)
        for i, dataset_label in enumerate(unique_labels):
            mask = np.array([l == dataset_label for l in labels])
            ax_biplot.scatter(scores[mask, 0], scores[mask, 1],
                            c=[colors[i]], label=dataset_label, s=60, alpha=0.6,
                            edgecolors='white', linewidths=0.5)
        
        # Overlay loadings as arrows (scaled for visibility)
        loading_scale = np.max(np.abs(scores[:, :2])) * 0.8
        
        # Select top contributing wavenumbers (peaks in loadings)
        pc1_loadings = pca.components_[0]
        pc2_loadings = pca.components_[1]
        loading_magnitude = np.sqrt(pc1_loadings**2 + pc2_loadings**2)
        
        # Show top 15 most influential wavenumbers
        top_indices = np.argsort(loading_magnitude)[-15:]
        
        for idx in top_indices:
            ax_biplot.arrow(0, 0,
                           pc1_loadings[idx] * loading_scale,
                           pc2_loadings[idx] * loading_scale,
                           head_width=loading_scale*0.02, head_length=loading_scale*0.03,
                           fc='#d13438', ec='#8b0000', alpha=0.8, linewidth=0.8)
            
            # Label with wavenumber - thinner text, no box to be cleaner
            ax_biplot.text(pc1_loadings[idx] * loading_scale * 1.15,
                          pc2_loadings[idx] * loading_scale * 1.15,
                          f'{int(wavenumbers[idx])}',
                          fontsize=8, ha='center', va='center', color='#8b0000', fontweight='bold')
        
        ax_biplot.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', 
                           fontsize=12, fontweight='bold')
        ax_biplot.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', 
                           fontsize=12, fontweight='bold')
        ax_biplot.set_title('PCA Biplot: Scores + Influential Wavenumbers', 
                          fontsize=14, fontweight='bold')
        ax_biplot.legend(loc='best', fontsize=11, framealpha=0.9)
        ax_biplot.grid(True, alpha=0.3)
        ax_biplot.axhline(y=0, color='k', linestyle='--', linewidth=0.5, alpha=0.3)
        ax_biplot.axvline(x=0, color='k', linestyle='--', linewidth=0.5, alpha=0.3)
        fig_biplot.tight_layout()
        print("[DEBUG] Biplot created successfully")
    
    # === FIGURE 5: Cumulative Variance Explained ===
    fig_cumvar = None
    if show_scree:
        print("[DEBUG] Creating cumulative variance plot...")
        fig_cumvar, ax_cumvar = plt.subplots(figsize=(10, 6))
        
        pc_indices = np.arange(1, n_components + 1)
        cumulative_variance = np.cumsum(pca.explained_variance_ratio_ * 100)
        
        # Area plot
        ax_cumvar.fill_between(pc_indices, cumulative_variance, alpha=0.4, color='#28a745')
        ax_cumvar.plot(pc_indices, cumulative_variance, color='#28a745', marker='o',
                      linewidth=3, markersize=10, markerfacecolor='white',
                      markeredgewidth=2, markeredgecolor='#28a745')
        
        # Add threshold lines
        ax_cumvar.axhline(y=80, color='#ffc107', linestyle='--', linewidth=2, 
                         label='80% Threshold', alpha=0.7)
        ax_cumvar.axhline(y=95, color='#dc3545', linestyle='--', linewidth=2,
                         label='95% Threshold', alpha=0.7)
        
        # Annotate values
        for i, cum_var in enumerate(cumulative_variance):
            ax_cumvar.text(i+1, cum_var + 2, f'{cum_var:.1f}%',
                          ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        ax_cumvar.set_xlabel('Number of Principal Components', fontsize=12, fontweight='bold')
        ax_cumvar.set_ylabel('Cumulative Variance Explained (%)', fontsize=12, fontweight='bold')
        ax_cumvar.set_title('Cumulative Variance Explained', fontsize=14, fontweight='bold')
        ax_cumvar.set_xticks(pc_indices)
        ax_cumvar.set_ylim(0, 105)
        ax_cumvar.grid(True, alpha=0.3)
        ax_cumvar.legend(loc='lower right', fontsize=11)
        fig_cumvar.tight_layout()
        print("[DEBUG] Cumulative variance plot created successfully")
    
    if progress_callback:
        progress_callback(75)
    
    # === FIGURE 2: Loadings Plot (Spectral interpretation) - ENHANCED WITH SUBPLOTS ===
    print(f"[DEBUG] show_loadings parameter: {show_loadings}")
    fig_loadings = None
    if show_loadings:
        print("[DEBUG] Creating loadings figure with subplots...")
        
        # Get max_loadings_components parameter (default 3, max 5)
        max_loadings = params.get("max_loadings_components", 3)
        max_loadings = min(max_loadings, n_components, 5)  # Ensure within bounds
        
        print(f"[DEBUG] Creating {max_loadings} loading subplot(s)")
        
        # Create subplot grid (vertical stack for better readability)
        fig_loadings, axes = plt.subplots(max_loadings, 1, figsize=(12, 4 * max_loadings))
        
        # Handle single subplot case (axes won't be array)
        if max_loadings == 1:
            axes = [axes]
        
        # Color palette for components
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        
        # Plot each component in its own subplot
        for pc_idx in range(max_loadings):
            ax = axes[pc_idx]
            
            # Plot loadings for this component
            ax.plot(wavenumbers, pca.components_[pc_idx], 
                   linewidth=2, color=colors[pc_idx], label=f'PC{pc_idx+1}')
            
            # Explained variance for this component
            explained_var = pca.explained_variance_ratio_[pc_idx] * 100
            
            # Styling
            ax.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=11, fontweight='bold')
            ax.set_ylabel('Loading Value', fontsize=11, fontweight='bold')
            ax.set_title(f'PC{pc_idx+1} Loadings (Explained Variance: {explained_var:.2f}%)', 
                        fontsize=12, fontweight='bold')
            ax.legend(loc='upper right', fontsize=10)
            ax.grid(True, alpha=0.3)
            ax.invert_xaxis()  # Raman convention: high to low wavenumber
            # Remove x-axis tick labels (wavenumbers) as requested
            ax.set_xticklabels([])
            
            # Annotate top 3 peak positions for this component
            loadings = pca.components_[pc_idx]
            abs_loadings = np.abs(loadings)
            top_indices = np.argsort(abs_loadings)[-3:]  # Top 3 peaks
            
            for peak_idx in top_indices:
                peak_wn = wavenumbers[peak_idx]
                peak_val = loadings[peak_idx]
                ax.plot(peak_wn, peak_val, 'o', color=colors[pc_idx], markersize=6, 
                       markeredgecolor='black', markeredgewidth=0.5)
                ax.annotate(f'{peak_wn:.0f}', 
                           xy=(peak_wn, peak_val), 
                           xytext=(0, 10 if peak_val > 0 else -15),
                           textcoords='offset points',
                           fontsize=8, fontweight='bold',
                           ha='center',
                           bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8, edgecolor='#cccccc'))
        
        fig_loadings.tight_layout()
        print(f"[DEBUG] Loadings figure created successfully with {max_loadings} subplots")
    else:
        print("[DEBUG] Loadings figure skipped (show_loadings=False)")
    
    if progress_callback:
        progress_callback(80)
    
    # === FIGURE 3: Score Distributions (CRITICAL for Raman classification) ===
    fig_distributions = None
    if show_distributions and len(unique_labels) > 1:
        # Get number of components to show (default 3, max 6)
        n_dist_comps = params.get("n_distribution_components", 3)
        n_pcs_to_plot = min(n_dist_comps, n_components)
        
        # Calculate grid dimensions (max 2 columns)
        n_cols = 2 if n_pcs_to_plot > 1 else 1
        n_rows = int(np.ceil(n_pcs_to_plot / n_cols))
        
        # Create figure with appropriate size
        fig_distributions, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 4*n_rows))
        
        # Flatten axes for easy iteration if multiple
        if n_pcs_to_plot > 1:
            axes_flat = axes.flatten()
        else:
            axes_flat = [axes]
            
        fig_distributions.suptitle('PC Score Distributions', fontsize=16, fontweight='bold')
        
        # Plot distributions for each PC
        for idx in range(n_pcs_to_plot):
            ax = axes_flat[idx]
            pc_idx = idx  # 0-based index
            
            # Plot histogram/KDE for each dataset
            for i, dataset_label in enumerate(unique_labels):
                mask = np.array([l == dataset_label for l in labels])
                pc_scores = scores[mask, pc_idx]
                
                # Calculate KDE (Kernel Density Estimation)
                try:
                    kde = stats.gaussian_kde(pc_scores)
                    x_range = np.linspace(pc_scores.min() - 1, pc_scores.max() + 1, 200)
                    kde_values = kde(x_range)
                    
                    # Plot KDE curve
                    ax.plot(x_range, kde_values, color=colors[i], linewidth=2.5,
                           label=dataset_label, alpha=0.9)
                    
                    # Fill under curve for visibility
                    ax.fill_between(x_range, kde_values, alpha=0.25, color=colors[i])
                except Exception:
                    # Fallback if KDE fails (e.g. singular matrix due to too few points)
                    pass
                
                # Add histogram for reference
                ax.hist(pc_scores, bins=20, density=True, alpha=0.15,
                       color=colors[i], edgecolor='white', linewidth=0.5)
            
            # Statistical test (Mann-Whitney U for 2 groups)
            if len(unique_labels) == 2:
                mask1 = np.array([l == unique_labels[0] for l in labels])
                mask2 = np.array([l == unique_labels[1] for l in labels])
                pc1_scores = scores[mask1, pc_idx]
                pc2_scores = scores[mask2, pc_idx]
                
                try:
                    # Mann-Whitney U test
                    statistic, p_value = stats.mannwhitneyu(pc1_scores, pc2_scores)
                    
                    # Calculate effect size (Cohen's d)
                    mean_diff = np.mean(pc1_scores) - np.mean(pc2_scores)
                    pooled_std = np.sqrt((np.std(pc1_scores)**2 + np.std(pc2_scores)**2) / 2)
                    cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0
                    
                    # Add statistical annotation
                    ax.text(0.05, 0.95, 
                           f'Mannâ€“Whitney U\np={p_value:.2e}\nÎ´={cohens_d:.2f}',
                           transform=ax.transAxes, fontsize=10,
                           verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))
                except Exception:
                    pass
            
            # Formatting
            ax.set_xlabel(f'PC{pc_idx+1} Score', fontsize=12, fontweight='bold')
            ax.set_ylabel('Density', fontsize=12, fontweight='bold')
            ax.set_title(f'PC{pc_idx+1} ({pca.explained_variance_ratio_[pc_idx]*100:.1f}%)',
                        fontsize=13, fontweight='bold')
            if idx == 0:  # Only show legend on first plot to save space
                ax.legend(loc='upper right', fontsize=10, framealpha=0.9)
            ax.grid(True, alpha=0.3, axis='y')
            ax.axvline(x=0, color='k', linestyle='--', linewidth=0.5, alpha=0.5)
            
        # Hide empty subplots if any
        # Ensure axes_flat is always a list/array even if single subplot
        if not isinstance(axes_flat, (list, np.ndarray)):
            axes_flat = [axes_flat]
            
        if n_pcs_to_plot < len(axes_flat):
            for idx in range(n_pcs_to_plot, len(axes_flat)):
                axes_flat[idx].axis('off')
                axes_flat[idx].set_visible(False) # Explicitly hide
        
        plt.tight_layout()
    
    if progress_callback:
        progress_callback(90)
    
    # Create data table with dataset labels
    pc_columns = [f'PC{i+1}' for i in range(n_components)]
    scores_df = pd.DataFrame(scores, columns=pc_columns)
    scores_df['Dataset'] = labels
    
    # === ENHANCED SUMMARY TEXT ===
    n_datasets = len(unique_labels)
    total_spectra = X.shape[0]
    total_variance = np.sum(pca.explained_variance_ratio_[:min(3, n_components)]) * 100
    
    # Header
    summary = f"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
    summary += f"â•‘       PCA ANALYSIS RESULTS - COMPREHENSIVE SUMMARY    â•‘\n"
    summary += f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
    
    # Basic Information
    summary += f"ðŸ“Š ANALYSIS OVERVIEW\n"
    summary += f"{'â”€' * 55}\n"
    summary += f"  Total Datasets:    {n_datasets}\n"
    summary += f"  Total Spectra:     {total_spectra}\n"
    summary += f"  Components:        {n_components}\n"
    summary += f"  Scaling Method:    {scaling_type}\n"
    summary += f"  Datasets:          {', '.join(unique_labels)}\n\n"
    
    # Variance Explained
    summary += f"ðŸ“ˆ VARIANCE EXPLAINED\n"
    summary += f"{'â”€' * 55}\n"
    
    # Show variance for each component (up to 10)
    max_components_summary = min(10, n_components)
    for i in range(max_components_summary):
        var_pct = pca.explained_variance_ratio_[i] * 100
        cumvar_pct = np.sum(pca.explained_variance_ratio_[:i+1]) * 100
        
        # Visual bar for variance
        bar_length = int(var_pct / 2)  # Scale to 50 chars max
        bar = 'â–ˆ' * bar_length + 'â–‘' * (50 - bar_length)
        
        summary += f"  PC{i+1:2d}:  {var_pct:5.2f}% â”‚{bar}â”‚ Cumulative: {cumvar_pct:5.2f}%\n"
    
    if n_components > 10:
        remaining_var = np.sum(pca.explained_variance_ratio_[10:]) * 100
        summary += f"  ...   {remaining_var:5.2f}% (remaining {n_components-10} components)\n"
    
    summary += f"\n  First 3 PCs:       {total_variance:.2f}% of total variance\n"
    cumvar_all = np.sum(pca.explained_variance_ratio_) * 100
    summary += f"  All {n_components} PCs:        {cumvar_all:.2f}% of total variance\n\n"
    
    # Top Spectral Features per Component
    summary += f"ðŸ”¬ TOP SPECTRAL FEATURES (Peak Wavenumbers)\n"
    summary += f"{'â”€' * 55}\n"
    
    max_components_features = min(5, n_components)  # Show top 5 components
    for pc_idx in range(max_components_features):
        loadings = pca.components_[pc_idx]
        abs_loadings = np.abs(loadings)
        top_3_indices = np.argsort(abs_loadings)[-3:][::-1]  # Top 3 peaks, descending
        
        top_features = [f"{wavenumbers[idx]:.0f} cmâ»Â¹" for idx in top_3_indices]
        summary += f"  PC{pc_idx+1}:  {', '.join(top_features)}\n"
    
    summary += f"\n"
    
    # Group Separation Analysis (for binary comparison)
    if len(unique_labels) == 2:
        summary += f"ðŸ“‰ GROUP SEPARATION ANALYSIS\n"
        summary += f"{'â”€' * 55}\n"
        
        mask1 = np.array([l == unique_labels[0] for l in labels])
        mask2 = np.array([l == unique_labels[1] for l in labels])
        
        # PC1 separation
        pc1_mean1 = np.mean(scores[mask1, 0])
        pc1_mean2 = np.mean(scores[mask2, 0])
        pc1_separation = abs(pc1_mean1 - pc1_mean2)
        
        pc1_std1 = np.std(scores[mask1, 0])
        pc1_std2 = np.std(scores[mask2, 0])
        pc1_pooled_std = np.sqrt((pc1_std1**2 + pc1_std2**2) / 2)
        
        cohens_d = pc1_separation / pc1_pooled_std if pc1_pooled_std > 0 else 0
        
        summary += f"  Groups:            {unique_labels[0]} vs {unique_labels[1]}\n"
        summary += f"  PC1 Mean Diff:     {pc1_separation:.3f}\n"
        summary += f"  Cohen's d:         {cohens_d:.3f}\n"
        
        if cohens_d > 0.8:
            effect = "LARGE (Excellent separation)"
            indicator = "âœ“âœ“âœ“"
        elif cohens_d > 0.5:
            effect = "MEDIUM (Moderate separation)"
            indicator = "âœ“âœ“"
        elif cohens_d > 0.2:
            effect = "SMALL (Weak separation)"
            indicator = "âœ“"
        else:
            effect = "NEGLIGIBLE (Poor separation)"
            indicator = "âœ—"
        
        summary += f"  Effect Size:       {indicator} {effect}\n\n"
    
    # Interpretation Guide
    summary += f"ðŸ’¡ INTERPRETATION GUIDE\n"
    summary += f"{'â”€' * 55}\n"
    summary += f"  â€¢ Scores Plot:     Shows sample clustering in PC space\n"
    summary += f"  â€¢ Loadings Plot:   Shows spectral features driving each PC\n"
    summary += f"  â€¢ High loading:    Strong contribution to that component\n"
    summary += f"  â€¢ Clusters:        Biochemically similar samples group together\n"
    summary += f"  â€¢ Outliers:        Samples far from origin may be anomalous\n\n"
    
    if show_loadings:
        max_loadings = params.get("max_loadings_components", 3)
        max_loadings = min(max_loadings, n_components, 5)
        summary += f"  Loading plots generated for first {max_loadings} component(s)\n"
    
    summary += f"\n{'â•' * 55}\n"
    
    print(f"[DEBUG] Enhanced summary generated ({len(summary)} characters)")
    # Statistical summary for multi-dataset comparison
    detailed_summary = f"Scaling: {scaling_type}\nTotal spectra: {X.shape[0]}\n"
    detailed_summary += f"Datasets: {n_datasets} groups\n"
    
    if len(unique_labels) == 2:
        # Add separation metrics for binary comparison
        mask1 = np.array([l == unique_labels[0] for l in labels])
        mask2 = np.array([l == unique_labels[1] for l in labels])
        
        # Calculate separation in PC1
        pc1_separation = abs(np.mean(scores[mask1, 0]) - np.mean(scores[mask2, 0]))
        pc1_pooled_std = np.sqrt((np.std(scores[mask1, 0])**2 + np.std(scores[mask2, 0])**2) / 2)
        separation_ratio = pc1_separation / pc1_pooled_std if pc1_pooled_std > 0 else 0
        
        detailed_summary += f"\nPC1 Separation:\n"
        detailed_summary += f"  Mean difference: {pc1_separation:.2f}\n"
        detailed_summary += f"  Cohen's d: {separation_ratio:.2f}\n"
        
        if separation_ratio > 0.8:
            detailed_summary += "  Interpretation: Large effect (good separation)"
        elif separation_ratio > 0.5:
            detailed_summary += "  Interpretation: Medium effect (moderate separation)"
        else:
            detailed_summary += "  Interpretation: Small effect (limited separation)"
    
    # Debug logging for returned figures
    print(f"[DEBUG] PCA return values:")
    print(f"[DEBUG]   primary_figure (scores): {fig1 is not None}")
    print(f"[DEBUG]   loadings_figure: {fig_loadings is not None}")
    print(f"[DEBUG]   distributions_figure: {fig_distributions is not None}")
    
    if fig_loadings is None:
        print(f"[DEBUG] WARNING: loadings_figure is None! show_loadings={show_loadings}")
    
    print(f"[DEBUG] PCA return values:")
    print(f"[DEBUG]   primary_figure (scores): {fig1 is not None}")
    print(f"[DEBUG]   scree_figure: {fig_scree is not None}")
    print(f"[DEBUG]   loadings_figure: {fig_loadings is not None}")
    print(f"[DEBUG]   biplot_figure: {fig_biplot is not None}")
    print(f"[DEBUG]   cumulative_variance_figure: {fig_cumvar is not None}")
    print(f"[DEBUG]   distributions_figure: {fig_distributions is not None}")
    
    return {
        "primary_figure": fig1,  # Scores plot with confidence ellipses (PC1 vs PC2)
        "scree_figure": fig_scree,  # Scree plot (variance explained per PC)
        "loadings_figure": fig_loadings,  # Loadings plot (spectral features)
        "biplot_figure": fig_biplot,  # Biplot (scores + loading arrows)
        "cumulative_variance_figure": fig_cumvar,  # Cumulative variance plot
        "distributions_figure": fig_distributions,  # Score distributions (separate tab)
        "secondary_figure": None,  # Deprecated - kept for compatibility
        "data_table": scores_df,
        "summary_text": summary,
        "detailed_summary": detailed_summary,
        "raw_results": {
            "pca_model": pca,
            "scores": scores,
            "loadings": pca.components_,
            "explained_variance": pca.explained_variance_ratio_,
            "labels": labels,
            "unique_labels": unique_labels
        }
    }



def perform_umap_analysis(dataset_data: Dict[str, pd.DataFrame],
                         params: Dict[str, Any],
                         progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform UMAP dimensionality reduction with multi-dataset support.
    
    Similar to PCA, supports group assignment for classification tasks.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - n_neighbors: Number of neighbors (default 15)
            - min_dist: Minimum distance (default 0.1)
            - n_components: Number of components (default 2)
            - metric: Distance metric (default 'euclidean')
            - _group_labels: Optional {dataset_name: group_label} mapping
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with embedding plot and results
    """
    if not UMAP_AVAILABLE:
        raise ImportError("UMAP is not installed. Install with: pip install umap-learn")
    
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    n_neighbors = params.get("n_neighbors", 15)
    min_dist = params.get("min_dist", 0.1)
    n_components = params.get("n_components", 2)
    metric = params.get("metric", "euclidean")
    group_labels_map = params.get("_group_labels", None)  # {dataset_name: group_label}
    
    print(f"[DEBUG] UMAP parameters: n_neighbors={n_neighbors}, min_dist={min_dist}, metric={metric}")
    print(f"[DEBUG] Group labels map: {group_labels_map}")
    
    # Combine all datasets (like PCA approach)
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        spectra_matrix = df.values.T
        all_spectra.append(spectra_matrix)
        
        # Use group label if available, otherwise use dataset name
        if group_labels_map and dataset_name in group_labels_map:
            label = group_labels_map[dataset_name]
        else:
            label = dataset_name
        
        labels.extend([label] * spectra_matrix.shape[0])
    
    X = np.vstack(all_spectra)
    
    print(f"[DEBUG] Combined matrix shape: {X.shape}")
    print(f"[DEBUG] Unique labels: {sorted(set(labels))}")
    
    if progress_callback:
        progress_callback(30)
    
    # Perform UMAP
    print(f"[DEBUG] Running UMAP with n_neighbors={n_neighbors}, min_dist={min_dist}")
    reducer = umap.UMAP(
        n_neighbors=n_neighbors,
        min_dist=min_dist,
        n_components=n_components,
        metric=metric,
        random_state=42
    )
    embedding = reducer.fit_transform(X)
    
    if progress_callback:
        progress_callback(80)
    
    # Create figure with high-contrast colors (like PCA)
    fig, ax = plt.subplots(figsize=(12, 10))
    
    unique_labels = sorted(set(labels))
    num_groups = len(unique_labels)
    
    # Use same color scheme as PCA for consistency
    if num_groups == 2:
        colors = ['#0066cc', '#ffd700']  # Blue and Gold
    elif num_groups == 3:
        colors = ['#0066cc', '#cc0000', '#00cc66']  # Blue, Red, Green
    else:
        colors = plt.cm.tab10(np.linspace(0, 1, num_groups))
    
    print(f"[DEBUG] Plotting {num_groups} groups with high-contrast colors")
    
    for i, dataset_label in enumerate(unique_labels):
        mask = np.array([l == dataset_label for l in labels])
        num_points = np.sum(mask)
        print(f"[DEBUG] Group '{dataset_label}': {num_points} spectra")
        
        ax.scatter(embedding[mask, 0], embedding[mask, 1],
                  color=colors[i], label=dataset_label,
                  alpha=0.7, s=100, edgecolors='white', linewidth=1.5)
    
    ax.set_xlabel('UMAP 1', fontsize=12, fontweight='bold')
    ax.set_ylabel('UMAP 2', fontsize=12, fontweight='bold')
    ax.set_title('UMAP Projection', fontsize=14, fontweight='bold')
    ax.legend(loc='best', framealpha=0.95, fontsize=10, 
              edgecolor='#cccccc', fancybox=True, shadow=True)
    ax.grid(True, alpha=0.3)
    
    # Create data table
    embedding_df = pd.DataFrame(
        embedding,
        columns=[f'UMAP{i+1}' for i in range(n_components)]
    )
    embedding_df['Dataset'] = labels
    
    summary = f"UMAP completed with {n_components} components.\n"
    summary += f"Parameters: n_neighbors={n_neighbors}, min_dist={min_dist}, metric={metric}"
    
    return {
        "primary_figure": fig,
        "secondary_figure": None,
        "data_table": embedding_df,
        "summary_text": summary,
        "detailed_summary": f"Total spectra: {X.shape[0]}",
        "raw_results": {"embedding": embedding, "reducer": reducer},
        "loadings_figure": None  # UMAP does not produce loadings
    }


def perform_tsne_analysis(dataset_data: Dict[str, pd.DataFrame],
                         params: Dict[str, Any],
                         progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform t-SNE dimensionality reduction.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - perplexity: Perplexity parameter (default 30)
            - learning_rate: Learning rate (default 200)
            - n_iter: Number of iterations (default 1000)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with embedding plot and results
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    perplexity = params.get("perplexity", 30)
    learning_rate = params.get("learning_rate", 200)
    n_iter = params.get("n_iter", 1000)
    group_labels_map = params.get("_group_labels", None)  # {dataset_name: group_label}
    
    print(f"[DEBUG] t-SNE parameters: perplexity={perplexity}, learning_rate={learning_rate}")
    print(f"[DEBUG] t-SNE n_iter={n_iter} (will use as max_iter for sklearn)")
    
    # Combine all datasets
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        spectra_matrix = df.values.T
        all_spectra.append(spectra_matrix)
        
        # Use group label if available, otherwise use dataset name
        if group_labels_map and dataset_name in group_labels_map:
            label = group_labels_map[dataset_name]
        else:
            label = dataset_name
            
        labels.extend([label] * spectra_matrix.shape[0])
    
    X = np.vstack(all_spectra)
    n_samples = X.shape[0]
    
    # CRITICAL FIX: Perplexity must be less than n_samples
    if perplexity >= n_samples:
        new_perplexity = max(1, n_samples - 1)
        print(f"[DEBUG] Adjusting perplexity from {perplexity} to {new_perplexity} (n_samples={n_samples})")
        perplexity = new_perplexity
    
    if progress_callback:
        progress_callback(30)
    
    # Perform t-SNE (sklearn uses max_iter, not n_iter)
    print(f"[DEBUG] Creating TSNE with max_iter={n_iter}")
    tsne = TSNE(
        n_components=2,
        perplexity=perplexity,
        learning_rate=learning_rate,
        max_iter=n_iter,  # CRITICAL FIX: sklearn uses max_iter not n_iter
        random_state=42
    )
    embedding = tsne.fit_transform(X)
    
    if progress_callback:
        progress_callback(80)
    
    # Create figure
    fig, ax = plt.subplots(figsize=(10, 8))
    
    unique_labels = sorted(set(labels))
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    
    for i, dataset_label in enumerate(unique_labels):
        mask = np.array([l == dataset_label for l in labels])
        ax.scatter(embedding[mask, 0], embedding[mask, 1],
                  c=[colors[i]], label=dataset_label,
                  alpha=0.7, s=50)
    
    ax.set_xlabel('t-SNE 1', fontsize=12)
    ax.set_ylabel('t-SNE 2', fontsize=12)
    ax.set_title('t-SNE Projection', fontsize=14, fontweight='bold')
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)
    
    # Create data table
    embedding_df = pd.DataFrame(embedding, columns=['tSNE1', 'tSNE2'])
    embedding_df['Dataset'] = labels
    
    summary = f"t-SNE completed with 2 components.\n"
    summary += f"Parameters: perplexity={perplexity}, learning_rate={learning_rate}, n_iter={n_iter}"
    
    return {
        "primary_figure": fig,
        "secondary_figure": None,
        "data_table": embedding_df,
        "summary_text": summary,
        "detailed_summary": f"Total spectra: {X.shape[0]}",
        "detailed_summary": f"Total spectra: {X.shape[0]}",
        "raw_results": {"embedding": embedding},
        "loadings_figure": None  # t-SNE does not produce loadings
    }


def perform_hierarchical_clustering(dataset_data: Dict[str, pd.DataFrame],
                                   params: Dict[str, Any],
                                   progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform hierarchical clustering analysis.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - linkage_method: Linkage method (default 'ward')
            - distance_metric: Distance metric (default 'euclidean')
            - n_clusters: Number of clusters to color (optional)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with dendrogram and results
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    linkage_method = params.get("linkage_method", "ward")
    distance_metric = params.get("distance_metric", "euclidean")
    n_clusters = params.get("n_clusters", None)
    
    # Combine all datasets
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        spectra_matrix = df.values.T
        all_spectra.append(spectra_matrix)
        labels.extend([dataset_name] * spectra_matrix.shape[0])
    
    X = np.vstack(all_spectra)
    
    if progress_callback:
        progress_callback(40)
    
    # Perform hierarchical clustering
    if linkage_method == 'ward':
        Z = linkage(X, method='ward')
    else:
        distances = pdist(X, metric=distance_metric)
        Z = linkage(distances, method=linkage_method)
    
    if progress_callback:
        progress_callback(70)
    
    # Create dendrogram
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Calculate color threshold (70% of max distance)
    max_d = np.max(Z[:, 2])
    color_threshold = 0.7 * max_d
    
    # Plot dendrogram with improved visualization
    dend = dendrogram(
        Z, 
        ax=ax, 
        labels=labels if params.get("show_labels", False) else None,
        leaf_font_size=8,
        color_threshold=color_threshold,
        above_threshold_color='#bcbcbc'  # Light gray for upper links
    )
    
    # Add threshold line
    ax.axhline(y=color_threshold, c='r', lw=1, linestyle='--', alpha=0.5, label='Color Threshold')
    
    ax.set_xlabel('Sample Index', fontsize=12, fontweight='bold')
    ax.set_ylabel('Distance', fontsize=12, fontweight='bold')
    ax.set_title('Hierarchical Clustering Dendrogram', fontsize=14, fontweight='bold')
    ax.grid(True, axis='y', alpha=0.3)
    
    if params.get("show_labels", False):
        plt.setp(ax.get_xticklabels(), rotation=90)
    
    plt.tight_layout()
    
    summary = f"Hierarchical clustering completed.\n"
    summary += f"Linkage: {linkage_method}, Distance metric: {distance_metric}\n"
    summary += f"Total spectra: {X.shape[0]}"
    
    return {
        "primary_figure": fig,
        "secondary_figure": None,
        "data_table": None,
        "summary_text": summary,
        "detailed_summary": f"Linkage matrix shape: {Z.shape}",
        "raw_results": {"linkage_matrix": Z, "labels": labels},
        "loadings_figure": None  # Clustering does not produce loadings
    }


def perform_kmeans_clustering(dataset_data: Dict[str, pd.DataFrame],
                              params: Dict[str, Any],
                              progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform K-means clustering analysis.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - n_clusters: Number of clusters (default 3)
            - max_iter: Maximum iterations (default 300)
            - n_init: Number of initializations (default 10)
            - show_pca: Show clusters in PCA space
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with cluster visualization and results
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    n_clusters = params.get("n_clusters", 3)
    max_iter = params.get("max_iter", 300)
    n_init = params.get("n_init", 10)
    show_pca = params.get("show_pca", True)
    
    print(f"[DEBUG] K-Means parameters received:")
    print(f"[DEBUG]   n_clusters = {n_clusters} (type: {type(n_clusters).__name__})")
    print(f"[DEBUG]   n_init = {n_init} (type: {type(n_init).__name__})")
    print(f"[DEBUG]   max_iter = {max_iter} (type: {type(max_iter).__name__})")
    print(f"[DEBUG]   show_pca = {show_pca}")
    
    # Combine all datasets
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        spectra_matrix = df.values.T
        all_spectra.append(spectra_matrix)
        labels.extend([dataset_name] * spectra_matrix.shape[0])
    
    X = np.vstack(all_spectra)
    
    if progress_callback:
        progress_callback(30)
    
    # Perform K-means clustering
    print(f"[DEBUG] Creating KMeans with n_clusters={n_clusters}, n_init={n_init}, max_iter={max_iter}")
    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter,
                   n_init=n_init, random_state=42)
    print(f"[DEBUG] Fitting KMeans model...")
    cluster_labels = kmeans.fit_predict(X)
    print(f"[DEBUG] KMeans completed. Inertia: {kmeans.inertia_:.2f}")
    
    if progress_callback:
        progress_callback(60)
    
    # Create visualization
    if show_pca:
        # Project to PCA space for visualization
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X)
        centers_pca = pca.transform(kmeans.cluster_centers_)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # Plot clusters
        colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))
        for i in range(n_clusters):
            mask = cluster_labels == i
            ax.scatter(X_pca[mask, 0], X_pca[mask, 1],
                      c=[colors[i]], label=f'Cluster {i+1}',
                      alpha=0.7, s=50)
        
        # Plot centroids
        ax.scatter(centers_pca[:, 0], centers_pca[:, 1],
                  c='red', marker='X', s=200, edgecolors='black',
                  linewidths=2, label='Centroids')
        
        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)
        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)
        ax.set_title('K-means Clustering (PCA Projection)', fontsize=14, fontweight='bold')
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
    else:
        # Just show cluster assignments
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(range(len(cluster_labels)), cluster_labels)
        ax.set_xlabel('Sample Index', fontsize=12)
        ax.set_ylabel('Cluster ID', fontsize=12)
        ax.set_title('K-means Cluster Assignments', fontsize=14, fontweight='bold')
    
    if progress_callback:
        progress_callback(90)
    
    # Create data table
    results_df = pd.DataFrame({
        'Dataset': labels,
        'Cluster': cluster_labels
    })
    
    # Calculate cluster statistics
    cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
    
    summary = f"K-means clustering completed with {n_clusters} clusters.\n"
    for i in range(n_clusters):
        count = cluster_counts.get(i, 0)
        pct = count / len(cluster_labels) * 100
        summary += f"Cluster {i+1}: {count} spectra ({pct:.1f}%)\n"
    
    return {
        "primary_figure": fig,
        "secondary_figure": None,
        "data_table": results_df,
        "summary_text": summary,
        "detailed_summary": f"Inertia: {kmeans.inertia_:.2f}\nIterations: {kmeans.n_iter_}",
        "raw_results": {
            "kmeans_model": kmeans,
            "cluster_labels": cluster_labels,
            "cluster_centers": kmeans.cluster_centers_
        },
        "loadings_figure": None  # Clustering does not produce loadings
    }


def create_spectrum_preview_figure(dataset_data: Dict[str, pd.DataFrame]) -> Figure:
    """
    Create a preview figure of the spectra from all datasets.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
    
    Returns:
        Matplotlib Figure object
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # Use high-contrast colors
    colors = plt.cm.tab10(np.linspace(0, 1, max(1, len(dataset_data))))
    
    for i, (name, df) in enumerate(dataset_data.items()):
        wavenumbers = df.index.values
        # Plot mean spectrum
        mean_spectrum = df.mean(axis=1).values
        std_spectrum = df.std(axis=1).values
        
        color = colors[i]
        ax.plot(wavenumbers, mean_spectrum, label=name, color=color, linewidth=1.5)
        ax.fill_between(wavenumbers, mean_spectrum - std_spectrum, mean_spectrum + std_spectrum,
                       color=color, alpha=0.2)
    
    ax.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax.set_ylabel('Intensity', fontsize=12)
    ax.set_title('Spectral Data Preview (Mean Â± SD)', fontsize=14, fontweight='bold')
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)
    ax.invert_xaxis()  # Raman convention
    
    fig.tight_layout()
    return fig


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\methods\statistical.py ##

"""
Statistical Analysis Methods

This module implements statistical analysis methods for Raman spectra including
spectral comparison, peak analysis, correlation analysis, and ANOVA.
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Callable, Optional
from matplotlib import pyplot as plt
from matplotlib.figure import Figure
from scipy import stats
from scipy.signal import find_peaks
from sklearn.preprocessing import normalize


def perform_spectral_comparison(dataset_data: Dict[str, pd.DataFrame],
                                params: Dict[str, Any],
                                progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform statistical comparison of spectral datasets.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - confidence_level: Confidence level (default 0.95)
            - fdr_correction: Apply FDR correction (default True)
            - show_ci: Show confidence intervals (default True)
            - highlight_significant: Highlight significant regions (default True)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with comparison plots and statistics
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    confidence_level = params.get("confidence_level", 0.95)
    fdr_correction = params.get("fdr_correction", True)
    show_ci = params.get("show_ci", True)
    highlight_significant = params.get("highlight_significant", True)
    
    # Get datasets
    dataset_names = list(dataset_data.keys())
    if len(dataset_names) < 2:
        raise ValueError("At least 2 datasets required for comparison")
    
    # Extract first two datasets for comparison
    df1 = dataset_data[dataset_names[0]]
    df2 = dataset_data[dataset_names[1]]
    
    wavenumbers = df1.index.values
    
    if progress_callback:
        progress_callback(30)
    
    # Calculate means and standard errors
    mean1 = df1.mean(axis=1).values
    mean2 = df2.mean(axis=1).values
    sem1 = df1.sem(axis=1).values
    sem2 = df2.sem(axis=1).values
    
    # Calculate confidence intervals
    z_score = stats.norm.ppf((1 + confidence_level) / 2)
    ci1 = z_score * sem1
    ci2 = z_score * sem2
    
    if progress_callback:
        progress_callback(50)
    
    # Perform t-tests at each wavenumber
    p_values = []
    for i in range(len(wavenumbers)):
        spec1 = df1.iloc[i, :].values
        spec2 = df2.iloc[i, :].values
        _, p = stats.ttest_ind(spec1, spec2)
        p_values.append(p)
    
    p_values = np.array(p_values)
    
    # FDR correction if requested
    if fdr_correction:
        from statsmodels.stats.multitest import fdrcorrection
        _, p_corrected = fdrcorrection(p_values, alpha=1-confidence_level)
        significant_mask = p_corrected < (1 - confidence_level)
    else:
        significant_mask = p_values < (1 - confidence_level)
    
    if progress_callback:
        progress_callback(70)
    
    # Create primary figure: Mean spectra with CI
    fig1, ax1 = plt.subplots(figsize=(12, 6))
    
    ax1.plot(wavenumbers, mean1, label=dataset_names[0], linewidth=2, color='blue')
    ax1.plot(wavenumbers, mean2, label=dataset_names[1], linewidth=2, color='red')
    
    if show_ci:
        ax1.fill_between(wavenumbers, mean1 - ci1, mean1 + ci1,
                        alpha=0.2, color='blue')
        ax1.fill_between(wavenumbers, mean2 - ci2, mean2 + ci2,
                        alpha=0.2, color='red')
    
    if highlight_significant:
        # Highlight significant regions
        sig_regions = np.where(significant_mask)[0]
        if len(sig_regions) > 0:
            y_min, y_max = ax1.get_ylim()
            for idx in sig_regions:
                ax1.axvspan(wavenumbers[idx]-2, wavenumbers[idx]+2,
                          alpha=0.1, color='yellow')
    
    ax1.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax1.set_ylabel('Intensity', fontsize=12)
    ax1.set_title('Spectral Comparison', fontsize=14, fontweight='bold')
    ax1.legend(loc='best')
    ax1.grid(True, alpha=0.3)
    ax1.invert_xaxis()
    
    # Create secondary figure: P-value plot
    fig2, ax2 = plt.subplots(figsize=(12, 4))
    
    ax2.plot(wavenumbers, -np.log10(p_values), linewidth=1.5, color='black')
    ax2.axhline(-np.log10(1-confidence_level), color='red', linestyle='--',
               label=f'{confidence_level*100:.0f}% significance')
    ax2.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax2.set_ylabel('-logâ‚â‚€(p-value)', fontsize=12)
    ax2.set_title('Statistical Significance', fontsize=14, fontweight='bold')
    ax2.legend(loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.invert_xaxis()
    
    if progress_callback:
        progress_callback(90)
    
    # Create data table
    results_df = pd.DataFrame({
        'Wavenumber': wavenumbers,
        f'{dataset_names[0]}_mean': mean1,
        f'{dataset_names[0]}_sem': sem1,
        f'{dataset_names[1]}_mean': mean2,
        f'{dataset_names[1]}_sem': sem2,
        'p_value': p_values,
        'significant': significant_mask
    })
    
    n_significant = np.sum(significant_mask)
    pct_significant = n_significant / len(wavenumbers) * 100
    
    summary = f"Spectral comparison between {dataset_names[0]} and {dataset_names[1]}.\n"
    summary += f"Significant regions: {n_significant} ({pct_significant:.1f}%)\n"
    summary += f"Confidence level: {confidence_level*100:.0f}%"
    if fdr_correction:
        summary += " (FDR corrected)"
    
    return {
        "primary_figure": fig1,
        "secondary_figure": fig2,
        "data_table": results_df,
        "summary_text": summary,
        "detailed_summary": f"Dataset 1 samples: {df1.shape[1]}, Dataset 2 samples: {df2.shape[1]}",
        "raw_results": {
            "p_values": p_values,
            "significant_mask": significant_mask,
            "means": [mean1, mean2],
            "sems": [sem1, sem2]
        }
    }


def perform_peak_analysis(dataset_data: Dict[str, pd.DataFrame],
                         params: Dict[str, Any],
                         progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform peak detection and analysis on spectra.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - prominence_threshold: Peak prominence threshold (default 0.05)
            - width_min: Minimum peak width (default 5)
            - top_n_peaks: Number of top peaks to analyze (default 20)
            - show_assignments: Show peak assignments (default True)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with peak analysis plots and table
    """
    import json
    import os
    
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    prominence_threshold = params.get("prominence_threshold", 0.05)
    width_min = params.get("width_min", 5)
    top_n_peaks = params.get("top_n_peaks", 20)
    show_assignments = params.get("show_assignments", True)
    
    # Load Raman peak assignments from JSON
    raman_peaks_data = {}
    try:
        peaks_json_path = os.path.join("assets", "data", "raman_peaks.json")
        if os.path.exists(peaks_json_path):
            with open(peaks_json_path, 'r', encoding='utf-8') as f:
                raman_peaks_data = json.load(f)
            print(f"[DEBUG] Loaded {len(raman_peaks_data)} peak assignments from raman_peaks.json")
        else:
            print(f"[DEBUG] WARNING: raman_peaks.json not found at {peaks_json_path}")
    except Exception as e:
        print(f"[DEBUG] ERROR loading raman_peaks.json: {e}")
    
    # Use first dataset for mean spectrum
    dataset_name = list(dataset_data.keys())[0]
    df = dataset_data[dataset_name]
    
    wavenumbers = df.index.values
    mean_spectrum = df.mean(axis=1).values
    
    if progress_callback:
        progress_callback(40)
    
    # Normalize spectrum for peak detection
    spectrum_normalized = (mean_spectrum - mean_spectrum.min()) / (mean_spectrum.max() - mean_spectrum.min())
    
    # Find peaks
    peaks, properties = find_peaks(
        spectrum_normalized,
        prominence=prominence_threshold,
        width=width_min
    )
    
    if progress_callback:
        progress_callback(70)
    
    # Get top N peaks by prominence
    prominences = properties['prominences']
    sorted_indices = np.argsort(prominences)[::-1][:top_n_peaks]
    top_peaks = peaks[sorted_indices]
    top_prominences = prominences[sorted_indices]
    
    print(f"[DEBUG] Peak detection: Found {len(peaks)} total peaks, showing top {len(top_peaks)} peaks")
    print(f"[DEBUG] top_n_peaks parameter: {top_n_peaks}")
    print(f"[DEBUG] Actual peaks shown: {len(top_peaks)}")
    
    # Helper function to find closest peak assignment
    def find_peak_assignment(wavenumber: float, tolerance: float = 10.0) -> str:
        """
        Find the closest peak assignment from raman_peaks.json.
        
        Args:
            wavenumber: Detected peak wavenumber
            tolerance: Maximum distance to consider a match (default 10 cmâ»Â¹)
        
        Returns:
            Component assignment string or empty string if no match
        """
        if not raman_peaks_data:
            return ""
        
        closest_match = None
        closest_distance = float('inf')
        
        for peak_wn_str, peak_info in raman_peaks_data.items():
            try:
                ref_wavenumber = float(peak_wn_str)
                distance = abs(wavenumber - ref_wavenumber)
                
                if distance < closest_distance and distance <= tolerance:
                    closest_distance = distance
                    closest_match = peak_info.get("assignment", "")
            except (ValueError, TypeError):
                continue
        
        if closest_match:
            # Truncate long assignments
            if len(closest_match) > 40:
                closest_match = closest_match[:37] + "..."
            return closest_match
        
        return ""
    
    # Create primary figure: Spectrum with peaks
    fig1, ax1 = plt.subplots(figsize=(14, 7))
    
    ax1.plot(wavenumbers, mean_spectrum, linewidth=1.5, color='blue', label='Mean spectrum')
    ax1.plot(wavenumbers[top_peaks], mean_spectrum[top_peaks],
            'ro', markersize=10, label=f'Top {len(top_peaks)} peaks', zorder=5)
    
    # Annotate ALL peaks with wavenumber AND component assignment labels
    print(f"[DEBUG] Adding wavenumber + component annotations for {len(top_peaks)} peaks")
    for i, peak_idx in enumerate(top_peaks):
        wavenumber = wavenumbers[peak_idx]
        intensity = mean_spectrum[peak_idx]
        
        # Find component assignment
        assignment = find_peak_assignment(wavenumber)
        
        # Build annotation text: wavenumber on first line, assignment on second line
        if show_assignments and assignment:
            annotation_text = f'{wavenumber:.0f} cmâ»Â¹\\n{assignment}'
        else:
            annotation_text = f'{wavenumber:.0f} cmâ»Â¹'
        
        # Alternate label positions to avoid overlap
        y_offset = 15 if i % 2 == 0 else 30
        
        # Use different colors for peaks with vs without assignments
        box_color = 'lightyellow' if assignment else 'lightgray'
        edge_color = 'orange' if assignment else 'gray'
        
        ax1.annotate(annotation_text,
                    xy=(wavenumber, intensity),
                    xytext=(0, y_offset), 
                    textcoords='offset points',
                    ha='center', 
                    fontsize=7 if assignment else 8,
                    fontweight='bold',
                    bbox=dict(boxstyle='round,pad=0.4', facecolor=box_color, alpha=0.8, edgecolor=edge_color),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='red', lw=1),
                    zorder=10)
        
        if assignment:
            print(f"[DEBUG] Peak {i+1}/{len(top_peaks)}: {wavenumber:.0f} cmâ»Â¹ â†’ {assignment[:30]}")
        else:
            print(f"[DEBUG] Peak {i+1}/{len(top_peaks)}: {wavenumber:.0f} cmâ»Â¹ (no assignment found)")
    
    ax1.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax1.set_ylabel('Intensity', fontsize=12)
    ax1.set_title('Peak Analysis with Component Assignments', fontsize=14, fontweight='bold')
    ax1.legend(loc='best')
    ax1.grid(True, alpha=0.3)
    ax1.invert_xaxis()
    
    # Create secondary figure: Peak intensity distribution
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    
    peak_wavenumbers = wavenumbers[top_peaks]
    peak_intensities = mean_spectrum[top_peaks]
    
    bars = ax2.bar(range(len(top_peaks)), peak_intensities, color='steelblue')
    ax2.set_xticks(range(len(top_peaks)))
    ax2.set_xticklabels([f'{wn:.0f}' for wn in peak_wavenumbers], rotation=45, ha='right')
    ax2.set_xlabel('Peak Position (cmâ»Â¹)', fontsize=12)
    ax2.set_ylabel('Peak Intensity', fontsize=12)
    ax2.set_title('Peak Intensity Distribution', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    
    if progress_callback:
        progress_callback(90)
    
    # Create data table with component assignments
    peak_assignments = [find_peak_assignment(wn) for wn in wavenumbers[top_peaks]]
    
    results_df = pd.DataFrame({
        'Peak_Position': wavenumbers[top_peaks],
        'Intensity': mean_spectrum[top_peaks],
        'Component_Assignment': peak_assignments,
        'Prominence': top_prominences,
        'Width': properties['widths'][sorted_indices]
    })
    results_df = results_df.sort_values('Intensity', ascending=False)
    
    summary = f"Peak analysis completed on {dataset_name}.\n"
    summary += f"Found {len(peaks)} peaks total, showing top {len(top_peaks)}.\n"
    summary += f"Peak detection threshold: prominence = {prominence_threshold:.3f}\n"
    if show_assignments:
        assigned_count = sum(1 for a in peak_assignments if a)
        summary += f"Component assignments: {assigned_count}/{len(top_peaks)} peaks matched\n"
    
    return {
        "primary_figure": fig1,
        "secondary_figure": fig2,
        "data_table": results_df,
        "summary_text": summary,
        "detailed_summary": f"Mean of {df.shape[1]} spectra analyzed",
        "raw_results": {
            "all_peaks": peaks,
            "top_peaks": top_peaks,
            "properties": properties
        }
    }


def perform_correlation_analysis(dataset_data: Dict[str, pd.DataFrame],
                                 params: Dict[str, Any],
                                 progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform correlation analysis between spectra.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - method: Correlation method ('pearson', 'spearman') (default 'pearson')
            - show_pvalues: Show p-value matrix (default False)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with correlation matrix and heatmap
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    method = params.get("method", "pearson")
    show_pvalues = params.get("show_pvalues", False)
    
    # Combine all datasets
    all_spectra = []
    labels = []
    
    for dataset_name, df in dataset_data.items():
        for col in df.columns:
            all_spectra.append(df[col].values)
            labels.append(f"{dataset_name}_{col}")
    
    # Create DataFrame
    spectra_df = pd.DataFrame(all_spectra, index=labels).T
    
    if progress_callback:
        progress_callback(40)
    
    # Calculate correlation matrix
    if method == "pearson":
        corr_matrix = spectra_df.corr(method='pearson')
    elif method == "spearman":
        corr_matrix = spectra_df.corr(method='spearman')
    else:
        corr_matrix = spectra_df.corr()
    
    if progress_callback:
        progress_callback(70)
    
    # Create heatmap
    fig, ax = plt.subplots(figsize=(10, 8))
    
    im = ax.imshow(corr_matrix.values, cmap='RdBu_r', aspect='auto',
                   vmin=-1, vmax=1)
    
    # Colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Correlation Coefficient', fontsize=12)
    
    # Labels
    ax.set_xticks(range(len(labels)))
    ax.set_yticks(range(len(labels)))
    ax.set_xticklabels(labels, rotation=90, fontsize=8)
    ax.set_yticklabels(labels, fontsize=8)
    
    ax.set_title(f'Correlation Matrix ({method.capitalize()})',
                fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    if progress_callback:
        progress_callback(90)
    
    # Statistics
    upper_triangle = np.triu(corr_matrix.values, k=1)
    upper_triangle_flat = upper_triangle[upper_triangle != 0]
    
    mean_corr = np.mean(upper_triangle_flat)
    std_corr = np.std(upper_triangle_flat)
    min_corr = np.min(upper_triangle_flat)
    max_corr = np.max(upper_triangle_flat)
    
    summary = f"Correlation analysis completed using {method} method.\n"
    summary += f"Mean correlation: {mean_corr:.3f} Â± {std_corr:.3f}\n"
    summary += f"Range: [{min_corr:.3f}, {max_corr:.3f}]"
    
    return {
        "primary_figure": fig,
        "secondary_figure": None,
        "data_table": corr_matrix,
        "summary_text": summary,
        "detailed_summary": f"Total spectra: {len(labels)}",
        "raw_results": {
            "correlation_matrix": corr_matrix.values,
            "labels": labels,
            "method": method
        }
    }


def perform_anova_test(dataset_data: Dict[str, pd.DataFrame],
                      params: Dict[str, Any],
                      progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
    """
    Perform ANOVA test across multiple datasets.
    
    Args:
        dataset_data: Dictionary of {dataset_name: DataFrame}
        params: Analysis parameters
            - alpha: Significance level (default 0.05)
            - post_hoc: Perform post-hoc tests (default True)
        progress_callback: Optional callback for progress updates
    
    Returns:
        Dictionary with ANOVA results and plots
    """
    if progress_callback:
        progress_callback(10)
    
    # Get parameters
    alpha = params.get("alpha", 0.05)
    post_hoc = params.get("post_hoc", True)
    
    # Check number of groups
    if len(dataset_data) < 3:
        raise ValueError("At least 3 datasets required for ANOVA")
    
    # Get common wavenumbers
    dataset_names = list(dataset_data.keys())
    wavenumbers = dataset_data[dataset_names[0]].index.values
    
    if progress_callback:
        progress_callback(30)
    
    # Perform ANOVA at each wavenumber
    f_statistics = []
    p_values = []
    
    for i in range(len(wavenumbers)):
        groups = [dataset_data[name].iloc[i, :].values for name in dataset_names]
        f_stat, p_val = stats.f_oneway(*groups)
        f_statistics.append(f_stat)
        p_values.append(p_val)
    
    f_statistics = np.array(f_statistics)
    p_values = np.array(p_values)
    
    # Identify significant wavenumbers
    significant_mask = p_values < alpha
    
    if progress_callback:
        progress_callback(70)
    
    # Create primary figure: F-statistic plot
    fig1, (ax1a, ax1b) = plt.subplots(2, 1, figsize=(12, 8))
    
    ax1a.plot(wavenumbers, f_statistics, linewidth=1.5, color='blue')
    ax1a.set_ylabel('F-statistic', fontsize=12)
    ax1a.set_title('ANOVA Results', fontsize=14, fontweight='bold')
    ax1a.grid(True, alpha=0.3)
    ax1a.invert_xaxis()
    
    ax1b.plot(wavenumbers, -np.log10(p_values), linewidth=1.5, color='black')
    ax1b.axhline(-np.log10(alpha), color='red', linestyle='--',
                label=f'Î± = {alpha}')
    ax1b.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax1b.set_ylabel('-logâ‚â‚€(p-value)', fontsize=12)
    ax1b.legend(loc='best')
    ax1b.grid(True, alpha=0.3)
    ax1b.invert_xaxis()
    
    plt.tight_layout()
    
    # Create secondary figure: Mean spectra of all groups
    fig2, ax2 = plt.subplots(figsize=(12, 6))
    
    colors = plt.cm.tab10(np.linspace(0, 1, len(dataset_names)))
    for i, name in enumerate(dataset_names):
        mean_spec = dataset_data[name].mean(axis=1).values
        ax2.plot(wavenumbers, mean_spec, label=name, color=colors[i], linewidth=1.5)
    
    # Highlight significant regions
    if np.any(significant_mask):
        y_min, y_max = ax2.get_ylim()
        sig_regions = np.where(significant_mask)[0]
        for idx in sig_regions:
            ax2.axvspan(wavenumbers[idx]-2, wavenumbers[idx]+2,
                       alpha=0.1, color='yellow')
    
    ax2.set_xlabel('Wavenumber (cmâ»Â¹)', fontsize=12)
    ax2.set_ylabel('Intensity', fontsize=12)
    ax2.set_title('Mean Spectra by Group', fontsize=14, fontweight='bold')
    ax2.legend(loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.invert_xaxis()
    
    if progress_callback:
        progress_callback(90)
    
    # Create data table
    results_df = pd.DataFrame({
        'Wavenumber': wavenumbers,
        'F_statistic': f_statistics,
        'p_value': p_values,
        'Significant': significant_mask
    })
    
    n_significant = np.sum(significant_mask)
    pct_significant = n_significant / len(wavenumbers) * 100
    
    summary = f"ANOVA completed across {len(dataset_names)} groups.\n"
    summary += f"Significant wavenumbers: {n_significant} ({pct_significant:.1f}%)\n"
    summary += f"Significance level: Î± = {alpha}"
    
    return {
        "primary_figure": fig1,
        "secondary_figure": fig2,
        "data_table": results_df,
        "summary_text": summary,
        "detailed_summary": f"Groups: {', '.join(dataset_names)}",
        "raw_results": {
            "f_statistics": f_statistics,
            "p_values": p_values,
            "significant_mask": significant_mask,
            "dataset_names": dataset_names
        }
    }


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\registry.py ##

"""
Analysis Methods Registry

This module defines all available analysis methods with their configurations,
parameters, and visualization functions. Methods are organized by category:
- Exploratory Analysis
- Statistical Analysis
- Visualization Methods
"""

from typing import Dict, Any, Callable


# Analysis Methods Registry
ANALYSIS_METHODS: Dict[str, Dict[str, Dict[str, Any]]] = {
    "exploratory": {
        "pca": {
            "name": "PCA (Principal Component Analysis)",
            "description": "Dimensionality reduction using PCA to identify variance patterns. Select multiple datasets to compare groups (e.g., Control vs Disease).",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "n_components": {
                    "type": "spinbox",
                    "default": 3,
                    "range": (2, 100),  # Removed arbitrary limit - users should be free to choose based on their data
                    "label": "Number of Components"
                },
                "scaling": {
                    "type": "combo",
                    "options": ["StandardScaler", "MinMaxScaler", "None"],
                    "default": "StandardScaler",
                    "label": "Scaling Method"
                },
                "show_ellipses": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show 95% Confidence Ellipses"
                },
                "show_loadings": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show Loading Plot"
                },
                "max_loadings_components": {
                    "type": "spinbox",
                    "default": 3,
                    "range": (1, 5),
                    "label": "Loading Components to Plot (max 5)"
                },
                "show_scree": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show Scree Plot"
                },
                "show_distributions": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Score Distributions"
                },
                "n_distribution_components": {
                    "type": "spinbox",
                    "default": 3,
                    "range": (1, 6),
                    "label": "Distribution Components (max 6)"
                }
            },
            "function": "perform_pca_analysis"
        },
        "umap": {
            "name": "UMAP (Uniform Manifold Approximation)",
            "description": "Non-linear dimensionality reduction preserving local and global structure. Select multiple datasets to compare groups.",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "n_neighbors": {
                    "type": "spinbox",
                    "default": 15,
                    "range": (5, 100),
                    "label": "Number of Neighbors"
                },
                "min_dist": {
                    "type": "double_spinbox",
                    "default": 0.1,
                    "range": (0.0, 1.0),
                    "step": 0.05,
                    "label": "Minimum Distance"
                },
                "n_components": {
                    "type": "spinbox",
                    "default": 2,
                    "range": (2, 3),
                    "label": "Number of Dimensions"
                },
                "metric": {
                    "type": "combo",
                    "options": ["euclidean", "cosine", "manhattan", "correlation"],
                    "default": "euclidean",
                    "label": "Distance Metric"
                }
            },
            "function": "perform_umap_analysis"
        },
        "tsne": {
            "name": "t-SNE (t-Distributed Stochastic Neighbor Embedding)",
            "description": "Non-linear dimensionality reduction for cluster visualization",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "perplexity": {
                    "type": "spinbox",
                    "default": 30,
                    "range": (5, 100),
                    "label": "Perplexity"
                },
                "learning_rate": {
                    "type": "double_spinbox",
                    "default": 200.0,
                    "range": (10.0, 1000.0),
                    "step": 10.0,
                    "label": "Learning Rate"
                },
                "n_iter": {
                    "type": "spinbox",
                    "default": 1000,
                    "range": (250, 5000),
                    "label": "Max Iterations"
                }
            },
            "function": "perform_tsne_analysis"
        },
        "hierarchical_clustering": {
            "name": "Hierarchical Clustering with Dendrogram",
            "description": "Hierarchical cluster analysis with dendrogram visualization",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "n_clusters": {
                    "type": "spinbox",
                    "default": 3,
                    "range": (2, 20),
                    "label": "Number of Clusters"
                },
                "linkage_method": {
                    "type": "combo",
                    "options": ["ward", "complete", "average", "single"],
                    "default": "ward",
                    "label": "Linkage Method"
                },
                "distance_metric": {
                    "type": "combo",
                    "options": ["euclidean", "cosine", "manhattan", "correlation"],
                    "default": "euclidean",
                    "label": "Distance Metric"
                },
                "show_labels": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show Sample Labels"
                }
            },
            "function": "perform_hierarchical_clustering"
        },
        "kmeans": {
            "name": "K-Means Clustering",
            "description": "Partitioning clustering algorithm",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "n_clusters": {
                    "type": "spinbox",
                    "default": 3,
                    "range": (2, 20),
                    "label": "Number of Clusters"
                },
                "n_init": {
                    "type": "spinbox",
                    "default": 10,
                    "range": (1, 50),
                    "label": "Number of Initializations"
                },
                "max_iter": {
                    "type": "spinbox",
                    "default": 300,
                    "range": (10, 1000),
                    "label": "Max Iterations"
                },
                "show_elbow": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Elbow Plot"
                }
            },
            "function": "perform_kmeans_clustering"
        }
    },
    "statistical": {
        "spectral_comparison": {
            "name": "Group Mean Spectral Comparison",
            "description": "Compare mean spectra across groups with statistical testing",
            "min_datasets": 2,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "confidence_level": {
                    "type": "double_spinbox",
                    "default": 0.95,
                    "range": (0.80, 0.99),
                    "step": 0.01,
                    "label": "Confidence Level"
                },
                "fdr_correction": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Apply FDR Correction"
                },
                "show_ci": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Confidence Intervals"
                },
                "highlight_significant": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Highlight Significant Regions"
                }
            },
            "function": "perform_spectral_comparison"
        },
        "peak_analysis": {
            "name": "Peak Detection and Analysis",
            "description": "Automated peak detection with statistical comparison",
            "min_datasets": 1,
            "max_datasets": 1,
            "dataset_selection_mode": "single",
            "params": {
                "prominence_threshold": {
                    "type": "double_spinbox",
                    "default": 0.1,
                    "range": (0.01, 1.0),
                    "step": 0.01,
                    "label": "Prominence Threshold"
                },
                "width_min": {
                    "type": "spinbox",
                    "default": 5,
                    "range": (1, 50),
                    "label": "Minimum Peak Width"
                },
                "top_n_peaks": {
                    "type": "spinbox",
                    "default": 20,
                    "range": (5, 100),
                    "label": "Top N Peaks to Display"
                },
                "show_assignments": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Biochemical Assignments"
                }
            },
            "function": "perform_peak_analysis"
        },
        "correlation_analysis": {
            "name": "Spectral Correlation Analysis",
            "description": "Analyze correlations between spectral regions",
            "min_datasets": 1,
            "max_datasets": 1,
            "dataset_selection_mode": "single",
            "params": {
                "method": {
                    "type": "combo",
                    "options": ["pearson", "spearman", "kendall"],
                    "default": "pearson",
                    "label": "Correlation Method"
                },
                "show_heatmap": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Correlation Heatmap"
                },
                "threshold": {
                    "type": "double_spinbox",
                    "default": 0.7,
                    "range": (0.0, 1.0),
                    "step": 0.05,
                    "label": "Correlation Threshold"
                }
            },
            "function": "perform_correlation_analysis"
        },
        "anova_test": {
            "name": "ANOVA Statistical Test",
            "description": "One-way ANOVA across multiple groups",
            "min_datasets": 3,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "alpha": {
                    "type": "double_spinbox",
                    "default": 0.05,
                    "range": (0.01, 0.1),
                    "step": 0.01,
                    "label": "Significance Level (Î±)"
                },
                "post_hoc": {
                    "type": "combo",
                    "options": ["tukey", "bonferroni", "none"],
                    "default": "tukey",
                    "label": "Post-hoc Test"
                },
                "show_boxplot": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Box Plot"
                }
            },
            "function": "perform_anova_test"
        }
    },
    "visualization": {
        "heatmap": {
            "name": "Spectral Heatmap with Clustering",
            "description": "2D heatmap visualization with hierarchical clustering",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "cluster_rows": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Cluster Rows (Samples)"
                },
                "cluster_cols": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Cluster Columns (Wavenumbers)"
                },
                "colormap": {
                    "type": "combo",
                    "options": ["viridis", "plasma", "inferno", "magma", "cividis", "coolwarm", "RdYlBu"],
                    "default": "viridis",
                    "label": "Colormap"
                },
                "normalize": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Normalize Intensities"
                },
                "show_dendrograms": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Dendrograms"
                }
            },
            "function": "create_spectral_heatmap"
        },
        "mean_spectra_overlay": {
            "name": "Mean Spectra Overlay Plot",
            "description": "Overlay mean spectra from different groups/datasets",
            "min_datasets": 2,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "show_std": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Standard Deviation"
                },
                "show_ci": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show Confidence Intervals"
                },
                "alpha_fill": {
                    "type": "double_spinbox",
                    "default": 0.2,
                    "range": (0.0, 1.0),
                    "step": 0.05,
                    "label": "Fill Transparency"
                },
                "line_width": {
                    "type": "double_spinbox",
                    "default": 1.5,
                    "range": (0.5, 5.0),
                    "step": 0.5,
                    "label": "Line Width"
                }
            },
            "function": "create_mean_spectra_overlay"
        },
        "waterfall_plot": {
            "name": "Waterfall Plot",
            "description": "visualization of multiple spectra",
            "min_datasets": 1,
            "max_datasets": 1,
            "dataset_selection_mode": "single",
            "params": {
                "offset_scale": {
                    "type": "double_spinbox",
                    "default": 1.0,
                    "range": (0.1, 5.0),
                    "step": 0.1,
                    "label": "Offset Scale"
                },
                "max_spectra": {
                    "type": "spinbox",
                    "default": 50,
                    "range": (10, 200),
                    "label": "Maximum Spectra to Display"
                },
                "colormap": {
                    "type": "combo",
                    "options": ["viridis", "plasma", "coolwarm", "rainbow"],
                    "default": "viridis",
                    "label": "Colormap"
                }
            },
            "function": "create_waterfall_plot"
        },
        "correlation_heatmap": {
            "name": "Correlation Heatmap",
            "description": "Heatmap of pairwise spectral correlations",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "method": {
                    "type": "combo",
                    "options": ["pearson", "spearman"],
                    "default": "pearson",
                    "label": "Correlation Method"
                },
                "colormap": {
                    "type": "combo",
                    "options": ["coolwarm", "RdYlBu", "RdBu", "seismic"],
                    "default": "coolwarm",
                    "label": "Colormap"
                },
                "show_values": {
                    "type": "checkbox",
                    "default": False,
                    "label": "Show Correlation Values"
                },
                "cluster": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Cluster Samples"
                }
            },
            "function": "create_correlation_heatmap"
        },
        "peak_intensity_scatter": {
            "name": "Peak Intensity Scatter Plot",
            "description": "2D/3D scatter plot of peak intensities",
            "min_datasets": 1,
            "max_datasets": None,
            "dataset_selection_mode": "multi",
            "params": {
                "peak_1_position": {
                    "type": "spinbox",
                    "default": 1000,
                    "range": (400, 4000),
                    "label": "Peak 1 Position (cmâ»Â¹)"
                },
                "peak_2_position": {
                    "type": "spinbox",
                    "default": 1650,
                    "range": (400, 4000),
                    "label": "Peak 2 Position (cmâ»Â¹)"
                },
                "use_3d": {
                    "type": "checkbox",
                    "default": False,
                    "label": "3D Scatter (3 peaks)"
                },
                "peak_3_position": {
                    "type": "spinbox",
                    "default": 2900,
                    "range": (400, 4000),
                    "label": "Peak 3 Position (cmâ»Â¹)"
                },
                "show_legend": {
                    "type": "checkbox",
                    "default": True,
                    "label": "Show Legend"
                }
            },
            "function": "create_peak_scatter"
        }
    }
}


def get_method_info(category: str, method_key: str) -> Dict[str, Any]:
    """
    Get information about a specific analysis method.
    
    Args:
        category: Analysis category
        method_key: Unique method identifier
    
    Returns:
        Method information dictionary
    
    Raises:
        KeyError: If category or method not found
    """
    if category not in ANALYSIS_METHODS:
        raise KeyError(f"Category '{category}' not found in registry")
    
    if method_key not in ANALYSIS_METHODS[category]:
        raise KeyError(f"Method '{method_key}' not found in category '{category}'")
    
    return ANALYSIS_METHODS[category][method_key]


def get_all_categories() -> list:
    """Get list of all available analysis categories."""
    return list(ANALYSIS_METHODS.keys())


def get_methods_in_category(category: str) -> Dict[str, Dict[str, Any]]:
    """
    Get all methods in a specific category.
    
    Args:
        category: Analysis category
    
    Returns:
        Dictionary of methods in the category
    """
    if category not in ANALYSIS_METHODS:
        raise KeyError(f"Category '{category}' not found in registry")
    
    return ANALYSIS_METHODS[category]


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\result.py ##

"""
Analysis Result Container

This module defines the AnalysisResult class for storing and managing
analysis results with all associated data and visualizations.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
import pandas as pd
from matplotlib.figure import Figure


@dataclass
class AnalysisResult:
    """
    Container for analysis results with comprehensive metadata.
    
    Attributes:
        category: Analysis category (exploratory, statistical, visualization)
        method_key: Unique method identifier
        method_name: Human-readable method name
        params: Parameters used for analysis
        dataset_names: List of dataset names analyzed
        n_spectra: Total number of spectra analyzed
        execution_time: Time taken to run analysis (seconds)
        summary_text: Brief summary for quick stats display
        detailed_summary: Detailed summary for results panel
        primary_figure: Main visualization figure
        secondary_figure: Secondary visualization figure (optional)
        data_table: Numerical results as DataFrame (optional)
        data_table: Numerical results as DataFrame (optional)
        raw_results: Raw analysis output for further processing
        dataset_data: Original dataset data for spectrum visualization (optional)
    """
    
    category: str
    method_key: str
    method_name: str
    params: Dict[str, Any]
    dataset_names: List[str]
    n_spectra: int
    execution_time: float
    summary_text: str
    detailed_summary: str
    primary_figure: Optional[Figure] = None
    secondary_figure: Optional[Figure] = None
    data_table: Optional[pd.DataFrame] = None
    raw_results: Dict[str, Any] = field(default_factory=dict)
    dataset_data: Optional[Dict[str, pd.DataFrame]] = None
    
    def __post_init__(self):
        """Validate result data after initialization."""
        if not self.category:
            raise ValueError("Category cannot be empty")
        if not self.method_key:
            raise ValueError("Method key cannot be empty")
        if self.n_spectra < 1:
            raise ValueError("Number of spectra must be positive")


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\thread.py ##

"""
Analysis Thread Worker

This module provides a QThread worker for running analysis methods
in the background to keep the UI responsive.
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

import time
import traceback
from typing import Dict, Any
import pandas as pd

from PySide6.QtCore import QThread, Signal

from .result import AnalysisResult
from .registry import get_method_info
from configs.configs import create_logs

# Import analysis method implementations
from .methods import (
    perform_pca_analysis,
    perform_umap_analysis,
    perform_tsne_analysis,
    perform_hierarchical_clustering,
    perform_kmeans_clustering,
    perform_spectral_comparison,
    perform_peak_analysis,
    perform_correlation_analysis,
    perform_anova_test,
    create_spectral_heatmap,
    create_mean_spectra_overlay,
    create_waterfall_plot,
    create_correlation_heatmap,
    create_peak_scatter
)


class AnalysisThread(QThread):
    """
    Worker thread for running analysis methods in background.
    
    Signals:
        progress: Emits progress percentage (0-100)
        finished: Emits AnalysisResult on successful completion
        error: Emits error message string on failure
    """
    
    progress = Signal(int)
    finished = Signal(AnalysisResult)
    error = Signal(str)
    
    def __init__(self, category: str, method_key: str, params: Dict[str, Any],
                 dataset_data: Dict[str, pd.DataFrame]):
        super().__init__()
        self.category = category
        self.method_key = method_key
        self.params = params
        self.dataset_data = dataset_data
        self._is_cancelled = False
    
    def run(self):
        """Execute the analysis method."""
        try:
            start_time = time.time()
            
            # Get method info
            method_info = get_method_info(self.category, self.method_key)
            function_name = method_info["function"]
            
            # Map function names to actual functions
            function_map = {
                "perform_pca_analysis": perform_pca_analysis,
                "perform_umap_analysis": perform_umap_analysis,
                "perform_tsne_analysis": perform_tsne_analysis,
                "perform_hierarchical_clustering": perform_hierarchical_clustering,
                "perform_kmeans_clustering": perform_kmeans_clustering,
                "perform_spectral_comparison": perform_spectral_comparison,
                "perform_peak_analysis": perform_peak_analysis,
                "perform_correlation_analysis": perform_correlation_analysis,
                "perform_anova_test": perform_anova_test,
                "create_spectral_heatmap": create_spectral_heatmap,
                "create_mean_spectra_overlay": create_mean_spectra_overlay,
                "create_waterfall_plot": create_waterfall_plot,
                "create_correlation_heatmap": create_correlation_heatmap,
                "create_peak_scatter": create_peak_scatter
            }
            
            if function_name not in function_map:
                raise ValueError(f"Analysis function '{function_name}' not found")
            
            analysis_function = function_map[function_name]
            
            # Update progress
            self.progress.emit(10)
            
            # Prepare data
            dataset_names = list(self.dataset_data.keys())
            n_spectra = sum(df.shape[1] for df in self.dataset_data.values())
            
            self.progress.emit(20)
            
            # Run analysis
            create_logs("AnalysisThread", "run_analysis",
                       f"Running {method_info['name']} with {n_spectra} spectra",
                       status='info')
            
            # Execute the analysis function
            result = analysis_function(
                dataset_data=self.dataset_data,
                params=self.params,
                progress_callback=self._update_progress
            )
            
            execution_time = time.time() - start_time
            
            # Create AnalysisResult object
            raw_results = result.get("raw_results", {})
            
            # Store additional figures in raw_results for PCA multi-tab visualization
            if "scree_figure" in result:
                raw_results["scree_figure"] = result["scree_figure"]
            if "loadings_figure" in result:
                raw_results["loadings_figure"] = result["loadings_figure"]
            if "biplot_figure" in result:
                raw_results["biplot_figure"] = result["biplot_figure"]
            if "cumulative_variance_figure" in result:
                raw_results["cumulative_variance_figure"] = result["cumulative_variance_figure"]
            if "distributions_figure" in result:
                raw_results["distributions_figure"] = result["distributions_figure"]
            
            analysis_result = AnalysisResult(
                category=self.category,
                method_key=self.method_key,
                method_name=method_info["name"],
                params=self.params,
                dataset_names=dataset_names,
                n_spectra=n_spectra,
                execution_time=execution_time,
                summary_text=result.get("summary_text", "Analysis completed"),
                detailed_summary=result.get("detailed_summary", ""),
                primary_figure=result.get("primary_figure"),
                secondary_figure=result.get("secondary_figure"),
                data_table=result.get("data_table"),
                raw_results=raw_results,
                dataset_data=self.dataset_data
            )
            
            self.progress.emit(100)
            self.finished.emit(analysis_result)
            
            create_logs("AnalysisThread", "run_analysis",
                       f"Analysis completed in {execution_time:.2f}s",
                       status='info')
            
        except Exception as e:
            error_msg = f"Analysis failed: {str(e)}\n{traceback.format_exc()}"
            create_logs("AnalysisThread", "run_analysis",
                       error_msg, status='error')
            self.error.emit(str(e))
    
    def _update_progress(self, progress: int):
        """
        Update progress callback for analysis functions.
        
        Args:
            progress: Progress value (0-100)
        """
        # Map analysis progress (20-90) to thread progress
        thread_progress = 20 + int((progress / 100) * 70)
        self.progress.emit(thread_progress)
    
    def cancel(self):
        """Cancel the running analysis."""
        self._is_cancelled = True
        self.terminate()


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\views.py ##

"""
Analysis Page View Components

This module contains UI view creation functions for the card-based analysis page:
- Startup view with method cards
- Method view with input forms and results
- History sidebar
- Category sections
"""

from typing import Dict, Any, Callable
import os
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QFrame, QScrollArea, QGridLayout, QListWidget, QListWidgetItem,
    QGroupBox, QTextEdit
)
from PySide6.QtCore import Qt, QSize
from PySide6.QtGui import QFont, QPixmap

from components.widgets import load_icon
from .registry import ANALYSIS_METHODS


# Method key to image file mapping
METHOD_IMAGES = {
    # Exploratory methods
    "pca": "pca_analysis.png",
    "umap": "umap.png",
    "tsne": "t-sne.png",
    "hierarchical_clustering": "hierarchical_clustering.png",
    "kmeans": "k-means.png",  # Fixed: was "kmeans_clustering"
    
    # Statistical methods
    "spectral_comparison": "spectral_comparison.png",
    "peak_analysis": "peak_analysis.png",
    "correlation_analysis": "correlation_analysis.png",
    "anova_test": "ANOVA.png",  # Fixed: was "anova"
    
    # Visualization methods
    "heatmap": "spectral_heatmap.png",  # Fixed: was "spectral_heatmap"
    "mean_spectra_overlay": "mean_spectra_overlay.png",
    "waterfall_plot": "waterfall.png",
    "correlation_heatmap": "correlation_heatmap.png",
    "peak_intensity_scatter": "peak_intensity_scatter.png"
}


def create_startup_view(localize_func: Callable, on_method_selected: Callable) -> QWidget:
    """
    Create startup view with categorized method cards in a cleaner layout.
    
    Args:
        localize_func: Localization function
        on_method_selected: Callback when method card is clicked (category, method_key)
    
    Returns:
        Startup view widget
    """
    startup_widget = QWidget()
    startup_widget.setObjectName("startupView")
    startup_widget.setStyleSheet("""
        QWidget#startupView {
            background-color: #f8f9fa;
        }
    """)
    
    layout = QVBoxLayout(startup_widget)
    layout.setContentsMargins(20, 8, 20, 16)  # Minimal top margin: 8px
    layout.setSpacing(8)  # Minimal spacing
    
    # Compact header - single line only
    header_label = QLabel(localize_func("ANALYSIS_PAGE.welcome_subtitle"))  # Use subtitle as main text
    header_label.setStyleSheet("""
        font-size: 14px;
        font-weight: 500;
        color: #495057;
        padding: 4px 0px;
    """)
    layout.addWidget(header_label)
    
    # Scroll area for cards
    scroll_area = QScrollArea()
    scroll_area.setWidgetResizable(True)
    scroll_area.setFrameShape(QFrame.NoFrame)
    scroll_area.setStyleSheet("""
        QScrollArea {
            background-color: transparent;
            border: none;
        }
    """)
    
    cards_container = QWidget()
    cards_container.setStyleSheet("background-color: transparent;")
    cards_layout = QVBoxLayout(cards_container)
    cards_layout.setSpacing(16)  # Compact section spacing
    cards_layout.setContentsMargins(0, 0, 0, 0)
    
    # Create category sections with method cards
    for category_key in ["exploratory", "statistical", "visualization"]:
        category_section = create_category_section(
            category_key, localize_func, on_method_selected
        )
        cards_layout.addWidget(category_section)
    
    cards_layout.addStretch()
    scroll_area.setWidget(cards_container)
    layout.addWidget(scroll_area)
    
    return startup_widget


def create_category_section(
    category_key: str, 
    localize_func: Callable, 
    on_method_selected: Callable
) -> QWidget:
    """
    Create a category section with method cards in a better layout.
    
    Args:
        category_key: Category identifier
        localize_func: Localization function
        on_method_selected: Callback for card clicks
    
    Returns:
        Category section widget
    """
    section = QFrame()
    section.setObjectName("categorySection")
    section.setStyleSheet("""
        QFrame#categorySection {
            background-color: transparent;
            border: none;
        }
    """)
    
    layout = QVBoxLayout(section)
    layout.setContentsMargins(0, 0, 0, 0)
    layout.setSpacing(8)  # Minimal spacing between header and grid
    
    # Category header with icon
    category_icons = {
        "exploratory": "ðŸ”",
        "statistical": "ðŸ“Š", 
        "visualization": "ðŸ“ˆ"
    }
    
    icon = category_icons.get(category_key, "ðŸ“Š")
    # Use localization for category names
    category_name = localize_func(f"ANALYSIS_PAGE.CATEGORIES.{category_key}")
    
    header_label = QLabel(f"{icon} {category_name}")
    header_label.setStyleSheet("""
        font-size: 15px;
        font-weight: 600;
        color: #2c3e50;
        padding: 4px 0px;
    """)
    layout.addWidget(header_label)
    
    # Grid layout for method cards (responsive 3-column)
    grid_widget = QWidget()
    grid_layout = QGridLayout(grid_widget)
    grid_layout.setSpacing(12)  # Reduced from 16
    grid_layout.setContentsMargins(0, 0, 0, 0)
    
    # Get methods for this category
    methods = ANALYSIS_METHODS.get(category_key, {})
    
    # Add method cards to grid (3 columns)
    row = 0
    col = 0
    for method_key, method_info in methods.items():
        card = create_method_card(
            category_key, method_key, method_info,
            localize_func, on_method_selected
        )
        grid_layout.addWidget(card, row, col)
        
        col += 1
        if col >= 3:  # 3 cards per row
            col = 0
            row += 1
    
    layout.addWidget(grid_widget)
    
    return section


def create_method_card(
    category: str,
    method_key: str,
    method_info: Dict,
    localize_func: Callable,
    on_method_selected: Callable
) -> QFrame:
    """
    Create modern method card with hover effects.
    
    Styling matches technical guide specifications:
    - Background: #ffffff
    - Border: 1px solid #e0e0e0
    - Border Radius: 8px
    - Hover: Border #0078d4 + shadow
    
    Args:
        category: Method category
        method_key: Method identifier
        method_info: Method configuration
        localize_func: Localization function
        on_method_selected: Callback for card clicks
    
    Returns:
        Method card widget
    """
    card = QFrame()
    card.setObjectName("methodCard")
    card.setStyleSheet("""
        QFrame#methodCard {
            background-color: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 12px;
        }
        QFrame#methodCard:hover {
            border-color: #0078d4;
            box-shadow: 0 2px 8px rgba(0, 120, 212, 0.12);
        }
    """)
    card.setMinimumWidth(260)  # Slightly smaller
    card.setMaximumWidth(380)  # Slightly smaller
    card.setMinimumHeight(200)  # Increased to fit image
    card.setCursor(Qt.PointingHandCursor)
    
    layout = QVBoxLayout(card)
    layout.setSpacing(8)  # Tighter spacing
    layout.setContentsMargins(0, 0, 0, 0)
    
    # Add method image if available
    if method_key in METHOD_IMAGES:
        image_label = QLabel()
        image_label.setAlignment(Qt.AlignCenter)
        
        # Get image path
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        image_path = os.path.join(base_dir, "assets", "image", METHOD_IMAGES[method_key])
        
        if os.path.exists(image_path):
            pixmap = QPixmap(image_path)
            if not pixmap.isNull():
                # Scale to fit card width while maintaining aspect ratio
                scaled_pixmap = pixmap.scaled(
                    240, 120,  # Max width 240px, height 120px
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )
                image_label.setPixmap(scaled_pixmap)
                image_label.setStyleSheet("""
                    QLabel {
                        background-color: #f8f9fa;
                        border-radius: 4px;
                        padding: 4px;
                    }
                """)
                layout.addWidget(image_label)
    
    # Method name - use localization
    method_name = localize_func(f"ANALYSIS_PAGE.METHODS.{method_key}")
    name_label = QLabel(method_name)
    name_label.setStyleSheet("""
        font-size: 14px;
        font-weight: 600;
        color: #2c3e50;
    """)
    name_label.setWordWrap(True)
    layout.addWidget(name_label)
    
    # Description - use localization
    desc_text = localize_func(f"ANALYSIS_PAGE.METHOD_DESC.{method_key}")
    desc_label = QLabel(desc_text)
    desc_label.setStyleSheet("""
        font-size: 11px;
        color: #6c757d;
        line-height: 1.3;
    """)
    desc_label.setWordWrap(True)
    desc_label.setMinimumHeight(40)  # Reduced from 50
    layout.addWidget(desc_label)
    
    layout.addStretch()
    
    # Start button
    start_btn = QPushButton(localize_func("ANALYSIS_PAGE.start_analysis_button"))
    start_btn.setObjectName("cardStartButton")
    start_btn.setMinimumHeight(32)  # Reduced from 36
    start_btn.setStyleSheet("""
        QPushButton#cardStartButton {
            background-color: #0078d4;
            color: white;
            border: none;
            border-radius: 4px;
            font-weight: 600;
            font-size: 12px;
            padding: 6px 12px;
        }
        QPushButton#cardStartButton:hover {
            background-color: #006abc;
        }
        QPushButton#cardStartButton:pressed {
            background-color: #005a9e;
        }
    """)
    start_btn.clicked.connect(lambda: on_method_selected(category, method_key))
    layout.addWidget(start_btn)
    
    # Make entire card clickable
    card.mousePressEvent = lambda event: on_method_selected(category, method_key)
    
    return card


def create_history_sidebar(localize_func: Callable) -> QWidget:
    """
    Create collapsible history sidebar for analysis session tracking.
    
    Args:
        localize_func: Localization function
    
    Returns:
        History sidebar widget
    """
    sidebar = QWidget()
    sidebar.setObjectName("historySidebar")
    sidebar.setStyleSheet("""
        QWidget#historySidebar {
            background-color: #f8f9fa;
            border-right: 1px solid #e0e0e0;
        }
    """)
    sidebar.setMaximumWidth(280)
    sidebar.setMinimumWidth(200)
    
    layout = QVBoxLayout(sidebar)
    layout.setContentsMargins(12, 12, 12, 12)
    layout.setSpacing(12)
    
    # Header
    header_label = QLabel("ðŸ“œ " + localize_func("ANALYSIS_PAGE.history_title"))
    header_label.setStyleSheet("""
        font-size: 14px;
        font-weight: 600;
        color: #2c3e50;
        padding: 8px 0;
    """)
    layout.addWidget(header_label)
    
    # History list
    history_list = QListWidget()
    history_list.setObjectName("historyList")
    history_list.setStyleSheet("""
        QListWidget#historyList {
            background-color: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
        }
        QListWidget#historyList::item {
            padding: 8px;
            border-bottom: 1px solid #f0f0f0;
        }
        QListWidget#historyList::item:selected {
            background-color: #e7f3ff;
            color: #2c3e50;
        }
        QListWidget#historyList::item:hover {
            background-color: #f0f0f0;
        }
    """)
    layout.addWidget(history_list)
    
    # Clear history button
    clear_btn = QPushButton(localize_func("ANALYSIS_PAGE.clear_history"))
    clear_btn.setObjectName("secondaryButton")
    clear_btn.setMinimumHeight(32)
    layout.addWidget(clear_btn)
    
    # Store reference for external access
    sidebar.history_list = history_list
    sidebar.clear_btn = clear_btn
    
    return sidebar


def create_top_bar(localize_func: Callable, on_new_analysis: Callable) -> QWidget:
    """
    Create top navigation bar with New Analysis button.
    
    Args:
        localize_func: Localization function
        on_new_analysis: Callback for new analysis button
    
    Returns:
        Top bar widget with new_analysis_btn attribute
    """
    top_bar = QWidget()
    top_bar.setObjectName("topBar")
    top_bar.setStyleSheet("""
        QWidget#topBar {
            background-color: #ffffff;
            border-bottom: 1px solid #dee2e6;
        }
    """)
    
    layout = QHBoxLayout(top_bar)
    layout.setContentsMargins(12, 4, 12, 4)  # Reduced from 6 to 4 - very tight
    layout.setSpacing(2)  # Reduced from 10 to 8
    
    # Title with back button
    back_btn = QPushButton("â†")
    back_btn.setObjectName("backButton")
    back_btn.setFixedSize(26, 26)  # Reduced from 28x28
    back_btn.setStyleSheet("""
        QPushButton#backButton {
            background-color: transparent;
            border: 1px solid #e0e0e0;
            border-radius: 13px;
            font-size: 14px;
            color: #2c3e50;
        }
        QPushButton#backButton:hover {
            background-color: #e7f3ff;
            border-color: #0078d4;
        }
    """)
    back_btn.setCursor(Qt.PointingHandCursor)
    back_btn.clicked.connect(on_new_analysis)
    back_btn.setVisible(False)  # Hidden by default
    layout.addWidget(back_btn)
    
    title_label = QLabel("ðŸ“Š " + localize_func("ANALYSIS_PAGE.title"))
    title_label.setStyleSheet("font-weight: 600; font-size: 13px; color: #2c3e50;")  # Reduced from 14px
    layout.addWidget(title_label)
    
    layout.addStretch()
    
    # New Analysis button (plus icon)
    new_analysis_btn = QPushButton()
    new_analysis_btn.setObjectName("newAnalysisButton")
    plus_icon = load_icon("plus", QSize(16, 16), "white")  # Reduced from 18x18
    new_analysis_btn.setIcon(plus_icon)
    new_analysis_btn.setIconSize(QSize(16, 16))
    new_analysis_btn.setFixedSize(32, 32)  # Reduced from 36x36
    new_analysis_btn.setToolTip(localize_func("ANALYSIS_PAGE.new_analysis_tooltip"))
    new_analysis_btn.setCursor(Qt.PointingHandCursor)
    new_analysis_btn.setStyleSheet("""
        QPushButton#newAnalysisButton {
            background-color: #0078d4;
            border: none;
            border-radius: 16px;
        }
        QPushButton#newAnalysisButton:hover {
            background-color: #006abc;
        }
        QPushButton#newAnalysisButton:pressed {
            background-color: #005a9e;
        }
    """)
    new_analysis_btn.clicked.connect(on_new_analysis)
    new_analysis_btn.setVisible(False)  # Hidden in startup view
    layout.addWidget(new_analysis_btn)
    
    # Store references for external access
    top_bar.new_analysis_btn = new_analysis_btn
    top_bar.back_btn = back_btn
    top_bar.title_label = title_label
    
    return top_bar


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\analysis_page_utils\widgets.py ##

"""
Parameter Widget Factory

This module provides functions to create parameter input widgets
dynamically based on parameter specifications.
"""

from PySide6.QtWidgets import (
    QWidget, QSpinBox, QDoubleSpinBox, QComboBox, QCheckBox
)
from typing import Dict, Any


def create_parameter_widgets(param_info: Dict[str, Any]) -> QWidget:
    """
    Create an appropriate widget based on parameter type specification.
    
    Args:
        param_info: Parameter specification dictionary with keys:
            - type: Widget type ('spinbox', 'double_spinbox', 'combo', 'checkbox')
            - default: Default value
            - range: (min, max) for numeric widgets
            - step: Step size for numeric widgets
            - options: List of options for combo widgets
            - label: Display label (not used here)
    
    Returns:
        Configured QWidget for the parameter
    """
    param_type = param_info.get("type")
    
    if param_type == "spinbox":
        widget = QSpinBox()
        min_val, max_val = param_info.get("range", (0, 100))
        widget.setRange(min_val, max_val)
        widget.setValue(param_info.get("default", min_val))
        return widget
    
    elif param_type == "double_spinbox":
        widget = QDoubleSpinBox()
        min_val, max_val = param_info.get("range", (0.0, 1.0))
        widget.setRange(min_val, max_val)
        widget.setValue(param_info.get("default", min_val))
        
        # Set step size if provided
        step = param_info.get("step", 0.1)
        widget.setSingleStep(step)
        
        # Set decimals based on step size
        if step >= 1:
            widget.setDecimals(0)
        elif step >= 0.1:
            widget.setDecimals(1)
        elif step >= 0.01:
            widget.setDecimals(2)
        else:
            widget.setDecimals(3)
        
        return widget
    
    elif param_type == "combo":
        widget = QComboBox()
        options = param_info.get("options", [])
        
        for option in options:
            widget.addItem(str(option), option)
        
        # Set default value
        default = param_info.get("default")
        if default:
            index = widget.findData(default)
            if index >= 0:
                widget.setCurrentIndex(index)
        
        return widget
    
    elif param_type == "checkbox":
        widget = QCheckBox()
        widget.setChecked(param_info.get("default", False))
        return widget
    
    else:
        # Fallback: return a disabled widget
        widget = QWidget()
        widget.setEnabled(False)
        return widget


def get_widget_value(widget: QWidget) -> Any:
    """
    Extract the current value from a parameter widget.
    
    Args:
        widget: Parameter widget created by create_parameter_widgets
    
    Returns:
        Current value of the widget
    """
    if isinstance(widget, QSpinBox):
        return widget.value()
    
    elif isinstance(widget, QDoubleSpinBox):
        return widget.value()
    
    elif isinstance(widget, QComboBox):
        return widget.currentData() or widget.currentText()
    
    elif isinstance(widget, QCheckBox):
        return widget.isChecked()
    
    else:
        return None


def set_widget_value(widget: QWidget, value: Any):
    """
    Set the value of a parameter widget.
    
    Args:
        widget: Parameter widget created by create_parameter_widgets
        value: Value to set
    """
    if isinstance(widget, (QSpinBox, QDoubleSpinBox)):
        widget.setValue(value)
    
    elif isinstance(widget, QComboBox):
        index = widget.findData(value)
        if index >= 0:
            widget.setCurrentIndex(index)
        else:
            # Try to find by text
            index = widget.findText(str(value))
            if index >= 0:
                widget.setCurrentIndex(index)
    
    elif isinstance(widget, QCheckBox):
        widget.setChecked(bool(value))


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\components\widgets\icons.py ##

"""
Icon management utilities for the widgets package.

This module provides centralized icon path management and loading functionality
for all widgets in the components/widgets package.
"""

import os
import sys
from typing import Optional, Union
from PySide6.QtGui import QFontDatabase, QIcon, QPixmap, QPainter 
from PySide6.QtSvg import QSvgRenderer
from PySide6.QtCore import QSize, Qt

def _get_base_path():
    """Get base path that works in both development and frozen (PyInstaller) modes."""
    if getattr(sys, 'frozen', False):
        # Running in PyInstaller bundle (frozen .exe)
        base_path = sys._MEIPASS
    else:
        # Running in normal Python (development mode)
        base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    return base_path

# Base path for all icons
ICONS_BASE_PATH = os.path.join(_get_base_path(), "assets", "icons")

# Icon file paths registry
ICON_PATHS = {
    # Widget control icons (current usage)
    "minus": "minus.svg",
    "plus": "plus.svg", 
    "trash": "trash-xmark.svg",
    "trash_bin": "trash-bin.svg",
    "delete_all": "delete-all.svg",      # Delete all button icon
    "export_button": "export-button.svg",  # Export button icon
    
    # Legacy icons (still used in some files - need to be migrated)
    "decrease_circle": "decrease-circle.svg",  # Used in preprocess_page_utils/widgets.py
    "increase_circle": "increase-circle.svg",  # Used in preprocess_page_utils/widgets.py
    
    # Navigation and view icons
    "chevron_down": "chevron-down.svg",
    "eye_open": "eye-open.svg",          # Used in preprocess_page.py
    "eye_close": "eye-close.svg",        # Used in preprocess_page.py
    "reload": "reload.svg",              # Used in preprocess_page.py, home_page.py, utils.py
    "focus_horizontal": "focus-horizontal-round.svg",  # Manual focus button
    "export": "export-button.svg",       # Export button icon
    "save": "save.svg",                # Save button icon
    "edit": "edit.svg",              # Edit button icon
    "checkmark": "checkmark.svg",    # Checkmark icon
    
    # Project management icons
    "new_project": "new-project.svg",    # Used in home_page.py, utils.py
    "load_project": "load-project.svg",  # Used as "open_project" in home_page.py, utils.py
    "recent_project": "recent-project.svg", # Used as "recent_projects" in home_page.py, utils.py
    
    # Aliases for backward compatibility with utils.py ICON_PATHS
    "open_project": "load-project.svg",     # Alias for load_project
    "recent_projects": "recent-project.svg", # Alias for recent_project (plural form)
}

# Default icon sizes for different widget types
DEFAULT_SIZES = {
    "button": QSize(16, 16),
    "toolbar": QSize(24, 24),
    "large": QSize(32, 32),
}

def get_icon_path(icon_name: str) -> str:
    """
    Get the full path to an icon file.
    
    Args:
        icon_name: Name of the icon (key from ICON_PATHS)
        
    Returns:
        Full path to the icon file
        
    Raises:
        KeyError: If icon_name is not found in registry
    """
    if icon_name not in ICON_PATHS:
        raise KeyError(f"Icon '{icon_name}' not found in registry. Available icons: {list(ICON_PATHS.keys())}")
    
    return os.path.join(ICONS_BASE_PATH, ICON_PATHS[icon_name])

def load_svg_icon(path: str,  color: Qt.GlobalColor = None, size: QSize = QSize(48, 48)) -> QIcon:
    """
    Loads an SVG file from disk and returns a QIcon of the given size.
    Optionally applies a color overlay to the SVG.
    """
    renderer = QSvgRenderer(path)
    pixmap = QPixmap(size)
    pixmap.fill(Qt.GlobalColor.transparent)
    painter = QPainter(pixmap)
    renderer.render(painter)
    painter.end()

    if color is not None:
        # Apply color overlay
        mask = pixmap.createMaskFromColor(Qt.GlobalColor.transparent)
        colored_pixmap = QPixmap(size)
        colored_pixmap.fill(Qt.GlobalColor.transparent)
        painter = QPainter(colored_pixmap)
        painter.setCompositionMode(QPainter.CompositionMode_Source)
        painter.drawPixmap(0, 0, pixmap)
        painter.setCompositionMode(QPainter.CompositionMode_SourceIn)
        painter.fillRect(colored_pixmap.rect(), color)
        painter.end()
        return QIcon(colored_pixmap)
    return QIcon(pixmap)

def load_icon(icon_name: str, size: Optional[Union[QSize, str]] = None, color: Optional[str] = None) -> QIcon:
    """
    Load an icon with optional size and color customization.
    
    Args:
        icon_name: Name of the icon (key from ICON_PATHS)
        size: Icon size - can be QSize object or string key from DEFAULT_SIZES
        color: Optional color for SVG icons (hex color or Qt color name)
        
    Returns:
        QIcon object ready for use
        
    Example:
        >>> icon = load_icon("minus", "button")
        >>> icon = load_icon("plus", QSize(20, 20), "#6c757d")
    """
    icon_path = get_icon_path(icon_name)
    
    # Handle size parameter
    if size is None:
        size = DEFAULT_SIZES["button"]
    elif isinstance(size, str):
        if size not in DEFAULT_SIZES:
            raise KeyError(f"Size '{size}' not found. Available sizes: {list(DEFAULT_SIZES.keys())}")
        size = DEFAULT_SIZES[size]
    
    # Load icon based on whether color customization is needed
    if color is not None:
        # Use the utility function for color customization
        return load_svg_icon(icon_path, color, size)
    else:
        # Use direct QIcon loading for better performance
        icon = QIcon(icon_path)
        return icon

def create_button_icon(icon_name: str, color: Optional[str] = None) -> QIcon:
    """
    Create an icon optimized for button usage.
    
    Args:
        icon_name: Name of the icon
        color: Optional color override
        
    Returns:
        QIcon sized appropriately for buttons
    """
    return load_icon(icon_name, "button", color)

def create_toolbar_icon(icon_name: str, color: Optional[str] = None) -> QIcon:
    """
    Create an icon optimized for toolbar usage.
    
    Args:
        icon_name: Name of the icon
        color: Optional color override
        
    Returns:
        QIcon sized appropriately for toolbars
    """
    return load_icon(icon_name, "toolbar", color)

def list_available_icons() -> list:
    """
    Get a list of all available icon names.
    
    Returns:
        List of icon names that can be used with load_icon()
    """
    return list(ICON_PATHS.keys())

def verify_icon_exists(icon_name: str) -> bool:
    """
    Check if an icon file actually exists on disk.
    
    Args:
        icon_name: Name of the icon to check
        
    Returns:
        True if icon file exists, False otherwise
    """
    try:
        icon_path = get_icon_path(icon_name)
        return os.path.exists(icon_path)
    except KeyError:
        return False

def get_missing_icons() -> list:
    """
    Get a list of icons that are registered but missing from disk.
    
    Returns:
        List of icon names that are registered but file doesn't exist
    """
    missing = []
    for icon_name in ICON_PATHS.keys():
        if not verify_icon_exists(icon_name):
            missing.append(icon_name)
    return missing


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\components\widgets\matplotlib_widget.py ##

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
from PySide6.QtWidgets import QWidget, QVBoxLayout
from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.backends.backend_qtagg import NavigationToolbar2QT as NavigationToolbar
from matplotlib.figure import Figure
from mpl_toolkits.mplot3d import Axes3D
from typing import Optional, Dict, Any, List, Tuple


def detect_signal_range(wavenumbers, intensities, noise_threshold_percentile=20, signal_threshold_factor=1.2, focus_padding=None, crop_bounds=None):
    """
    Automatically detect the range of wavenumbers where there is meaningful signal.
    Optimized for Raman spectroscopy data.
    
    Args:
        wavenumbers: Array of wavenumber values
        intensities: Array or 2D array of intensity values 
        noise_threshold_percentile: Percentile to use for noise floor estimation
        signal_threshold_factor: Factor above noise floor to consider as signal
        focus_padding: Additional padding in wavenumber units (default: None for percentage-based padding)
        crop_bounds: Tuple of (min_wn, max_wn) to use as base range with padding instead of auto-detection
    
    Returns:
        tuple: (min_wavenumber, max_wavenumber) for the focused range
    """
    try:
        # Handle 2D data by taking mean across spectra
        if len(intensities.shape) == 2:
            mean_intensity = np.mean(intensities, axis=0)
        else:
            mean_intensity = intensities
        
        # If crop_bounds are provided, use them as base range with padding
        if crop_bounds is not None:
            min_crop, max_crop = crop_bounds
            
            # Apply focus_padding to the crop bounds
            if focus_padding is not None:
                padded_min = min_crop - focus_padding
                padded_max = max_crop + focus_padding
            else:
                # Default fixed padding of 50 wavenumber units
                padded_min = min_crop - 50
                padded_max = max_crop + 50
            
            # Ensure bounds are within data range
            data_min = np.min(wavenumbers)
            data_max = np.max(wavenumbers)
            final_min = max(data_min, padded_min)
            final_max = min(data_max, padded_max)
            
            return final_min, final_max
        
        # For Raman spectroscopy, try a different approach
        # Look for regions with significant variance (indicating peaks)
        window_size = max(10, len(mean_intensity) // 50)  # Adaptive window size
        
        # Calculate local variance to find peak regions
        variance_signal = np.zeros_like(mean_intensity)
        for i in range(len(mean_intensity)):
            start_idx = max(0, i - window_size // 2)
            end_idx = min(len(mean_intensity), i + window_size // 2)
            local_data = mean_intensity[start_idx:end_idx]
            variance_signal[i] = np.var(local_data)
        
        # Find regions with high variance (peaks)
        variance_threshold = np.percentile(variance_signal, 70)  # Top 30% variance regions
        high_variance_mask = variance_signal > variance_threshold
        
        # Also look for regions above intensity threshold
        intensity_threshold = np.percentile(mean_intensity, 70)  # Top 30% intensity regions
        high_intensity_mask = mean_intensity > intensity_threshold
        
        # Combine both criteria
        signal_mask = high_variance_mask | high_intensity_mask
        signal_indices = np.where(signal_mask)[0]
        
        if len(signal_indices) == 0:
            # Fallback: focus on middle 60% of spectrum (typical Raman range)
            start_idx = int(len(wavenumbers) * 0.2)
            end_idx = int(len(wavenumbers) * 0.8)
            return wavenumbers[start_idx], wavenumbers[end_idx]
        
        # Find contiguous regions of signal
        signal_start = signal_indices[0]
        signal_end = signal_indices[-1]
        
        # Add padding based on focus_padding parameter or default percentage
        if focus_padding is not None:
            # Convert focus_padding (wavenumber units) to indices
            wn_per_index = (wavenumbers[-1] - wavenumbers[0]) / len(wavenumbers)
            padding_indices = int(focus_padding / wn_per_index)
        else:
            # Default: 15% on each side
            padding_indices = int(len(wavenumbers) * 0.1)
        
        start_idx = max(0, signal_start - padding_indices)
        end_idx = min(len(wavenumbers) - 1, signal_end + padding_indices)
        
        # Ensure reasonable range (at least 25% of total, at most 80%)
        min_range = (wavenumbers[-1] - wavenumbers[0]) * 0.25
        max_range = (wavenumbers[-1] - wavenumbers[0]) * 0.8
        current_range = wavenumbers[end_idx] - wavenumbers[start_idx]
        
        if current_range < min_range:
            # Expand to minimum range
            center_idx = (start_idx + end_idx) // 2
            half_min_indices = int(len(wavenumbers) * 0.125)  # 12.5% on each side
            start_idx = max(0, center_idx - half_min_indices)
            end_idx = min(len(wavenumbers) - 1, center_idx + half_min_indices)
        elif current_range > max_range:
            # Contract to maximum range
            center_idx = (start_idx + end_idx) // 2
            half_max_indices = int(len(wavenumbers) * 0.4)  # 40% on each side
            start_idx = max(0, center_idx - half_max_indices)
            end_idx = min(len(wavenumbers) - 1, center_idx + half_max_indices)
        
        return wavenumbers[start_idx], wavenumbers[end_idx]
        
    except Exception as e:
        # Fallback to middle 60% of range (common Raman region)
        start_idx = int(len(wavenumbers) * 0.2)
        end_idx = int(len(wavenumbers) * 0.8)
        return wavenumbers[start_idx], wavenumbers[end_idx]

class MatplotlibWidget(QWidget):
    """
    A custom widget to embed a Matplotlib plot into a PySide6 application.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("matplotlibWidget")
        
        # --- Create a Figure and a Canvas ---
        self.figure = Figure(figsize=(5, 4), dpi=100, facecolor='whitesmoke')
        self.canvas = FigureCanvas(self.figure)
        
        # --- Create a Toolbar ---
        self.toolbar = NavigationToolbar(self.canvas, self)
        
        # --- Layout ---
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.addWidget(self.toolbar)
        layout.addWidget(self.canvas)

    def add_custom_toolbar(self, widget: QWidget):
        """
        Add a custom widget to the toolbar area.
        
        Args:
            widget: The QWidget to add to the toolbar layout
        """
        # Find the toolbar layout (it's the second item in the main layout, index 1)
        # Layout structure: [Canvas, Toolbar_Layout]
        if self.layout().count() >= 2:
            # The toolbar is usually in a VBox or HBox. 
            # Based on __init__, we have self.layout() as QVBoxLayout.
            # It contains self.canvas and self.toolbar.
            # We want to add the custom widget next to the toolbar or above/below it.
            
            # Let's add it to the main layout, right after the toolbar
            self.layout().addWidget(widget)
        else:
            # Fallback
            self.layout().addWidget(widget)

    def update_plot(self, new_figure: Figure):
        """
        Clears the current figure and replaces it with a new one.
        """
        self.figure.clear()
        # This is a way to "copy" the contents of the new figure
        # to the existing figure managed by the canvas.
        axes_list = new_figure.get_axes()
        
        if not axes_list:
            # No axes to copy
            self.canvas.draw()
            return
            
        for i, ax in enumerate(axes_list):
            # Create a new subplot in the same position
            # For simple cases, we can use add_subplot(111) for single plots
            if len(axes_list) == 1:
                new_ax = self.figure.add_subplot(111)
            else:
                # For multiple subplots, try to preserve layout
                new_ax = self.figure.add_subplot(len(axes_list), 1, i+1)
            
            # Copy all line plots from the original axes
            for line in ax.get_lines():
                new_ax.plot(line.get_xdata(), line.get_ydata(), 
                           label=line.get_label(), 
                           color=line.get_color(),
                           linestyle=line.get_linestyle(),
                           linewidth=line.get_linewidth(),
                           marker=line.get_marker(),
                           markersize=line.get_markersize())
            
            # Copy scatter plots (PathCollections) and LineCollections from the original axes
            from matplotlib.collections import LineCollection, PathCollection
            
            for collection in ax.collections:
                # Handle LineCollection (used in dendrograms, heatmaps, cluster plots)
                if isinstance(collection, LineCollection):
                    print(f"[DEBUG] Copying LineCollection (dendrogram/cluster lines)")
                    # Copy line segments directly
                    segments = collection.get_segments()
                    colors = collection.get_colors()
                    linewidths = collection.get_linewidths()
                    linestyles = collection.get_linestyles()
                    
                    new_collection = LineCollection(
                        segments,
                        colors=colors,
                        linewidths=linewidths,
                        linestyles=linestyles
                    )
                    new_ax.add_collection(new_collection)
                    continue
                
                # Handle PathCollection (scatter plots)
                if isinstance(collection, PathCollection):
                    offsets = collection.get_offsets()
                    if len(offsets) > 0:
                        # Get collection properties
                        facecolors = collection.get_facecolors()
                        edgecolors = collection.get_edgecolors()
                        sizes = collection.get_sizes() if hasattr(collection, 'get_sizes') else [50]
                        label = collection.get_label()
                        
                        # Create scatter plot
                        new_ax.scatter(offsets[:, 0], offsets[:, 1],
                                     c=facecolors if len(facecolors) > 0 else None,
                                     s=sizes[0] if len(sizes) > 0 else 50,
                                     edgecolors=edgecolors if len(edgecolors) > 0 else None,
                                     label=label if label and not label.startswith('_') else None,
                                     alpha=collection.get_alpha() or 1.0)
            
            # Recreate patches (ellipses, rectangles, arrows) on new axis
            # Patches can't be transferred between figures (RuntimeError), so we recreate them
            # Skip if too many patches (likely heatmap/correlation plot with many cells)
            num_patches = len(ax.patches)
            print(f"[DEBUG] Found {num_patches} patches on axis")
            
            if num_patches > 100:
                print(f"[DEBUG] Too many patches ({num_patches}), skipping recreation (likely heatmap)")
                print(f"[DEBUG] Heatmap patches are handled by matplotlib's internal rendering")
            else:
                print(f"[DEBUG] Recreating {num_patches} patches on new axis")
                
                from matplotlib.patches import Ellipse, Rectangle, Polygon, FancyArrow, FancyArrowPatch
                
                for patch in ax.patches:
                    # Get patch properties
                    if isinstance(patch, Ellipse):
                        # Recreate ellipse with same properties
                        new_ellipse = Ellipse(
                            xy=patch.center,
                            width=patch.width,
                            height=patch.height,
                            angle=patch.angle,
                            facecolor=patch.get_facecolor(),
                            edgecolor=patch.get_edgecolor(),
                            linestyle=patch.get_linestyle(),
                            linewidth=patch.get_linewidth(),
                            alpha=patch.get_alpha(),
                        label=patch.get_label() if not patch.get_label().startswith('_') else None
                        )
                        new_ax.add_patch(new_ellipse)
                        print(f"[DEBUG] Recreated ellipse at {patch.center} on new axis")
                    
                    elif isinstance(patch, Rectangle):
                        # Recreate rectangle (for bar plots)
                        new_rect = Rectangle(
                            xy=(patch.get_x(), patch.get_y()),
                            width=patch.get_width(),
                            height=patch.get_height(),
                            facecolor=patch.get_facecolor(),
                            edgecolor=patch.get_edgecolor(),
                            linewidth=patch.get_linewidth(),
                            alpha=patch.get_alpha()
                        )
                        new_ax.add_patch(new_rect)
                        print(f"[DEBUG] Recreated rectangle at ({patch.get_x()}, {patch.get_y()}) on new axis")
                    
                    elif isinstance(patch, FancyArrow):
                        # 
                        # Recreate FancyArrow (used in Biplots)
                        print(f"[DEBUG] Recreating FancyArrow on new axis")
                        
                        # FancyArrow stores properties as attributes, not via get_ methods
                        new_arrow = FancyArrow(
                            x=patch._x,              # Changed from get_x()
                            y=patch._y,              # Changed from get_y()
                            dx=patch._dx,            # Changed from get_width()
                            dy=patch._dy,            # Changed from get_height()
                            width=getattr(patch, '_width', 0.01), # Keep using internal attribs if getters miss
                            head_width=getattr(patch, '_head_width', 0.03),
                            head_length=getattr(patch, '_head_length', 0.05),
                            length_includes_head=getattr(patch, '_length_includes_head', False),
                            shape=getattr(patch, '_shape', 'full'),
                            overhang=getattr(patch, '_overhang', 0),
                            head_starts_at_zero=getattr(patch, '_head_starts_at_zero', False),
                            facecolor=patch.get_facecolor(),
                            edgecolor=patch.get_edgecolor(),
                            linewidth=patch.get_linewidth(),
                            alpha=patch.get_alpha()
                        )
                        new_ax.add_patch(new_arrow)
                        print(f"[DEBUG] Successfully recreated FancyArrow")
                    
                    elif isinstance(patch, FancyArrowPatch):
                        # Recreate FancyArrowPatch (more common arrow type)
                        print(f"[DEBUG] Recreating FancyArrowPatch on new axis")
                        posA = patch.get_path().vertices[0]
                        posB = patch.get_path().vertices[-1]
                        new_arrow_patch = FancyArrowPatch(
                            posA=posA,
                            posB=posB,
                            arrowstyle=patch.get_arrowstyle(),
                            mutation_scale=patch.get_mutation_scale(),
                            facecolor=patch.get_facecolor(),
                            edgecolor=patch.get_edgecolor(),
                            linewidth=patch.get_linewidth(),
                            alpha=patch.get_alpha()
                        )
                        new_ax.add_patch(new_arrow_patch)
                        print(f"[DEBUG] Successfully recreated FancyArrowPatch")
                    
                    else:
                        # For other patch types, log and skip
                        print(f"[DEBUG] Skipping unsupported patch type: {type(patch).__name__}")
            
            # Copy annotations (text with arrows) - CRITICAL FOR PEAK LABELS
            annotations = [artist for artist in ax.get_children() 
                          if hasattr(artist, 'arrow_patch') or 
                          (hasattr(artist, '__class__') and 
                           artist.__class__.__name__ == 'Annotation')]
            num_annotations = len(annotations)
            print(f"[DEBUG] Found {num_annotations} annotations on axis")
            
            if num_annotations > 0:
                print(f"[DEBUG] Copying {num_annotations} annotations to new axis")
                for artist in annotations:
                    try:
                        # Get annotation properties
                        text = artist.get_text()
                        xy = artist.xy  # Point being annotated
                        xytext = artist.xyann  # Text position (tuple)
                            
                        # Get text properties
                        fontsize = artist.get_fontsize()
                        fontweight = artist.get_fontweight()
                        color = artist.get_color()
                        ha = artist.get_ha()
                        va = artist.get_va()
                        
                        # Get bbox properties
                        bbox = artist.get_bbox_patch()
                        bbox_props = None
                        if bbox:
                            bbox_props = dict(
                                boxstyle=bbox.get_boxstyle(),
                                facecolor=bbox.get_facecolor(),
                                edgecolor=bbox.get_edgecolor(),
                                alpha=bbox.get_alpha()
                            )
                        
                        # Get arrow properties
                        arrow_patch = artist.arrow_patch
                        arrowprops = None
                        if arrow_patch:
                            arrowprops = dict(
                                arrowstyle=getattr(arrow_patch, 'arrowstyle', '->'),
                                connectionstyle=getattr(arrow_patch, 'connectionstyle', 'arc3,rad=0'),
                                color=arrow_patch.get_edgecolor()[0:3] if hasattr(arrow_patch, 'get_edgecolor') else 'red',
                                lw=arrow_patch.get_linewidth() if hasattr(arrow_patch, 'get_linewidth') else 1
                            )
                        
                        # Create new annotation on new axis
                        new_ax.annotate(
                            text,
                            xy=xy,
                            xytext=xytext,
                            textcoords='offset points',
                            fontsize=fontsize,
                            fontweight=fontweight,
                            color=color,
                            ha=ha,
                            va=va,
                            bbox=bbox_props,
                            arrowprops=arrowprops,
                            zorder=10
                        )
                        print(f"[DEBUG] Copied annotation: '{text[:20]}...' at {xy}")
                    except Exception as e:
                        print(f"[DEBUG] Failed to copy annotation: {e}")
            
            # Copy axes properties
            new_ax.set_title(ax.get_title())
            new_ax.set_xlabel(ax.get_xlabel())
            new_ax.set_ylabel(ax.get_ylabel())
            new_ax.set_xlim(ax.get_xlim())
            new_ax.set_ylim(ax.get_ylim())
            
            # Copy legend if it exists and has valid artists
            legend = ax.get_legend()
            if legend and legend.get_texts():
                # Check if there are any labeled artists
                handles, labels = ax.get_legend_handles_labels()
                if handles and labels:
                    new_ax.legend(handles, labels, loc=legend._loc if hasattr(legend, '_loc') else 'best')
            
            # Add grid
            new_ax.grid(True, which='both', linestyle='--', linewidth=0.5)

        self.figure.tight_layout()
        self.canvas.draw()
    
    def update_plot_with_config(self, new_figure: Figure, config: Optional[Dict[str, Any]] = None):
        """
        Enhanced update_plot with robust configuration options.
        
        Args:
            new_figure: Matplotlib Figure to display
            config: Optional configuration dictionary with keys:
                - subplot_spacing: tuple (hspace, wspace) for spacing between subplots
                - grid: dict with {enabled: bool, alpha: float, linestyle: str, linewidth: float}
                - legend: dict with {loc: str, fontsize: int, framealpha: float}
                - title: dict with {fontsize: int, fontweight: str, pad: float}
                - axes: dict with {xlabel_fontsize: int, ylabel_fontsize: int, tick_labelsize: int}
                - figure: dict with {tight_layout: bool, constrained_layout: bool}
        """
        if config is None:
            config = {}
        
        # Clear and copy figure (same as update_plot)
        self.figure.clear()
        axes_list = new_figure.get_axes()
        
        if not axes_list:
            self.canvas.draw()
            return
        
        # Apply subplot spacing if specified
        if 'subplot_spacing' in config:
            hspace, wspace = config['subplot_spacing']
            self.figure.subplots_adjust(hspace=hspace, wspace=wspace)
        
        # Copy axes with enhanced configuration
        for i, ax in enumerate(axes_list):
            # Determine subplot layout
            if len(axes_list) == 1:
                new_ax = self.figure.add_subplot(111)
            else:
                # Calculate grid layout (prefer square-ish layouts)
                n_plots = len(axes_list)
                n_cols = int(np.ceil(np.sqrt(n_plots)))
                n_rows = int(np.ceil(n_plots / n_cols))
                new_ax = self.figure.add_subplot(n_rows, n_cols, i+1)
            
            # Copy plot elements (lines, collections, patches)
            self._copy_plot_elements(ax, new_ax)
            
            # Copy axes properties
            new_ax.set_title(ax.get_title())
            new_ax.set_xlabel(ax.get_xlabel())
            new_ax.set_ylabel(ax.get_ylabel())
            new_ax.set_xlim(ax.get_xlim())
            new_ax.set_ylim(ax.get_ylim())
            
            # Apply grid configuration
            if 'grid' in config:
                grid_cfg = config['grid']
                new_ax.grid(
                    grid_cfg.get('enabled', True),
                    which='both',
                    linestyle=grid_cfg.get('linestyle', '--'),
                    linewidth=grid_cfg.get('linewidth', 0.5),
                    alpha=grid_cfg.get('alpha', 0.3)
                )
            else:
                new_ax.grid(True, which='both', linestyle='--', linewidth=0.5)
            
            # Apply legend configuration
            legend = ax.get_legend()
            if legend and legend.get_texts():
                handles, labels = ax.get_legend_handles_labels()
                if handles and labels:
                    if 'legend' in config:
                        leg_cfg = config['legend']
                        new_ax.legend(
                            handles, labels,
                            loc=leg_cfg.get('loc', 'best'),
                            fontsize=leg_cfg.get('fontsize', 9),
                            framealpha=leg_cfg.get('framealpha', 0.8)
                        )
                    else:
                        new_ax.legend(handles, labels, loc='best')
            
            # Apply title configuration
            if 'title' in config and ax.get_title():
                title_cfg = config['title']
                new_ax.set_title(
                    ax.get_title(),
                    fontsize=title_cfg.get('fontsize', 12),
                    fontweight=title_cfg.get('fontweight', 'bold'),
                    pad=title_cfg.get('pad', 10)
                )
            
            # Apply axes configuration
            if 'axes' in config:
                axes_cfg = config['axes']
                new_ax.set_xlabel(
                    ax.get_xlabel(),
                    fontsize=axes_cfg.get('xlabel_fontsize', 11)
                )
                new_ax.set_ylabel(
                    ax.get_ylabel(),
                    fontsize=axes_cfg.get('ylabel_fontsize', 11)
                )
                new_ax.tick_params(
                    axis='both',
                    labelsize=axes_cfg.get('tick_labelsize', 9)
                )
        
        # Apply figure-level configuration
        if 'figure' in config:
            fig_cfg = config['figure']
            if fig_cfg.get('constrained_layout', False):
                self.figure.set_constrained_layout(True)
            elif fig_cfg.get('tight_layout', True):
                self.figure.tight_layout()
        else:
            # Default to tight_layout as requested
            self.figure.tight_layout()
        
        self.canvas.draw()
    
    def _copy_plot_elements(self, source_ax, target_ax):
        """
        Helper method to copy plot elements from source to target axis.
        Handles lines, collections (scatter, line collections), and patches.
        """
        # Copy lines
        for line in source_ax.get_lines():
            target_ax.plot(line.get_xdata(), line.get_ydata(),
                         label=line.get_label(),
                         color=line.get_color(),
                         linestyle=line.get_linestyle(),
                         linewidth=line.get_linewidth(),
                         marker=line.get_marker(),
                         markersize=line.get_markersize())
        
        # Copy collections
        from matplotlib.collections import LineCollection, PathCollection
        for collection in source_ax.collections:
            if isinstance(collection, LineCollection):
                segments = collection.get_segments()
                colors = collection.get_colors()
                linewidths = collection.get_linewidths()
                linestyles = collection.get_linestyles()
                new_collection = LineCollection(segments, colors=colors,
                                              linewidths=linewidths,
                                              linestyles=linestyles)
                target_ax.add_collection(new_collection)
            elif isinstance(collection, PathCollection):
                offsets = collection.get_offsets()
                if len(offsets) > 0:
                    target_ax.scatter(offsets[:, 0], offsets[:, 1],
                                    c=collection.get_facecolors(),
                                    s=collection.get_sizes()[0] if hasattr(collection, 'get_sizes') and len(collection.get_sizes()) > 0 else 50,
                                    edgecolors=collection.get_edgecolors(),
                                    label=collection.get_label() if not collection.get_label().startswith('_') else None,
                                    alpha=collection.get_alpha() or 1.0)
        
        # Copy patches (if not too many)
        if len(source_ax.patches) <= 100:
            from matplotlib.patches import Ellipse, Rectangle, FancyArrow, FancyArrowPatch
            for patch in source_ax.patches:
                if isinstance(patch, Ellipse):
                    new_patch = Ellipse(xy=patch.center, width=patch.width,
                                      height=patch.height, angle=patch.angle,
                                      facecolor=patch.get_facecolor(),
                                      edgecolor=patch.get_edgecolor(),
                                      linestyle=patch.get_linestyle(),
                                      linewidth=patch.get_linewidth(),
                                      alpha=patch.get_alpha())
                    target_ax.add_patch(new_patch)
                elif isinstance(patch, Rectangle):
                    new_patch = Rectangle(xy=(patch.get_x(), patch.get_y()),
                                        width=patch.get_width(),
                                        height=patch.get_height(),
                                        facecolor=patch.get_facecolor(),
                                        edgecolor=patch.get_edgecolor(),
                                        linewidth=patch.get_linewidth(),
                                        alpha=patch.get_alpha())
                    target_ax.add_patch(new_patch)
                elif isinstance(patch, FancyArrow):
                    new_patch = FancyArrow(x=patch.get_x(), y=patch.get_y(),
                                         dx=patch.get_width(), dy=patch.get_height(),
                                         width=getattr(patch, '_width', 0.01),
                                         head_width=getattr(patch, '_head_width', 0.03),
                                         head_length=getattr(patch, '_head_length', 0.05),
                                         facecolor=patch.get_facecolor(),
                                         edgecolor=patch.get_edgecolor(),
                                         linewidth=patch.get_linewidth(),
                                         alpha=patch.get_alpha())
                    target_ax.add_patch(new_patch)
                elif isinstance(patch, FancyArrowPatch):
                    posA = patch.get_path().vertices[0]
                    posB = patch.get_path().vertices[-1]
                    new_patch = FancyArrowPatch(posA=posA, posB=posB,
                                              arrowstyle=patch.get_arrowstyle(),
                                              mutation_scale=patch.get_mutation_scale(),
                                              facecolor=patch.get_facecolor(),
                                              edgecolor=patch.get_edgecolor(),
                                              linewidth=patch.get_linewidth(),
                                              alpha=patch.get_alpha())
                    target_ax.add_patch(new_patch)
    
    def plot_3d(self, data: Dict[str, np.ndarray], plot_type: str = 'scatter',
                title: str = "3D Visualization", config: Optional[Dict[str, Any]] = None):
        """
        Create 3D plot for dimensionality reduction or other 3D data.
        
        Args:
            data: Dictionary with keys:
                - 'x', 'y', 'z': Coordinate arrays
                - 'labels' (optional): Labels for coloring
                - 'colors' (optional): Color array
            plot_type: Type of 3D plot ('scatter', 'surface', 'wireframe')
            title: Plot title
            config: Optional configuration for axes, grid, etc.
        """
        if config is None:
            config = {}
        
        self.figure.clear()
        ax = self.figure.add_subplot(111, projection='3d')
        
        x = data.get('x', np.array([]))
        y = data.get('y', np.array([]))
        z = data.get('z', np.array([]))
        
        if len(x) == 0 or len(y) == 0 or len(z) == 0:
            ax.text2D(0.5, 0.5, "No 3D data to display", ha='center', va='center',
                     fontsize=14, color='gray', transform=ax.transAxes)
            self.canvas.draw()
            return
        
        if plot_type == 'scatter':
            # Scatter plot
            colors = data.get('colors', None)
            labels = data.get('labels', None)
            
            if colors is not None:
                scatter = ax.scatter(x, y, z, c=colors, cmap='viridis',
                                   s=config.get('marker_size', 50),
                                   alpha=config.get('alpha', 0.6))
                self.figure.colorbar(scatter, ax=ax, label='Value')
            elif labels is not None:
                # Color by labels
                unique_labels = np.unique(labels)
                colors_map = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
                for i, label in enumerate(unique_labels):
                    mask = labels == label
                    ax.scatter(x[mask], y[mask], z[mask],
                             c=[colors_map[i]],
                             label=f'Class {label}',
                             s=config.get('marker_size', 50),
                             alpha=config.get('alpha', 0.6))
                ax.legend()
            else:
                ax.scatter(x, y, z, c='blue',
                         s=config.get('marker_size', 50),
                         alpha=config.get('alpha', 0.6))
        
        elif plot_type == 'surface':
            # Surface plot (requires gridded data)
            if len(x.shape) == 1:
                # Create meshgrid if 1D arrays provided
                X, Y = np.meshgrid(x, y)
                Z = z.reshape(len(y), len(x))
            else:
                X, Y, Z = x, y, z
            
            ax.plot_surface(X, Y, Z, cmap='viridis',
                          alpha=config.get('alpha', 0.8),
                          antialiased=True)
        
        elif plot_type == 'wireframe':
            # Wireframe plot
            if len(x.shape) == 1:
                X, Y = np.meshgrid(x, y)
                Z = z.reshape(len(y), len(x))
            else:
                X, Y, Z = x, y, z
            
            ax.plot_wireframe(X, Y, Z,
                            color=config.get('color', 'blue'),
                            alpha=config.get('alpha', 0.6))
        
        # Set labels and title
        ax.set_xlabel(config.get('xlabel', 'X'), fontsize=11)
        ax.set_ylabel(config.get('ylabel', 'Y'), fontsize=11)
        ax.set_zlabel(config.get('zlabel', 'Z'), fontsize=11)
        ax.set_title(title, fontsize=13, fontweight='bold')
        
        # Set viewing angle
        ax.view_init(elev=config.get('elev', 20), azim=config.get('azim', 45))
        
        # Grid
        ax.grid(config.get('grid', True), alpha=0.3)
        
        self.figure.tight_layout()
        self.canvas.draw()
    
    def plot_dendrogram(self, dendrogram_data: Dict[str, Any],
                       title: str = "Hierarchical Clustering Dendrogram",
                       config: Optional[Dict[str, Any]] = None):
        """
        Create dendrogram plot for hierarchical clustering.
        
        Args:
            dendrogram_data: Dictionary returned by scipy.cluster.hierarchy.dendrogram
                            or linkage matrix to compute dendrogram from
            title: Plot title
            config: Optional configuration
        """
        if config is None:
            config = {}
        
        self.figure.clear()
        ax = self.figure.add_subplot(111)
        
        # Check if we have linkage matrix or dendrogram data
        from scipy.cluster.hierarchy import dendrogram, linkage
        
        if isinstance(dendrogram_data, dict) and 'icoord' in dendrogram_data:
            # Already computed dendrogram data - plot directly
            # Manually recreate dendrogram from data
            icoord = dendrogram_data['icoord']
            dcoord = dendrogram_data['dcoord']
            colors = dendrogram_data.get('color_list', ['C0'] * len(icoord))
            
            for i, (xi, yi) in enumerate(zip(icoord, dcoord)):
                ax.plot(xi, yi, color=colors[i],
                       linewidth=config.get('linewidth', 1.5))
        
        elif isinstance(dendrogram_data, np.ndarray):
            # Linkage matrix - compute and plot dendrogram
            dend = dendrogram(
                dendrogram_data,
                ax=ax,
                orientation=config.get('orientation', 'top'),
                color_threshold=config.get('color_threshold', None),
                above_threshold_color=config.get('above_threshold_color', 'grey'),
                leaf_font_size=config.get('leaf_font_size', 8)
            )
        
        else:
            ax.text(0.5, 0.5, "Invalid dendrogram data", ha='center', va='center',
                   fontsize=14, color='gray', transform=ax.transAxes)
            self.canvas.draw()
            return
        
        # Set labels and title
        ax.set_title(title, fontsize=13, fontweight='bold')
        ax.set_xlabel(config.get('xlabel', 'Sample Index'), fontsize=11)
        ax.set_ylabel(config.get('ylabel', 'Distance'), fontsize=11)
        ax.grid(config.get('grid', True), axis='y', alpha=0.3)
        
        self.figure.tight_layout()
        self.canvas.draw()

    def clear_plot(self):
        """Clears the plot area."""
        self.figure.clear()
        self.canvas.draw()
    
    def plot_spectra(self, data, title="Spectra", auto_focus=False, focus_padding=None, crop_bounds=None):
        """Plot spectra data directly."""
        self.figure.clear()
        ax = self.figure.add_subplot(111)
        
        if data is None:
            ax.text(0.5, 0.5, "No data to display", ha='center', va='center', 
                   fontsize=14, color='gray', transform=ax.transAxes)
            self.canvas.draw()
            return
        
        # Handle different data types
        if hasattr(data, 'columns'):
            # DataFrame - handle this first before checking for shape
            num_spectra = min(data.shape[1], 10)
            for i, column in enumerate(data.columns[:num_spectra]):
                ax.plot(data.index, data[column], label=column)
        elif hasattr(data, 'shape') and len(data.shape) == 2:
            # Numpy array or similar
            num_spectra = min(data.shape[1] if data.shape[1] < data.shape[0] else data.shape[0], 10)
            for i in range(num_spectra):
                spectrum = data[:, i] if data.shape[1] < data.shape[0] else data[i, :]
                ax.plot(spectrum, label=f"Spectrum {i+1}")
        
        ax.set_title(title)
        ax.set_xlabel("Wavenumber (cmâ»Â¹)")
        ax.set_ylabel("Intensity (a.u.)")
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # Apply auto-focus only if requested and data has wavenumber index
        if auto_focus:
            try:
                if hasattr(data, 'index') and hasattr(data, 'values'):
                    # DataFrame with wavenumber index
                    wavenumbers = data.index.values
                    intensities = data.values
                    min_wn, max_wn = detect_signal_range(wavenumbers, intensities.T, focus_padding=focus_padding, crop_bounds=crop_bounds)  # Transpose for proper shape
                    ax.set_xlim(min_wn, max_wn)
            except Exception as e:
                pass  # Silently fall back to full range
        
        self.figure.tight_layout()
        self.canvas.draw()
    
    def plot_comparison_spectra(self, original_data, processed_data, titles=None, colors=None):
        """Plot comparison between original and processed data."""
        self.figure.clear()
        ax = self.figure.add_subplot(111)
        
        if titles is None:
            titles = ["Original", "Processed"]
        if colors is None:
            colors = ["lightblue", "darkblue"]
        
        # Plot original data (sample)
        if original_data is not None:
            num_original = min(5, original_data.shape[1] if hasattr(original_data, 'shape') and len(original_data.shape) == 2 else len(original_data))
            for i in range(num_original):
                if hasattr(original_data, 'shape') and len(original_data.shape) == 2:
                    spectrum = original_data[:, i] if original_data.shape[1] < original_data.shape[0] else original_data[i, :]
                    x_data = range(len(spectrum))
                else:
                    spectrum = original_data
                    x_data = range(len(spectrum))
                
                ax.plot(x_data, spectrum, color=colors[0], alpha=0.6, linewidth=1, 
                       label=titles[0] if i == 0 else "")
        
        # Plot processed data
        if processed_data is not None:
            num_processed = min(5, processed_data.shape[1] if hasattr(processed_data, 'shape') and len(processed_data.shape) == 2 else len(processed_data))
            for i in range(num_processed):
                if hasattr(processed_data, 'shape') and len(processed_data.shape) == 2:
                    spectrum = processed_data[:, i] if processed_data.shape[1] < processed_data.shape[0] else processed_data[i, :]
                    x_data = range(len(spectrum))
                else:
                    spectrum = processed_data
                    x_data = range(len(spectrum))
                
                ax.plot(x_data, spectrum, color=colors[1], alpha=0.8, linewidth=1.5,
                       label=titles[1] if i == 0 else "")
        
        ax.set_title("Preprocessing Preview")
        ax.set_xlabel("Wavenumber (cmâ»Â¹)")
        ax.set_ylabel("Intensity (a.u.)")
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        self.figure.tight_layout()
        self.canvas.draw()

    def plot_comparison_spectra_with_wavenumbers(self, original_data, processed_data, 
                                               original_wavenumbers, processed_wavenumbers,
                                               titles=None, colors=None, auto_focus=True, focus_padding=None, crop_bounds=None):
        """Plot comparison between original and processed data with proper wavenumber axes."""
        self.figure.clear()
        ax = self.figure.add_subplot(111)
        
        if titles is None:
            titles = ["Original", "Processed"]
        if colors is None:
            colors = ["lightblue", "darkblue"]
        
        # Plot original data (sample) with actual wavenumbers
        if original_data is not None and original_wavenumbers is not None:
            num_original = min(5, original_data.shape[0] if hasattr(original_data, 'shape') and len(original_data.shape) == 2 else 1)
            for i in range(num_original):
                if hasattr(original_data, 'shape') and len(original_data.shape) == 2:
                    spectrum = original_data[i, :]
                else:
                    spectrum = original_data
                
                ax.plot(original_wavenumbers, spectrum, color=colors[0], alpha=0.6, linewidth=1, 
                       label=titles[0] if i == 0 else "")
        
        # Plot processed data with actual wavenumbers
        if processed_data is not None and processed_wavenumbers is not None:
            num_processed = min(5, processed_data.shape[0] if hasattr(processed_data, 'shape') and len(processed_data.shape) == 2 else 1)
            for i in range(num_processed):
                if hasattr(processed_data, 'shape') and len(processed_data.shape) == 2:
                    spectrum = processed_data[i, :]
                else:
                    spectrum = processed_data
                
                ax.plot(processed_wavenumbers, spectrum, color=colors[1], alpha=0.8, linewidth=1.5,
                       label=titles[1] if i == 0 else "")
        
        ax.set_title("Preprocessing Preview")
        ax.set_xlabel("Wavenumber (cmâ»Â¹)")
        ax.set_ylabel("Intensity (a.u.)")
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # Apply auto-focus only if requested
        if auto_focus:
            try:
                # Determine the best range from the available data
                focus_wavenumbers = processed_wavenumbers if processed_wavenumbers is not None else original_wavenumbers
                
                if focus_wavenumbers is not None:
                    # Get intensity data for range detection
                    if processed_data is not None:
                        focus_intensities = processed_data
                    elif original_data is not None:
                        focus_intensities = original_data
                    else:
                        focus_intensities = None
                    
                    if focus_intensities is not None:
                        min_wn, max_wn = detect_signal_range(focus_wavenumbers, focus_intensities, focus_padding=focus_padding, crop_bounds=crop_bounds)
                        ax.set_xlim(min_wn, max_wn)
                    
            except Exception as e:
                pass  # Silently fall back to full range
        
        self.figure.tight_layout()
        self.canvas.draw()


def plot_spectra(df: pd.DataFrame, title: str = "", auto_focus: bool = False) -> Figure:
    """
    Generates a matplotlib Figure object containing a plot of the spectra.
    Plots a maximum of 10 spectra for clarity and applies themed styling.
    
    Args:
        df: DataFrame with wavenumber index and intensity columns
        title: Plot title
        auto_focus: Whether to automatically focus on signal regions
    """
    
    fig = Figure(figsize=(8, 6), dpi=100, facecolor='#eaf2f8') # Themed background
    ax = fig.add_subplot(111, facecolor='#eaf2f8') # Themed background

    # --- Robustness Check ---
    if df is None or df.empty:
        ax.text(0.5, 0.5, "No data to display.", ha='center', va='center', fontsize=14, color='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        fig.tight_layout()
        return fig

    # --- Plotting Logic ---
    num_spectra = df.shape[1]
    plot_title = "Loaded Raman Spectra"
    
    # Limit the number of plotted spectra for clarity
    if num_spectra > 10:
        df_to_plot = df.iloc[:, :10]
        plot_title += f" (showing first 10 of {num_spectra})"
    else:
        df_to_plot = df

    # Plot each spectrum
    for i, column in enumerate(df_to_plot.columns):
        ax.plot(df_to_plot.index, df_to_plot[column], label=column)
    
    ax.set_title(plot_title, fontsize=14, weight='bold')
    ax.set_xlabel("Wavenumber (cmâ»Â¹)", fontsize=12)
    ax.set_ylabel("Intensity (a.u.)", fontsize=12)
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='#d1dbe5')
    
    # Customize legend
    legend = ax.legend(facecolor='#ffffff', framealpha=0.7)
    for text in legend.get_texts():
        text.set_color('#34495e')

    # Customize tick colors
    ax.tick_params(axis='x', colors='#34495e', labelsize=10)
    ax.tick_params(axis='y', colors='#34495e', labelsize=10)

    # Customize spine colors
    for spine in ax.spines.values():
        spine.set_edgecolor('#34495e')

    # Apply auto-focus only if requested
    if auto_focus:
        try:
            wavenumbers = df_to_plot.index.values
            intensities = df_to_plot.values
            min_wn, max_wn = detect_signal_range(wavenumbers, intensities.T)  # Transpose for proper shape
            ax.set_xlim(min_wn, max_wn)
        except Exception as e:
            pass  # Silently fall back to full range

    # Adjust layout with explicit padding to ensure y-axis labels are visible
    fig.tight_layout(pad=1.5)  # Increased padding for better visibility
    fig.subplots_adjust(left=0.12, right=0.95, top=0.93, bottom=0.10)  # Explicit margins for y-axis labels
    return fig


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\components\widgets\utils.py ##

import sys
import os
import pandas as pd
import numpy as np
import ramanspy as rp
import traceback
from typing import Dict, List, Any, Optional, Tuple
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QGridLayout, QPushButton,
    QLabel, QLineEdit, QGroupBox, QListWidget, QListWidgetItem,
    QStackedWidget, QComboBox, QDoubleSpinBox, QSpinBox, QMessageBox,
    QCheckBox, QSlider, QTextEdit, QScrollArea, QFrame, QSplitter,
    QProgressBar, QApplication, QDialog, QDialogButtonBox, QTreeWidget,
    QTreeWidgetItem, QFormLayout, QTabWidget
)
from PySide6.QtCore import Signal, Qt, QSize, QThread, QTimer
from PySide6.QtGui import QIcon
from PySide6.QtSvgWidgets import QSvgWidget
from PySide6.QtSvg import QSvgRenderer

# Import utils functions
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from utils import create_logs, LOCALIZE
from PySide6.QtCore import Qt, Signal, QThread, QTimer, QSize
from PySide6.QtGui import QFont, QIcon

from utils import *
from .matplotlib_widget import MatplotlibWidget, plot_spectra
from functions.preprocess import PREPROCESSING_REGISTRY, EnhancedRamanPipeline


## J:\Coding\??\raman-app\.docs\reference\analysis_page\2025-12-03_analysis_page_pca_method_analysis_1\analysis_page_ai\components\widgets\views_widget.py ##

from typing import Dict, Any, Callable, Optional
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QFrame, QScrollArea, QTabWidget, QGroupBox, QComboBox,
    QSplitter, QTextEdit, QTableWidget, QTableWidgetItem, QListWidget,
    QAbstractItemView, QStackedWidget, QButtonGroup, QRadioButton, QCheckBox, 
    QTreeView, QTreeWidget, QTreeWidgetItem, QInputDialog
)
from PySide6.QtCore import Qt, QSize
from PySide6.QtGui import QFont, QIcon


class GroupTreeManager(QWidget):
    """
    A professional Tree-based widget for managing dataset groups.
    Features: Drag & Drop, Auto-Assign, Context Menus.
    """
    def __init__(self, dataset_names, localize_func, parent=None):
        super().__init__(parent)
        self.dataset_names = dataset_names
        self.localize = localize_func
        self._setup_ui()
        self.reset() # Initialize with all items in Unassigned

    def _setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(0)

        # 1. Unified Toolbar (User Request #1)
        toolbar = QFrame()
        toolbar.setStyleSheet("""
            QFrame { 
                background-color: #f9f9f9; 
                border: 1px solid #ccc; 
                border-bottom: none;
                border-top-left-radius: 4px; 
                border-top-right-radius: 4px; 
            }
        """)
        tb_layout = QHBoxLayout(toolbar)
        tb_layout.setContentsMargins(8, 4, 8, 4)
        tb_layout.setSpacing(10)

        # Toolbar Buttons
        btn_style = """
            QPushButton { 
                border: none; color: #333; font-size: 11px; font-weight: 600; 
                background: transparent; padding: 5px 10px; border-radius: 3px; 
            }
            QPushButton:hover { background-color: #e0e0e0; color: #000; }
        """
        
        self.btn_create = QPushButton("âž• Create Group")
        self.btn_create.setStyleSheet(btn_style)
        self.btn_create.clicked.connect(self.create_group_dialog)

        self.btn_auto = QPushButton("âœ¨ Auto-Assign")
        self.btn_auto.setStyleSheet(btn_style)
        self.btn_auto.clicked.connect(self.auto_assign)

        self.btn_reset = QPushButton("â†º Reset")
        self.btn_reset.setStyleSheet(btn_style)
        self.btn_reset.clicked.connect(self.reset)

        tb_layout.addWidget(self.btn_create)
        tb_layout.addWidget(self.btn_auto)
        tb_layout.addWidget(self.btn_reset)
        tb_layout.addStretch()

        layout.addWidget(toolbar)

        # 2. The Tree Gadget (User Request #2)
        self.tree = QTreeWidget()
        self.tree.setHeaderHidden(True)
        self.tree.setDragEnabled(True)
        self.tree.setAcceptDrops(True)
        self.tree.setDropIndicatorShown(True)
        self.tree.setDragDropMode(QAbstractItemView.InternalMove)
        self.tree.setSelectionMode(QAbstractItemView.ExtendedSelection)
        
        # Styling the Tree to look professional
        self.tree.setStyleSheet("""
            QTreeWidget {
                border: 1px solid #ccc;
                border-bottom-left-radius: 4px;
                border-bottom-right-radius: 4px;
                font-size: 13px;
            }
            QTreeWidget::item { 
                height: 28px; 
                padding-left: 4px;
            }
            QTreeWidget::item:hover { background-color: #f0f0f0; }
            QTreeWidget::item:selected { background-color: #e7f3ff; color: #0078d4; }
        """)
        
        layout.addWidget(self.tree)

    def reset(self):
        """Reset tree: Clear all groups, put everything in 'Unassigned'."""
        self.tree.clear()
        
        # Create immutable "Unassigned" group
        self.unassigned_root = QTreeWidgetItem(self.tree)
        self.unassigned_root.setText(0, "ðŸ“‚ Unassigned Datasets")
        self.unassigned_root.setFlags(Qt.ItemIsEnabled | Qt.ItemIsDropEnabled) # Not selectable/draggable itself, just a container
        self.unassigned_root.setForeground(0, Qt.darkGray)
        
        # Add datasets
        icon_dataset = QIcon() # You can add a file icon here if available
        for name in self.dataset_names:
            item = QTreeWidgetItem(self.unassigned_root)
            item.setText(0, name)
            item.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable | Qt.ItemIsDragEnabled)
        
        self.tree.expandAll()

    def create_group_dialog(self):
        """Prompt user for group name and create it."""
        dialog = QInputDialog(self)
        dialog.setWindowTitle(self.localize("ANALYSIS_PAGE.create_group_title") if self.localize else "Create Group")
        dialog.setLabelText(self.localize("ANALYSIS_PAGE.group_name_label") if self.localize else "Group Name:")
        dialog.setStyleSheet("""
            QInputDialog {
                background-color: #ffffff;
            }
            QLabel {
                color: #2c3e50;
                font-size: 13px;
            }
            QLineEdit {
                padding: 8px;
                border: 1px solid #dfe3ea;
                border-radius: 4px;
                background-color: #ffffff;
                color: #2c3e50;
                font-size: 13px;
            }
            QLineEdit:focus {
                border-color: #0078d4;
            }
            QPushButton {
                padding: 8px 16px;
                border-radius: 4px;
                font-weight: 600;
                font-size: 13px;
                min-width: 80px;
            }
            QPushButton[text="OK"] {
                background-color: #0078d4;
                color: white;
                border: none;
            }
            QPushButton[text="OK"]:hover {
                background-color: #006abc;
            }
            QPushButton[text="Cancel"] {
                background-color: white;
                color: #2c3e50;
                border: 1px solid #dfe3ea;
            }
            QPushButton[text="Cancel"]:hover {
                background-color: #f8f9fa;
            }
        """)
        
        ok = dialog.exec()
        text = dialog.textValue()
        
        if ok and text:
            self.add_group(text)

    def add_group(self, name):
        """Add a new group folder to the tree."""
        group_root = QTreeWidgetItem(self.tree)
        group_root.setText(0, f"ðŸ§ª {name}")
        group_root.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable | Qt.ItemIsDropEnabled | Qt.ItemIsEditable)
        # Insert before 'Unassigned' (which is usually last index or 0 depending on logic, let's just append)
        self.tree.addTopLevelItem(group_root)
        group_root.setExpanded(True)
        return group_root

    def auto_assign(self):
        """
        Auto-assign datasets to existing groups based on name matching.
        
        Logic:
        1. Check if groups exist (excluding Unassigned)
        2. If no groups, show dialog prompting user to create groups first
        3. For each unassigned dataset, check if group name appears in dataset name
        4. Case-insensitive matching with partial string search
        """
        from PySide6.QtWidgets import QMessageBox
        import re
        
        # 1. Get all existing groups (exclude Unassigned)
        existing_groups = []
        root = self.tree.invisibleRootItem()
        for i in range(root.childCount()):
            group_item = root.child(i)
            if group_item != self.unassigned_root:
                # Remove emoji prefix if present
                group_name = group_item.text(0).replace("ðŸ§ª ", "")
                existing_groups.append((group_name, group_item))
        
        # 2. Check if any groups exist
        if not existing_groups:
            msg = QMessageBox(self)
            msg.setWindowTitle(self.localize("ANALYSIS_PAGE.auto_assign_no_groups_title") if self.localize else "No Groups Available")
            msg.setText(self.localize("ANALYSIS_PAGE.auto_assign_no_groups_message") if self.localize else 
                       "Please create at least one group before using Auto-Assign.\n\nClick 'Create Group' to get started.")
            msg.setIcon(QMessageBox.Information)
            msg.setStyleSheet("""
                QMessageBox {
                    background-color: white;
                }
                QLabel {
                    color: #2c3e50;
                    font-size: 13px;
                }
                QPushButton {
                    background-color: #0078d4;
                    color: white;
                    border: none;
                    border-radius: 4px;
                    padding: 6px 16px;
                    font-weight: 600;
                    font-size: 13px;
                    min-width: 60px;
                }
                QPushButton:hover {
                    background-color: #006abc;
                }
            """)
            msg.exec()
            return
        
        # 3. Gather unassigned items
        items_to_process = []
        for i in range(self.unassigned_root.childCount()):
            items_to_process.append(self.unassigned_root.child(i))
        
        if not items_to_process:
            return  # Nothing to assign
        
        # 4. Match datasets to groups
        assigned_count = 0
        for item in items_to_process:
            dataset_name = item.text(0)
            dataset_name_lower = dataset_name.lower()
            
            # Try to match with existing groups
            best_match = None
            best_match_length = 0
            
            for group_name, group_item in existing_groups:
                group_name_lower = group_name.lower()
                
                # Check if group name appears in dataset name (case-insensitive)
                if group_name_lower in dataset_name_lower:
                    # Prefer longer matches (e.g., "MGUS" over "MM" if both match)
                    if len(group_name) > best_match_length:
                        best_match = group_item
                        best_match_length = len(group_name)
            
            # Assign to best matching group
            if best_match:
                cloned_item = item.clone()
                self.unassigned_root.removeChild(item)
                best_match.addChild(cloned_item)
                assigned_count += 1
        
        # Optional: Show summary message if useful
        # print(f"Auto-assigned {assigned_count} dataset(s) to existing groups")

    def get_groups(self):
        """
        Returns dictionary of { "GroupName": ["Dataset1", "Dataset2"] }
        Ignores the 'Unassigned' folder.
        """
        result = {}
        root = self.tree.invisibleRootItem()
        
        for i in range(root.childCount()):
            group_item = root.child(i)
            
            # Skip the Unassigned folder
            if group_item == self.unassigned_root:
                continue
                
            group_name = group_item.text(0).replace("ðŸ§ª ", "") # Remove emoji
            datasets = []
            
            for j in range(group_item.childCount()):
                datasets.append(group_item.child(j).text(0))
                
            if datasets:
                result[group_name] = datasets
                
        return result




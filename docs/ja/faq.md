# よくある質問（FAQ）

ラマン分光分析アプリケーションについてよくある質問と回答

---

## 📋 目次

- {ref}`一般的な質問 <faq-general>`
- {ref}`インストールとセットアップ <faq-install>`
- {ref}`データのインポート <faq-import>`
- {ref}`前処理 <faq-preprocess>`
- {ref}`分析と結果 <faq-analysis>`
- {ref}`機械学習 <faq-ml>`
- {ref}`エラーとトラブルシューティング <faq-troubleshooting>`
- {ref}`高度な使用方法 <faq-advanced>`

---

(faq-general)=
## 一般的な質問

### Q1: このアプリケーションは何ができますか？

**A:** ラマン分光データの包括的な分析が可能です：

- **データ管理**: CSV/Excel形式のスペクトルのインポート、グループ管理、プロジェクト保存
- **データ管理**: CSV/TXT/ASC/ASCII/PKL 形式のスペクトルのインポート、グループ管理
- **前処理**: 40以上の手法（ベースライン補正、スムージング、正規化、微分など）
- **探索的分析**: PCA、UMAP、t-SNE、クラスタリング
- **統計分析**: t検定、ANOVA、相関分析、効果量計算
- **機械学習**: SVM、Random Forest、XGBoost、ロジスティック回帰
- **可視化**: 高品質なプロット、図のエクスポート
- **結果のエクスポート**: データ（CSV / XLSX / JSON / TXT / PKL）、図（PNG / SVG）

### Q2: 無料で使用できますか？

**A:** はい、このアプリケーションはMITライセンスの下でオープンソースとして公開されています。商用、研究、教育目的で無料で使用できます。

### Q3: どのような研究分野に適していますか？

**A:** 以下の分野で広く使用できます：

- **化学**: 化合物の識別、構造解析
- **材料科学**: ポリマー、セラミックス、複合材料の特性評価
- **生物医学**: バイオマーカー検出、組織分類
- **薬学**: 医薬品の品質管理、偽造品検出
- **環境科学**: 汚染物質の同定
- **法科学**: 証拠物の分析
- **宝石学**: 宝石の真贋鑑定
- **教育**: ラマン分光法の学習と指導

### Q4: プログラミングの知識は必要ですか？

**A:** いいえ、基本的な使用には不要です。グラフィカルユーザーインターフェース（GUI）ですべての機能にアクセスできます。

ただし、以下の場合はPythonの知識があると便利です：
- カスタム前処理手法の追加
- 新しい分析アルゴリズムの実装
- バッチ処理の自動化
- カスタムエクスポート形式の作成

### Q5: 他のソフトウェアと比較した利点は何ですか？

**A:** 主な利点：

✅ **無料でオープンソース**: 商用ソフトウェアと異なり、コストがかかりません
✅ **包括的**: 前処理から機械学習まですべて1つのアプリで
✅ **最新の手法**: 最新の機械学習アルゴリズム（XGBoost、UMAP）
✅ **カスタマイズ可能**: Pythonで拡張可能
✅ **クロスプラットフォーム**: Windows、macOS、Linux対応
✅ **活発な開発**: GitHubでのオープンな開発
✅ **完全なドキュメント**: 包括的な使用ガイドとチュートリアル

---

(faq-install)=
## インストールとセットアップ

### Q6: システム要件は何ですか？

**A:** 

**最小要件**:
- OS: Windows 10、macOS 11、Ubuntu 20.04以上
- RAM: 4 GB
- ディスク: 500 MB空き容量
- Python: 3.12（3.12.x）（ソースから実行する場合）

**推奨要件**:
- RAM: 8 GB以上
- CPU: マルチコアプロセッサ
- ディスク: 1 GB空き容量（SSD推奨）
- GPU: CUDA対応（深層学習機能使用時）

### Q7: インストール方法を教えてください

**A:** 3つの方法があります：

**方法1: 実行可能ファイル（最も簡単）**
```bash
# 1. GitHubリリースページからダウンロード
# 2. ZIPを解凍またはインストーラーを実行
# 3. アプリケーションを起動
```

**方法2: Pythonパッケージ**
```bash
# （注）PyPI での配布は前提にしていません。
# このリポジトリから実行する場合は、方法3（ソースから）を利用してください。
```

**方法3: ソースから**
```bash
git clone https://github.com/zerozedsc/Raman-Spectroscopy-Analysis-Application.git
cd Raman-Spectroscopy-Analysis-Application
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -e .
python main.py
```

詳細は[インストールガイド](installation.md)をご覧ください。

### Q8: "ModuleNotFoundError"が表示されます

**A:** 依存関係がインストールされていません。以下を実行してください：

```bash
# 仮想環境を有効化
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows

# 依存関係をインストール
pip install -e .

# または特定のパッケージ
uv pip install numpy scipy scikit-learn PyQt6 matplotlib pandas
```

### Q9: Windows で "VCRUNTIME140.dll が見つかりません" エラー

**A:** Visual C++ Redistributableをインストールしてください：

1. [Microsoft公式サイト](https://aka.ms/vs/17/release/vc_redist.x64.exe)からダウンロード
2. インストーラーを実行
3. アプリケーションを再起動

### Q10: macOS で "破損しているため開けません" エラー

**A:** Gatekeeperの制限を解除してください：

```bash
# ターミナルで実行
xattr -cr /Applications/RamanApp.app

# または
sudo xattr -rd com.apple.quarantine /Applications/RamanApp.app
```

その後、システム環境設定 → セキュリティとプライバシーで「このまま開く」をクリック。

---

(faq-import)=
## データのインポート

### Q11: どのようなデータ形式がサポートされていますか？

**A:** 以下の形式をサポートしています：

- **CSV** (.csv) - 推奨、最も互換性が高い
- **テキスト** (.txt) - タブまたはスペース区切り
- **ASCII** (.asc, .ascii) - テキスト形式（波数・強度の2列）
- **PKL** (.pkl) - Python/pandas のデータ

**期待されるフォーマット**:
```text
Wavenumber,Sample1,Sample2,Sample3
400,0.123,0.145,0.112
401,0.134,0.156,0.123
402,0.145,0.167,0.134
...
```

### Q12: データが正しくロードされません

**A:** 以下を確認してください：

**チェックリスト**:
- ✅ ヘッダー行がある（列名）
- ✅ 第1列が波数
- ✅ 数値データのみ（テキストや空白セルなし）
- ✅ すべての行が同じ列数
- ✅ カンマ区切り（CSV）
- ✅ 適切なエンコーディング（UTF-8推奨）

**よくある問題**:
- 小数点がカンマ（`,`）の場合 → ピリオド（`.`）に変更
- タブ区切りの場合 → CSV形式に変換
- 複数のヘッダー行 → 最初の1行のみに

### Q13: 大きなデータセット（数千スペクトル）をロードできますか？

**A:** はい、可能です。ただし以下に注意：

**推奨事項**:
- **RAM**: 8 GB以上推奨
- **ファイルサイズ**: 100 MBまで快適に動作
- **スペクトル数**: 〜5,000スペクトルまで
- **波数ポイント**: 〜10,000ポイントまで

**大規模データの場合**:
1. データを分割してバッチ処理
2. 波数範囲を制限（関心領域のみ）
3. ダウンサンプリング（必要な場合）
4. 64ビットPythonを使用

### Q14: 複数のファイルを一度にインポートできますか？

**A:** はい、バッチインポート機能があります：

```
データパッケージ → ファイルをインポート → 
複数選択（Ctrl/Cmd + クリック） → ロード
```

すべてのファイルが同じ波数範囲である必要があります。

### Q15: スペクトルをグループ化する方法は？

**A:** 

**方法1: インポート時**
1. データパッケージ → グループ管理
2. 新規グループを作成
3. サンプルを選択してグループに割り当て

**方法2: CSVファイル名から**
```
sample_A_001.csv  → グループ A
sample_A_002.csv  → グループ A
sample_B_001.csv  → グループ B
```
ファイル名のパターンから自動的にグループ化

**方法3: メタデータファイル**
別のCSVファイルでサンプルとグループの対応を定義

---

(faq-preprocess)=
## 前処理

### Q16: どの前処理手法を使用すればよいですか？

**A:** 目的とデータによります：

**一般的なパイプライン（初心者向け）**:
```
1. AsLS (ベースライン補正)
   - lambda: 100000
   - p: 0.01

2. Savitzky-Golay (スムージング)
   - window: 11
   - polyorder: 3

3. ベクトルノルム (正規化)
```

**品質管理用**:
```
1. AsLS
2. SNV (標準正規変量変換)
3. MSC (多重散乱補正)
```

**微小な差の検出用**:
```
1. AirPLS (適応的ベースライン)
2. 一次微分 (Savitzky-Golay)
3. 分位点正規化
```

詳細は[前処理ガイド](user-guide/preprocessing.md)をご覧ください。

### Q17: AsLSの`lambda`と`p`パラメータの意味は？

**A:** 

**lambda（平滑化パラメータ）**:
- **大きい値** (10⁶-10⁷): 非常に滑らかなベースライン、広いピークに適用
- **中程度** (10⁴-10⁵): 標準的な使用、ほとんどのケースで推奨
- **小さい値** (10²-10³): ピークに追従、狭いベースライン変動用

**p（非対称性パラメータ）**:
- **小さい値** (0.001-0.01): ピークを保護、スペクトルがベースライン上にある
- **中程度** (0.05-0.1): バランスが取れている
- **大きい値** (0.1-0.5): より強い補正、大きなドリフトがある場合

**推奨設定**:
```python
# 標準的なラマンスペクトル
lambda = 100000
p = 0.01

# 強い蛍光バックグラウンド
lambda = 1000000
p = 0.001

# 小さなベースライン変動
lambda = 10000
p = 0.05
```

### Q18: 前処理後にピークが消えました

**A:** パラメータが強すぎる可能性があります：

**原因と解決策**:

1. **スムージングが過剰**
   - 問題: `window`が大きすぎる（例: 31）
   - 解決: より小さい値を試す（7-15）

2. **ベースライン補正が過剰**
   - 問題: `lambda`が小さすぎる、`p`が大きすぎる
   - 解決: `lambda`を増やす、`p`を減らす

3. **微分の不適切な使用**
   - 問題: ノイズの多いデータに微分を適用
   - 解決: 微分の前にスムージング

**ベストプラクティス**:
- プレビュー機能を使用して効果を確認
- パラメータを段階的に調整
- 元のスペクトルと比較

### Q19: 前処理パイプラインを保存できますか？

**A:** はい、可能です：

**方法1: テンプレートとして保存**
```
前処理 → パイプライン → 保存 → 
名前を入力（例: "標準パイプライン"） → OK
```

**方法2: プロジェクトに含めて保存**
```
ファイル → プロジェクトを保存 →
（パイプライン設定が自動的に含まれる）
```

**方法3: エクスポートして共有**
```
前処理 → パイプライン → エクスポート → JSON
（他のユーザーと共有可能）
```

### Q20: バッチで複数のスペクトルに同じ前処理を適用できますか？

**A:** はい、自動的に適用されます：

```
1. すべてのスペクトルを選択（Ctrl/Cmd + A）
2. 前処理パイプラインを構築
3. 「適用」をクリック
→ すべてのスペクトルに自動的に適用
```

進行状況バーが表示され、処理完了後に結果が確認できます。

---

(faq-analysis)=
## 分析と結果

### Q21: PCAの成分数はいくつにすべきですか？

**A:** 

**推奨アプローチ**:
1. **最初は2-3成分**から始めて可視化
2. **スクリープロット**を確認して最適な数を決定
3. **累積説明分散**を見て、目標（通常90%以上）を達成

**目的別**:
- **可視化目的**: 2-3成分（スコアプロット用）
- **機械学習の前処理**: 説明分散90-95%に達する数
- **ノイズ除去**: 最初の5-10成分

**例**:
```python
# 説明分散を確認
n_components = 10
pca = PCA(n_components=n_components)
pca.fit(data)

# 累積説明分散をプロット
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('成分数')
plt.ylabel('累積説明分散')

# 90%に達する成分数を選択
```

### Q22: PCAのスコアプロットで外れ値を見つけました。どうすればよいですか？

**A:** 

**ステップ1: 外れ値を確認**
```
1. スコアプロット上の点をクリック
2. 元のスペクトルを確認
3. データ品質を評価
```

**ステップ2: 原因を特定**
- **測定エラー**: ノイズが多い、シグナルなし → 除去
- **異なるサンプル**: 実際に異なる → 保持、別グループに
- **汚染**: バックグラウンド信号 → 可能なら補正、または除去

**ステップ3: 対処**
```text
# 除去する場合
data_page → 外れ値を選択 → 削除

# 別グループにする場合
data_page → 外れ値を選択 → 新規グループ作成
```

### Q23: クラスタリングで最適なクラスター数を決定する方法は？

**A:** 複数の方法があります：

**方法1: エルボー法**
```
1. K-meansを異なるk値で実行（k=2〜10）
2. 各kのイナーシャ（Within-cluster sum of squares）を計算
3. プロット上で「エルボー」を探す
```

**方法2: シルエット分析**
```
1. 各kのシルエットスコアを計算
2. 最も高いスコアのkを選択
3. スコア > 0.5 が良好
```

**方法3: デンドログラム（階層的クラスタリング）**
```
1. 階層的クラスタリングを実行
2. デンドログラムで自然な切断点を探す
3. その高さでクラスター数を決定
```

**実用的なアプローチ**:
- 生物学的/化学的な意味を考慮
- 複数の方法で確認
- サンプルサイズを考慮（クラスターあたり最低5-10サンプル）

### Q24: 統計検定のp値はどう解釈しますか？

**A:** 

**基本的な解釈**:
- **p < 0.05**: 統計的に有意な差がある（5%の有意水準）
- **p < 0.01**: 非常に有意
- **p < 0.001**: 極めて有意
- **p ≥ 0.05**: 有意な差があるとは言えない

**注意点**:

1. **多重比較補正**
   複数の検定を行う場合、偽陽性が増加：
   ```
   100回の検定 × 0.05 = 5回の偽陽性が期待される
   
   解決策:
   - Bonferroni補正: α_adjusted = 0.05 / 100 = 0.0005
   - FDR補正: より緩やか
   ```

2. **効果量も確認**
   p値は統計的有意性のみ示し、実用的な重要性は示しません：
   ```
   - Cohen's d < 0.2: 小さい効果
   - Cohen's d 0.2-0.5: 中程度の効果
   - Cohen's d > 0.8: 大きい効果
   ```

3. **サンプルサイズの影響**
   大きなサンプルサイズでは、小さな差でも有意になる可能性

### Q25: 結果をエクスポートする方法は？

**A:** 現時点のエクスポートは、主に以下の形式に対応しています。

- **データ**: CSV / XLSX / JSON / TXT / PKL
- **図（プロット）**: PNG / SVG

※ PDF 形式のレポート生成は現時点では未対応です。
必要な場合は、エクスポートされたデータ/画像を外部ツールでまとめてください。

---

(faq-ml)=
## 機械学習

### Q26: どの機械学習アルゴリズムを選択すべきですか？

**A:** データと目的によります：

**初心者/一般的な使用**:
```
Random Forest
- バランスが良い
- ハイパーパラメータ調整が少ない
- 特徴量の重要度を提供
- 過学習に強い
```

**高精度が必要**:
```
XGBoost
- 最高の精度（通常）
- ハイパーパラメータ調整が重要
- やや遅い
- 競技やベンチマークに最適
```

**解釈性が重要**:
```
ロジスティック回帰
- 最もシンプル
- 係数が直接解釈可能
- 線形分離可能なデータに適用
- ベースラインモデルとして最適
```

**少数のサンプル**:
```
SVM (Support Vector Machine)
- 少ないサンプルでも動作
- 高次元データに強い
- カーネルトリックで非線形境界
```

**推奨アプローチ**: 複数のアルゴリズムを試して比較

### Q27: データをトレーニング/テストセットに分割する必要がありますか？

**A:** はい、必須です！

**理由**: 
モデルの汎化性能（新しいデータへの適用能力）を評価するため

**推奨分割**:
```
- トレーニング: 70%（モデルの学習用）
- テスト: 30%（最終評価用）

または

- トレーニング: 60%
- 検証: 20%（ハイパーパラメータ調整用）
- テスト: 20%（最終評価用）
```

**アプリケーションでの実行**:
```
機械学習 → 設定 → データ分割 →
テスト分割: 0.3
ランダムシード: 42（再現性のため）
```

**クロスバリデーションも使用**:
```
設定 → クロスバリデーション有効化 →
Folds: 5
```
より信頼性の高い評価

### Q28: 混同行列の読み方を教えてください

**A:** 

**混同行列の例**:
```
実際のクラス
         A    B    C
予測  A [45   3   2]  
      B [ 2  48   1]
      C [ 1   2  47]
```

**解釈**:
- **対角線上の値**: 正しい予測（45, 48, 47）
- **対角線外の値**: 誤った予測

**メトリクスの計算（クラスA）**:
```
真陽性 (TP): 45
偽陽性 (FP): 3 + 2 = 5
偽陰性 (FN): 2 + 1 = 3
真陰性 (TN): 48 + 1 + 2 + 47 = 98

精度 (Precision): TP / (TP + FP) = 45 / 50 = 90%
再現率 (Recall): TP / (TP + FN) = 45 / 48 = 93.75%
F1スコア: 2 × (Precision × Recall) / (Precision + Recall) = 91.84%
```

**良い結果の指標**:
- 対角線上の値が大きい（濃い色）
- 対角線外の値が小さい（薄い色）
- すべてのクラスでバランスが取れている

### Q29: モデルが過学習しているか確認する方法は？

**A:** 

**兆候**:
```
訓練精度: 99%
テスト精度: 65%
→ 過学習！（34%の差）
```

**確認方法**:

1. **訓練/テスト精度の差**
   - < 5%: 良好
   - 5-10%: 許容範囲
   - > 10%: 過学習の可能性

2. **学習曲線**
   ```
   エポック数を増やすと:
   - 訓練誤差: 減少し続ける
   - 検証誤差: 増加し始める
   → 過学習
   ```

3. **クロスバリデーションスコアの分散**
   ```
   CV スコア: [0.85, 0.88, 0.86, 0.84, 0.87]
   平均: 0.86, 標準偏差: 0.015
   → 安定（過学習なし）
   
   CV スコア: [0.95, 0.65, 0.90, 0.70, 0.88]
   平均: 0.82, 標準偏差: 0.118
   → 不安定（過学習の可能性）
   ```

**解決策**:
- より多くのトレーニングデータ
- 正則化パラメータの調整
- 特徴量の削減
- より単純なモデルの使用
- データ拡張

### Q30: 特徴量の重要度を確認できますか？

**A:** はい、Random ForestとXGBoostで可能です：

**アプリケーション内**:
```
機械学習 → モデルをトレーニング → 
結果タブ → 特徴量の重要度
```

**プロット**:
- 棒グラフで各波数の重要度を表示
- 重要な波数が赤で強調

**使用方法**:
1. **重要な波数を特定**: どの波数が分類に最も寄与するか
2. **化学的解釈**: これらの波数に対応する化学結合を特定
3. **特徴量選択**: 重要度の低い波数を除去（オプション）
4. **スペクトル領域の選択**: 重要な領域に焦点を当てる

**例**:
```python
# 上位20の重要な波数
top_20_wavenumbers = [1450, 1485, 1590, 1620, ...]

# これらに対応する化学結合
# 1450 cm⁻¹: CH₂ bending
# 1590 cm⁻¹: C=C stretching
```

---

(faq-troubleshooting)=
## エラーとトラブルシューティング

### Q31: "Memory Error"が表示されます

**A:** メモリ不足です。以下を試してください：

**即効解決策**:
1. 他のアプリケーションを閉じる
2. ブラウザのタブを減らす
3. アプリケーションを再起動

**データサイズの削減**:
```text
# 方法1: スペクトル数を減らす
全データを複数のバッチに分割

# 方法2: 波数範囲を制限
関心領域のみを選択（例: 500-2000 cm⁻¹）

# 方法3: ダウンサンプリング
2ポイントごと、3ポイントごとに選択
```

**システムアップグレード**:
- RAMを増設（8 GB → 16 GB）
- 64ビットPythonを使用
- スワップファイルを増やす

### Q32: アプリケーションがクラッシュします

**A:** 

**ログを確認**:
```bash
# ログファイルの場所
Windows: %APPDATA%\RamanApp\logs\
macOS: ~/Library/Logs/RamanApp/
Linux: ~/.local/share/RamanApp/logs/

# 最新のログを開く
cat app.log
```

**一般的な原因と解決策**:

1. **PyQt6エラー**
   ```bash
   # PyQt6を再インストール
   uv pip uninstall PyQt6
   uv pip install PyQt6
   ```

2. **NumPy/SciPyエラー**
   ```bash
   # 互換性のあるバージョンをインストール
   uv pip install numpy==1.24.0 scipy==1.11.0
   ```

3. **破損した設定ファイル**
   ```bash
   # 設定をリセット
   rm -rf ~/.config/RamanApp/  # macOS/Linux
   # または
   rd /s "%APPDATA%\RamanApp"  # Windows
   ```

### Q33: 図が表示されません

**A:** 

**確認項目**:
1. **Matplotlibバックエンド**
   ```python
   import matplotlib
   print(matplotlib.get_backend())  # 'Qt5Agg' または 'Qt6Agg' のはず
   ```

2. **グラフィックスドライバ**
   - 最新のドライバに更新
   - ハードウェアアクセラレーションを無効化（テスト）

3. **環境変数**
   ```bash
   # Qt設定
   export QT_DEBUG_PLUGINS=1  # デバッグ情報を出力
   ```

**回避策**:
```
設定 → グラフィックス → 
「ソフトウェアレンダリングを使用」にチェック
```

### Q34: "Singular matrix"エラーが出ます

**A:** 数学的に特異な行列（逆行列が存在しない）です。

**原因**:
- **重複データ**: 完全に同一のスペクトル
- **線形従属**: 一部の波数が他の線形結合
- **ゼロ分散**: すべての値が同じ波数がある

**解決策**:
```text
# 1. 重複を除去
data_page → 重複を削除

# 2. 分散が低い特徴量を除去
前処理 → 特徴量選択 → 
「分散閾値で選択」→ 閾値: 0.01

# 3. PCAで次元削減
分析 → PCA → 
n_components: min(n_samples, n_features) - 1
```

### Q35: プロジェクトファイルが開けません

**A:** 

**原因の確認**:
```python
# ファイルの整合性チェック
import json

with open('project.json', 'r') as f:
    try:
        data = json.load(f)
        print("ファイルは有効です")
    except json.JSONDecodeError as e:
        print(f"破損しています: {e}")
```

**回復方法**:

1. **バックアップから復元**
   ```
   ファイル → プロジェクトを開く → 
   バックアップフォルダを探す
   ```

2. **手動修復**
   テキストエディタで開いてJSON構文エラーを修正

3. **新規プロジェクト**
   最悪の場合、データを再インポート

**予防策**:
- 定期的なバックアップ（自動バックアップを有効化）
- バージョン管理（Git使用）
- クラウドストレージに保存

---

(faq-advanced)=
## 高度な使用方法

### Q39: カスタム前処理手法を追加できますか？

**A:** はい、Pythonコードで追加可能です：

```python
# 1. カスタム関数を定義
import numpy as np

def my_custom_method(spectrum, param1=10, param2=0.5):
    """
    カスタム前処理手法
    
    Parameters
    ----------
    spectrum : np.ndarray
        入力スペクトル
    param1 : int
        パラメータ1
    param2 : float
        パラメータ2
    
    Returns
    -------
    np.ndarray
        処理済みスペクトル
    """
    # カスタムロジック
    processed = spectrum * param2 + param1
    return processed

# 2. レジストリに登録
from functions.preprocess.registry import MethodRegistry

MethodRegistry.register(
    name="my_method",
    function=my_custom_method,
    category="Custom",
    description="私のカスタム手法",
    parameters={
        "param1": {"type": "int", "default": 10, "min": 1, "max": 100},
        "param2": {"type": "float", "default": 0.5, "min": 0.0, "max": 1.0}
    }
)

# 3. アプリを再起動
# → 前処理メニューに自動的に表示される
```

詳細は[開発ガイド](dev-guide/contributing.md)をご覧ください。

### Q40: Pythonスクリプトからアプリの機能を使用できますか？

**A:** 現時点では、公式にサポートされたPython API / CLIは提供していません。
自動化が必要な場合は、GUI上のフォルダ読み込みやエクスポート機能をご利用ください。

### Q41: バッチ処理を自動化できますか？

**A:** 現時点では、コマンドラインによるバッチ実行は未対応です。

代替として、GUIで以下を組み合わせて運用できます：

- データパッケージの**フォルダ読み込み**（複数ファイルをまとめて取り込み）
- 必要な結果の**エクスポート**（CSV / XLSX / JSON / TXT / PKL、図: PNG / SVG）

### Q42: 他のソフトウェアとデータを交換できますか？

**A:** はい、一般的な形式でのやり取りを想定しています。

**インポート（現時点で対応）**:
- CSV / TXT / ASC / ASCII / PKL

**エクスポート（現時点で対応）**:
- データ: CSV / XLSX / JSON / TXT / PKL
- 図（プロット）: PNG / SVG

※ MAT/HDF5/SPC などの専用形式は現時点では未対応です。

### Q43: リアルタイムデータ取得はサポートされていますか？

**A:** 現時点では、主にファイル読み込みベースのワークフローです。
装置からのリアルタイム取得（例: SDK連携）は準備中のため、GUI上の機能としては未対応の場合があります。

### Q44: クラウドでアプリケーションを実行できますか？

**A:** 本アプリはデスクトップGUIアプリケーションとして提供されており、クラウド実行（Docker/サーバーモードなど）は現時点では未対応です。

### Q45: ヘルプやサポートを受けるには？

**A:** 複数のサポートチャネルがあります：

**ドキュメント**:
1. **[ユーザーガイド](user-guide/index.md)** - 完全な機能ドキュメント
2. **[はじめに](getting-started.md)** - セットアップと基本の流れ
3. **[API リファレンス](api/index.md)** - 開発者向けドキュメント
4. **[トラブルシューティング](troubleshooting.md)** - 問題解決ガイド

**コミュニティ**:
- **GitHub Discussions**: [質問と議論](https://github.com/zerozedsc/Raman-Spectroscopy-Analysis-Application/discussions)
- **GitHub Issues**: [バグ報告と機能リクエスト](https://github.com/zerozedsc/Raman-Spectroscopy-Analysis-Application/issues)

**質問するときのヒント**:
```
良い質問の例:
「AsLSベースライン補正を適用すると、1000 cm⁻¹付近のピークが
消えてしまいます。lambda=100000、p=0.01を使用しています。
スペクトルは蛍光バックグラウンドが強いです。推奨されるパラメータは？」

含めるべき情報:
✓ 実行している操作
✓ 使用しているパラメータ
✓ 期待される結果と実際の結果
✓ エラーメッセージ（ある場合）
✓ アプリケーションのバージョン
✓ オペレーティングシステム
```

---

## 📚 追加リソース

### 学習資料

- **[クイックスタート](quick-start.md)** - 5分で開始
- **[はじめに](getting-started.md)** - セットアップと基本の流れ
- **[分析手法](analysis-methods/index.md)** - すべての手法の説明

### コミュニティリソース

- （準備中）

### 開発者リソース

- **[GitHub](https://github.com/zerozedsc/Raman-Spectroscopy-Analysis-Application)** - ソースコード
- **[貢献ガイド](dev-guide/contributing.md)** - 開発方法
- **[API ドキュメント](api/index.md)** - プログラマティックアクセス

---

**さらに質問がありますか？**

このFAQで質問への回答が見つからない場合は、[GitHub Discussions](https://github.com/zerozedsc/Raman-Spectroscopy-Analysis-Application/discussions)で質問を投稿してください。

---

**最終更新**: 2026年1月24日

# データ解析ガイド

ラマンスペクトルの包括的な解析手法

---

## 📋 目次

- {ref}`探索的データ解析 <ug-analysis-exploratory>`
- {ref}`次元削減 <ug-analysis-dim-reduction>`
- {ref}`クラスタリング <ug-analysis-clustering>`
- {ref}`統計解析 <ug-analysis-statistical>`
- {ref}`相関解析 <ug-analysis-correlation>`
- {ref}`ピーク解析 <ug-analysis-peaks>`
- {ref}`結果の解釈 <ug-analysis-interpretation>`
- {ref}`レポート作成 <ug-analysis-reporting>`

---

(ug-analysis-exploratory)=
## 探索的データ解析

### データの概要把握

#### 基本統計量

```
解析タブ → 統計サマリー

表示される情報:
- サンプル数: 150
- グループ数: 3
- 波数ポイント: 1601
- 波数範囲: 400-2000 cm⁻¹
- 平均強度: 0.523 ± 0.145
- 最小値: -0.023
- 最大値: 1.987
```

#### スペクトルの可視化

**すべてのスペクトルを重ねて表示**

```
分析タブ → 可視化 → すべてのスペクトル

オプション:
□ グループごとに色分け
□ 透明度: 0.3（重なりを見やすく）
□ 平均スペクトルを重ねて表示
```

**グループ平均の比較**

```
分析タブ → 可視化 → グループ平均

表示:
- 各グループの平均スペクトル
- 標準偏差（シェード領域）
- 信頼区間（オプション）

用途:
→ グループ間の大まかな違いを確認
```

#### ヒートマップ

```
分析タブ → 可視化 → ヒートマップ

設定:
- 行: サンプル
- 列: 波数
- カラーマップ: 'viridis'、'RdBu'、'jet'

用途:
- データ全体のパターンを視覚化
- 外れ値の検出
- グループ構造の確認
```

---

(ug-analysis-dim-reduction)=
## 次元削減

### PCA（Principal Component Analysis）

#### 原理

```
高次元データを低次元に射影し、分散を最大化

数学的定義:
X = T × P^T + E

X: 元のデータ（n × m）
T: スコア（n × k）主成分空間の座標
P: ローディング（m × k）各変数の寄与
E: 残差

目的:
- データの可視化（通常2-3次元）
- ノイズ除去
- 特徴量削減
```

#### 実行方法

```
分析タブ → PCA → 実行

設定:
n_components: 2-10
  - 可視化: 2-3
  - 前処理: 5-50
  - ノイズ除去: 説明分散90%まで

scaling: True（推奨）
  データを標準化してからPCA

center: True
  平均を0にする
```

#### スコアプロット

```
PCA結果 → スコアプロット

表示:
- X軸: PC1（第1主成分）
- Y軸: PC2（第2主成分）
- 点の色: グループ
- 点のサイズ: 調整可能

解釈:
- 近い点: 類似したスペクトル
- 遠い点: 異なるスペクトル
- グループの分離: クラスター形成
```

**3Dスコアプロット**

```
PCA結果 → 3Dスコアプロット

軸:
- X: PC1
- Y: PC2
- Z: PC3

インタラクティブ:
- マウスで回転
- ズーム
- サンプル選択
```

#### ローディングプロット

```
PCA結果 → ローディングプロット

表示:
各波数のPC1, PC2への寄与

解釈:
- 高い正の値: そのPCに正の寄与
- 高い負の値: そのPCに負の寄与
- 0に近い: そのPCとは無関係

用途:
→ どの波数がグループ分離に重要かを特定
```

#### スクリープロット

```
PCA結果 → スクリープロット

表示:
各主成分の説明分散

解釈:
- 「エルボー」の位置: 有用な成分数
- 例: PC1-3で90% → 3成分で十分

使用例:
成分1: 45%
成分2: 25%
成分3: 15%
成分4: 8%
成分5: 4%
→ 3-4成分が適切
```

#### バイプロット

```
PCA結果 → バイプロット

表示:
- スコア（サンプル）: 点
- ローディング（変数）: 矢印

解釈:
- 矢印の方向: その変数が増加する方向
- 矢印の長さ: その変数の重要度
- サンプルと矢印の位置関係:
  サンプルがその変数で高い値を持つ方向
```

### UMAP（Uniform Manifold Approximation and Projection）

#### PCAとの比較

```
PCA:
✓ 線形変換
✓ 解釈しやすい
✓ 高速
✗ 非線形構造を捉えられない

UMAP:
✓ 非線形構造を保持
✓ 局所的な構造と大域的な構造を両方保持
✓ 複雑なデータに適する
✗ 解釈が難しい
✗ やや遅い
```

#### 実行方法

```
分析タブ → UMAP → 実行

設定:
n_neighbors: 15（デフォルト）
  - 小さい（5-10）: 局所構造重視
  - 大きい（30-50）: 大域構造重視

min_dist: 0.1（デフォルト）
  - 小さい（0.01-0.1）: 密なクラスター
  - 大きい（0.3-0.5）: 広がったクラスター

n_components: 2
  通常は2次元で可視化
```

#### 使用ケース

```
UMAP が適している場合:
- PCAで分離が不明確
- 非線形な関係がある
- 複雑なデータ構造
- より視覚的に明確な分離が必要

PCA が適している場合:
- 線形な関係
- 解釈性が重要
- 高速処理が必要
- 主成分の意味を知りたい
```

### t-SNE

#### 特徴

```
非線形次元削減、可視化に特化

利点:
✓ 優れたクラスター可視化
✓ 複雑な構造を捉える

欠点:
✗ 計算が遅い
✗ 大域的な距離は保持されない
✗ 再現性の問題（ランダムシード依存）
```

#### パラメータ

```
perplexity: 30（デフォルト）
  - 小さい（5-15）: 局所構造重視
  - 大きい（50-100）: 大域構造重視
  
learning_rate: 200
  - 調整が必要な場合がある

n_iter: 1000
  - 収束に十分な反復数
```

#### 注意点

```
⚠️ t-SNEの制限:
- クラスター間の距離は意味がない
- クラスターサイズは意味がない
- 各実行で結果が異なる可能性
- 大規模データでは遅い（n > 5000）

推奨:
→ 探索的可視化にはUMAPを優先
→ t-SNEは補完的に使用
```

---

(ug-analysis-clustering)=
## クラスタリング

### K-means

#### 原理

```
k個のクラスター中心を最適化

アルゴリズム:
1. k個の中心をランダムに初期化
2. 各点を最も近い中心に割り当て
3. 各クラスターの中心を更新
4. 収束するまで繰り返し

目的関数:
minimize: Σ ||x_i - μ_k||²
```

#### 実行方法

```
分析タブ → クラスタリング → K-means

設定:
n_clusters: クラスター数
  - エルボー法で決定
  - 通常 2-10

n_init: 10
  - 異なる初期化で複数回実行
  - 最良の結果を選択

max_iter: 300
  - 収束に十分な反復数
```

#### クラスター数の決定

**エルボー法**

```
分析タブ → クラスタリング → エルボー法

プロット:
X軸: クラスター数（k）
Y軸: イナーシャ（クラスター内平方和）

探す: グラフの「エルボー」（急激な変化）

例:
k=2: イナーシャ = 1000
k=3: イナーシャ = 600
k=4: イナーシャ = 500  ← エルボー
k=5: イナーシャ = 480
k=6: イナーシャ = 470

→ k=4 が適切
```

**シルエット分析**

```
分析タブ → クラスタリング → シルエット分析

シルエットスコア: -1 〜 +1
- 1に近い: よくクラスター化されている
- 0に近い: クラスター境界上
- 負: 誤ったクラスターに割り当て

判定基準:
スコア > 0.5: 良好
スコア 0.3-0.5: 許容
スコア < 0.3: 不良

また、各クラスターのスコア分布も確認
```

**Gap統計量**

```
最適なクラスター数を統計的に決定

計算:
Gap(k) = log(W_k) - E[log(W_k*)]

W_k: クラスター内分散
E[log(W_k*)]: 参照分布での期待値

最大のGap(k)を選択
```

### 階層的クラスタリング

#### 原理

```
ボトムアップアプローチ:
1. 各点を個別のクラスターとして開始
2. 最も近い2つのクラスターを結合
3. すべてが1つのクラスターになるまで繰り返し

結果: デンドログラム（樹形図）
```

#### 実行方法

```
分析タブ → クラスタリング → 階層的

設定:
linkage: クラスター間距離の定義
  - 'ward': 分散を最小化（推奨）
  - 'average': 平均距離
  - 'complete': 最大距離
  - 'single': 最小距離

metric: 距離メトリック
  - 'euclidean'（推奨）
  - 'correlation'
  - 'cosine'
```

#### デンドログラムの解釈

```
デンドログラム表示:

     |
   __|__
  |     |
__|__  _|_
|   | |  |
A   B C  D

解釈:
- 高さ: クラスター間の距離
- 低い結合: 類似度が高い
- 高い結合: 類似度が低い

クラスター数の決定:
水平線を引いて切断
→ 交差する垂直線の数 = クラスター数
```

### DBSCAN

#### 特徴

```
密度ベースのクラスタリング

利点:
✓ クラスター数を事前指定不要
✓ 任意の形状のクラスター検出
✓ 外れ値を自動検出

欠点:
✗ パラメータ調整が難しい
✗ 密度が異なるクラスターには不向き
```

#### パラメータ

```
eps: 近傍の半径
  - 小さすぎる: 多くのノイズ点
  - 大きすぎる: すべてが1つのクラスター
  - k-距離プロットで決定

min_samples: コアポイントの最小近傍数
  - 経験則: 次元数 × 2
  - 2次元データ: 4-5
  - 高次元: より大きく
```

#### 使用例

```
分析タブ → クラスタリング → DBSCAN

設定:
eps: 0.5（データに依存）
min_samples: 5

結果:
- クラスター 0, 1, 2, ...: 検出されたクラスター
- -1: ノイズ点（外れ値）

用途:
- 外れ値検出
- 不規則な形状のクラスター
- クラスター数が不明
```

---

(ug-analysis-statistical)=
## 統計分析

### t検定

#### 2群の比較

```
分析タブ → 統計検定 → t検定

設定:
group1: グループA
group2: グループB

検定タイプ:
- 独立サンプル: 異なるサンプル
- 対応サンプル: 同じサンプルの前後

検定の種類:
- 両側検定（デフォルト）: A ≠ B
- 片側検定: A > B または A < B

有意水準: 0.05
```

#### 結果の解釈

```
出力:
- t統計量: 2.45
- p値: 0.018
- 自由度: 48
- 信頼区間: [0.05, 0.45]

解釈:
p < 0.05 → 統計的に有意な差がある

各波数でのp値プロット:
X軸: 波数
Y軸: p値
水平線: α = 0.05

有意な波数: p値 < 0.05 の波数
→ グループ間で差がある領域
```

### ANOVA（Analysis of Variance）

#### 3群以上の比較

```
分析タブ → 統計検定 → ANOVA

設定:
groups: すべてのグループ

検定タイプ:
- 一元配置: 1つの因子
- 二元配置: 2つの因子

仮説:
H0: すべてのグループの平均が等しい
H1: 少なくとも1つのグループが異なる
```

#### 多重比較

```
ANOVAで有意な場合 → どのグループ間が異なる？

事後検定:
- Tukey HSD: すべてのペアを比較
- Bonferroni: 保守的
- Dunnett: コントロール群との比較

分析タブ → 統計検定 → 事後検定:

結果例:
A vs B: p = 0.003 ***
A vs C: p = 0.234 n.s.
B vs C: p = 0.012 *

***: p < 0.001
**: p < 0.01
*: p < 0.05
n.s.: 有意でない
```

### 多重比較補正

#### 問題

```
例:
1000波数 × α=0.05 = 50の偽陽性が期待される

解決: 多重比較補正が必要
```

#### Bonferroni補正

```
最も保守的な補正

α_adjusted = α / n_tests

例:
α = 0.05
n = 1000波数
α_adjusted = 0.05 / 1000 = 0.00005

判定: p < 0.00005 の場合のみ有意
```

#### FDR（False Discovery Rate）補正

```
よりバランスの取れた補正

Benjamini-Hochberg法:
q値（FDR調整済みp値）を使用

判定: q < 0.05

特徴:
- Bonferroniより緩やか
- より多くの発見
- 偽発見率を制御
```

#### 使用方法

```
分析タブ → 統計検定 → 設定:

□ 多重比較補正を有効化

方法:
- Bonferroni（保守的）
- FDR（推奨）
- Holm
- Sidak
```

### 効果量

#### 重要性

```
p値の限界:
- サンプルサイズに依存
- 実用的な重要性を示さない

解決: 効果量を併記
```

#### Cohen's d

```
2群間の標準化された差

d = (mean1 - mean2) / pooled_std

解釈:
d < 0.2: 小さい効果
d = 0.2-0.5: 中程度の効果
d = 0.5-0.8: 大きい効果
d > 0.8: 非常に大きい効果

使用:
t検定の結果と併記
```

#### Eta-squared (η²)

```
ANOVAでの効果量

η² = SS_between / SS_total

解釈:
η² < 0.01: 小さい
η² = 0.01-0.06: 中程度
η² > 0.14: 大きい

使用:
ANOVA の結果と併記
```

---

(ug-analysis-correlation)=
## 相関分析

### ピアソン相関

```
線形相関を測定

分析タブ → 相関分析 → ピアソン

相関係数 r: -1 〜 +1
- r = 1: 完全な正の相関
- r = 0: 無相関
- r = -1: 完全な負の相関

解釈:
|r| > 0.7: 強い相関
|r| = 0.4-0.7: 中程度の相関
|r| < 0.4: 弱い相関
```

### スペアマン相関

```
順位相関（非線形でもOK）

分析タブ → 相関分析 → スペアマン

利点:
- 外れ値に頑強
- 単調な関係を検出
- 正規分布の仮定不要

使用ケース:
- 非線形な関係
- 順序データ
- 外れ値がある
```

### 相関行列

```
すべての変数間の相関

分析タブ → 相関行列

表示:
ヒートマップ
- 赤: 正の相関
- 青: 負の相関
- 白: 無相関

用途:
- 特徴量選択
- 多重共線性の検出
- 変数間の関係理解
```

---

(ug-analysis-peaks)=
## ピーク解析

### ピーク検出

```
分析タブ → ピーク解析 → ピーク検出

設定:
height: 最小ピーク高さ
  - ベースラインの5倍（推奨）
  
distance: 最小ピーク間距離
  - 10 cm⁻¹（推奨）
  
prominence: ピークの卓立度
  - 0.1-0.5

width: 最小ピーク幅
  - 3-5ポイント

結果:
検出されたピーク位置リスト:
[450, 620, 1003, 1450, 1585, 1620, ...]
```

### ピークフィッティング

```
分析タブ → ピーク解析 → フィッティング

モデル:
- Gaussian: 対称的なピーク
- Lorentzian: 裾が広いピーク
- Voigt: Gaussian + Lorentzian
- Pseudo-Voigt: Voigt の近似（高速）

パラメータ:
- 中心位置
- 高さ
- 幅（FWHM）
- 面積

用途:
- 重なったピークの分離
- ピーク位置の精密決定
- ピーク面積の定量
```

### ピーク同定

```
分析タブ → ピーク解析 → ピーク同定

データベース参照:
- 内蔵ラマンピークデータベース
- カスタムライブラリ

マッチング:
検出されたピーク vs データベース

許容誤差: ±5 cm⁻¹

結果:
1450 cm⁻¹ → CH₂ bending
1585 cm⁻¹ → C=C stretching
1620 cm⁻¹ → Aromatic C=C
```

---

(ug-analysis-interpretation)=
## 結果の解釈

### PCA結果の解釈

#### スコアプロット分析

```
観察項目:
1. クラスターの形成
   明確なグループ分離があるか？

2. 外れ値
   クラスターから大きく離れた点

3. グループ内の変動
   クラスターの広がり

4. グループ間の距離
   よく分離している vs 重なっている
```

#### ローディング解釈

```
重要な波数の特定:
1. |loading| が大きい波数を特定
2. その波数の化学的意味を調査
3. 文献やデータベースと照合

例:
PC1のローディングが大きい波数:
- 1450 cm⁻¹: CH₂ bending
- 1585 cm⁻¹: C=C stretching

→ PC1はこれらの結合の違いを表す
```

### クラスタリング結果の解釈

```
評価項目:
1. クラスター数の妥当性
   生物学的/化学的に意味があるか？

2. クラスターの品質
   シルエットスコア
   クラスター内分散

3. クラスターの特徴
   各クラスターの平均スペクトル
   特徴的な波数

4. 既知のグループとの一致
   教師なし学習の結果が
   既知のラベルと一致するか？
```

### 統計検定結果の解釈

```
報告すべき内容:
1. 検定統計量とp値
   t = 2.45, p = 0.018

2. 効果量
   Cohen's d = 0.65（中程度）

3. 信頼区間
   95% CI: [0.05, 0.45]

4. 多重比較補正
   Bonferroni補正後も有意

5. 生物学的/化学的意味
   差がある波数の解釈
```

---

(ug-analysis-reporting)=
## レポート作成

### レポート用エクスポート（現状）

現時点では、PDF/Word/HTML 形式の自動レポート生成は未対応です。
代わりに、分析結果を「フォルダ」としてまとめて出力する形式が利用される場合があります。

例（フォルダ構成の一例）:

- `plot.png`
- `data.csv`
- `report.txt`
- `metadata.json`

### カスタムレポート

カスタムレポート（PDF/Word/HTML など）は将来的に対応予定です。

### 図のエクスポート

```
各図を右クリック → 画像として保存:

フォーマット:
- PNG: プレゼンテーション（300-600 DPI）
- SVG: 編集可能（Illustratorなど）

※ PDF/EPS 出力は現時点では未対応です。

設定:
DPI: 300（標準）、600（高品質）
サイズ: カスタム（mm単位）
背景: 透明 or 白
```

---

## 🔗 関連ドキュメント

- **[前処理ガイド](preprocessing.md)** - データの前処理
- **[機械学習](machine-learning.md)** - MLモデル構築
- **[分析手法索引](../analysis-methods/index.md)** - 詳細な手法説明
- **[FAQ](../faq.md)** - よくある質問

---

**最終更新**: 2026年1月24日
